id,title,summary,published,authors
9901001v1,"TDLeaf(lambda): Combining Temporal Difference Learning with Game-Tree
  Search","In this paper we present TDLeaf(lambda), a variation on the TD(lambda)
algorithm that enables it to be used in conjunction with minimax search. We
present some experiments in both chess and backgammon which demonstrate its
utility and provide comparisons with TD(lambda) and another less radical
variant, TD-directed(lambda). In particular, our chess program, ``KnightCap,''
used TDLeaf(lambda) to learn its evaluation function while playing on the Free
Internet Chess Server (FICS, fics.onenet.net). It improved from a 1650 rating
to a 2100 rating in just 308 games. We discuss some of the reasons for this
success and the relationship between our results and Tesauro's results in
backgammon.",1999-01-05T00:56:54Z,"Jonathan Baxter, Andrew Tridgell, Lex Weaver"
9901002v1,"KnightCap: A chess program that learns by combining TD(lambda) with
  game-tree search","In this paper we present TDLeaf(lambda), a variation on the TD(lambda)
algorithm that enables it to be used in conjunction with game-tree search. We
present some experiments in which our chess program ``KnightCap'' used
TDLeaf(lambda) to learn its evaluation function while playing on the Free
Internet Chess Server (FICS, fics.onenet.net). The main success we report is
that KnightCap improved from a 1650 rating to a 2150 rating in just 308 games
and 3 days of play. As a reference, a rating of 1650 corresponds to about level
B human play (on a scale from E (1000) to A (1800)), while 2150 is human master
level. We discuss some of the reasons for this success, principle among them
being the use of on-line, rather than self-play.",1999-01-10T03:21:23Z,"Jonathan Baxter, Andrew Tridgell, Lex Weaver"
9906016v1,Automatically Selecting Useful Phrases for Dialogue Act Tagging,"We present an empirical investigation of various ways to automatically
identify phrases in a tagged corpus that are useful for dialogue act tagging.
We found that a new method (which measures a phrase's deviation from an
optimally-predictive phrase), enhanced with a lexical filtering mechanism,
produces significantly better cues than manually-selected cue phrases, the
exhaustive set of phrases in a training corpus, and phrases chosen by
traditional metrics, like mutual information and information gain.",1999-06-18T03:25:03Z,"Ken Samuel, Sandra Carberry, K. Vijay-Shanker"
9912008v2,New Error Bounds for Solomonoff Prediction,"Solomonoff sequence prediction is a scheme to predict digits of binary
strings without knowing the underlying probability distribution. We call a
prediction scheme informed when it knows the true probability distribution of
the sequence. Several new relations between universal Solomonoff sequence
prediction and informed prediction and general probabilistic prediction schemes
will be proved. Among others, they show that the number of errors in Solomonoff
prediction is finite for computable distributions, if finite in the informed
case. Deterministic variants will also be studied. The most interesting result
is that the deterministic variant of Solomonoff prediction is optimal compared
to any other probabilistic or deterministic prediction scheme apart from
additive square root corrections only. This makes it well suited even for
difficult prediction problems, where it does not suffice when the number of
errors is minimal to within some factor greater than one. Solomonoff's original
bound and the ones presented here complement each other in a useful way.",1999-12-13T08:33:43Z,Marcus Hutter
0005021v1,Modeling the Uncertainty in Complex Engineering Systems,"Existing procedures for model validation have been deemed inadequate for many
engineering systems. The reason of this inadequacy is due to the high degree of
complexity of the mechanisms that govern these systems. It is proposed in this
paper to shift the attention from modeling the engineering system itself to
modeling the uncertainty that underlies its behavior. A mathematical framework
for modeling the uncertainty in complex engineering systems is developed. This
framework uses the results of computational learning theory. It is based on the
premise that a system model is a learning machine.",2000-05-14T14:35:20Z,A. Guergachi
0109034v1,"Relevant Knowledge First - Reinforcement Learning and Forgetting in
  Knowledge Based Configuration","In order to solve complex configuration tasks in technical domains, various
knowledge based methods have been developed. However their applicability is
often unsuccessful due to their low efficiency. One of the reasons for this is
that (parts of the) problems have to be solved again and again, instead of
being ""learnt"" from preceding processes. However, learning processes bring with
them the problem of conservatism, for in technical domains innovation is a
deciding factor in competition. On the other hand a certain amount of
conservatism is often desired since uncontrolled innovation as a rule is also
detrimental. This paper proposes the heuristic RKF (Relevant Knowledge First)
for making decisions in configuration processes based on the so-called
relevance of objects in a knowledge base. The underlying relevance-function has
two components, one based on reinforcement learning and the other based on
forgetting (fading). Relevance of an object increases with its successful use
and decreases with age when it is not used. RKF has been developed to speed up
the configuration process and to improve the quality of the solutions relative
to the reward value that is given by users.",2001-09-19T08:07:38Z,"Ingo Kreuz, Dieter Roller"
0206006v1,Robust Feature Selection by Mutual Information Distributions,"Mutual information is widely used in artificial intelligence, in a
descriptive way, to measure the stochastic dependence of discrete random
variables. In order to address questions such as the reliability of the
empirical value, one must consider sample-to-population inferential approaches.
This paper deals with the distribution of mutual information, as obtained in a
Bayesian framework by a second-order Dirichlet prior distribution. The exact
analytical expression for the mean and an analytical approximation of the
variance are reported. Asymptotic approximations of the distribution are
proposed. The results are applied to the problem of selecting features for
incremental learning and classification of the naive Bayes classifier. A fast,
newly defined method is shown to outperform the traditional approach based on
empirical mutual information on a number of real data sets. Finally, a
theoretical development is reported that allows one to efficiently extend the
above methods to incomplete samples in an easy and effective way.",2002-06-03T16:00:55Z,"Marco Zaffalon, Marcus Hutter"
0206017v1,The Prioritized Inductive Logic Programs,"The limit behavior of inductive logic programs has not been explored, but
when considering incremental or online inductive learning algorithms which
usually run ongoingly, such behavior of the programs should be taken into
account. An example is given to show that some inductive learning algorithm may
not be correct in the long run if the limit behavior is not considered. An
inductive logic program is convergent if given an increasing sequence of
example sets, the program produces a corresponding sequence of the Horn logic
programs which has the set-theoretic limit, and is limit-correct if the limit
of the produced sequence of the Horn logic programs is correct with respect to
the limit of the sequence of the example sets. It is shown that the GOLEM
system is not limit-correct. Finally, a limit-correct inductive logic system,
called the prioritized GOLEM system, is proposed as a solution.",2002-06-10T16:02:36Z,"Shilong Ma, Yuefei Sui, Ke Xu"
0211006v1,Maximing the Margin in the Input Space,"We propose a novel criterion for support vector machine learning: maximizing
the margin in the input space, not in the feature (Hilbert) space. This
criterion is a discriminative version of the principal curve proposed by Hastie
et al. The criterion is appropriate in particular when the input space is
already a well-designed feature space with rather small dimensionality. The
definition of the margin is generalized in order to represent prior knowledge.
The derived algorithm consists of two alternating steps to estimate the dual
parameters. Firstly, the parameters are initialized by the original SVM. Then
one set of parameters is updated by Newton-like procedure, and the other set is
updated by solving a quadratic programming problem. The algorithm converges in
a few steps to a local optimum under mild conditions and it preserves the
sparsity of support vectors. Although the complexity to calculate temporal
variables increases the complexity to solve the quadratic programming problem
for each step does not change. It is also shown that the original SVM can be
seen as a special case. We further derive a simplified algorithm which enables
us to use the existing code for the original SVM.",2002-11-07T06:44:54Z,Shotaro Akaho
0212008v1,"Principal Manifolds and Nonlinear Dimension Reduction via Local Tangent
  Space Alignment","Nonlinear manifold learning from unorganized data points is a very
challenging unsupervised learning and data visualization problem with a great
variety of applications. In this paper we present a new algorithm for manifold
learning and nonlinear dimension reduction. Based on a set of unorganized data
points sampled with noise from the manifold, we represent the local geometry of
the manifold using tangent spaces learned by fitting an affine subspace in a
neighborhood of each data point. Those tangent spaces are aligned to give the
internal global coordinates of the data points with respect to the underlying
manifold by way of a partial eigendecomposition of the neighborhood connection
matrix. We present a careful error analysis of our algorithm and show that the
reconstruction errors are of second-order accuracy. We illustrate our algorithm
using curves and surfaces both in
  2D/3D and higher dimensional Euclidean spaces, and 64-by-64 pixel face images
with various pose and lighting conditions. We also address several theoretical
and algorithmic issues for further research and improvements.",2002-12-07T18:51:12Z,"Zhenyue Zhang, Hongyuan Zha"
0301007v1,Kalman filter control in the reinforcement learning framework,"There is a growing interest in using Kalman-filter models in brain modelling.
In turn, it is of considerable importance to make Kalman-filters amenable for
reinforcement learning. In the usual formulation of optimal control it is
computed off-line by solving a backward recursion. In this technical note we
show that slight modification of the linear-quadratic-Gaussian Kalman-filter
model allows the on-line estimation of optimal control and makes the bridge to
reinforcement learning. Moreover, the learning rule for value estimation
assumes a Hebbian form weighted by the error of the value estimation.",2003-01-09T15:08:47Z,"Istvan Szita, Andras Lorincz"
0302015v1,"Unsupervised Learning in a Framework of Information Compression by
  Multiple Alignment, Unification and Search","This paper describes a novel approach to unsupervised learning that has been
developed within a framework of ""information compression by multiple alignment,
unification and search"" (ICMAUS), designed to integrate learning with other AI
functions such as parsing and production of language, fuzzy pattern
recognition, probabilistic and exact forms of reasoning, and others.",2003-02-12T09:39:00Z,J. G. Wolff
0306120v2,"Reinforcement Learning with Linear Function Approximation and LQ control
  Converges","Reinforcement learning is commonly used with function approximation. However,
very few positive results are known about the convergence of function
approximation based RL control algorithms. In this paper we show that TD(0) and
Sarsa(0) with linear function approximation is convergent for a simple class of
problems, where the system is linear and the costs are quadratic (the LQ
control problem). Furthermore, we show that for systems with Gaussian noise and
non-completely observable states (the LQG problem), the mentioned RL algorithms
are still convergent, if they are combined with Kalman filtering.",2003-06-22T08:00:09Z,"Istvan Szita, Andras Lorincz"
0403031v2,"Concept of E-machine: How does a ""dynamical"" brain learn to process
  ""symbolic"" information? Part I","The human brain has many remarkable information processing characteristics
that deeply puzzle scientists and engineers. Among the most important and the
most intriguing of these characteristics are the brain's broad universality as
a learning system and its mysterious ability to dynamically change
(reconfigure) its behavior depending on a combinatorial number of different
contexts.
  This paper discusses a class of hypothetically brain-like dynamically
reconfigurable associative learning systems that shed light on the possible
nature of these brain's properties. The systems are arranged on the general
principle referred to as the concept of E-machine.
  The paper addresses the following questions:
  1. How can ""dynamical"" neural networks function as universal programmable
""symbolic"" machines?
  2. What kind of a universal programmable symbolic machine can form
arbitrarily complex software in the process of programming similar to the
process of biological associative learning?
  3. How can a universal learning machine dynamically reconfigure its software
depending on a combinatorial number of possible contexts?",2004-03-19T17:13:55Z,Victor Eliashberg
0403038v1,Tournament versus Fitness Uniform Selection,"In evolutionary algorithms a critical parameter that must be tuned is that of
selection pressure. If it is set too low then the rate of convergence towards
the optimum is likely to be slow. Alternatively if the selection pressure is
set too high the system is likely to become stuck in a local optimum due to a
loss of diversity in the population. The recent Fitness Uniform Selection
Scheme (FUSS) is a conceptually simple but somewhat radical approach to
addressing this problem - rather than biasing the selection towards higher
fitness, FUSS biases selection towards sparsely populated fitness levels. In
this paper we compare the relative performance of FUSS with the well known
tournament selection scheme on a range of problems.",2004-03-23T15:17:53Z,"Shane Legg, Marcus Hutter, Akshat Kumar"
0405043v2,"Prediction with Expert Advice by Following the Perturbed Leader for
  General Weights","When applying aggregating strategies to Prediction with Expert Advice, the
learning rate must be adaptively tuned. The natural choice of
sqrt(complexity/current loss) renders the analysis of Weighted Majority
derivatives quite complicated. In particular, for arbitrary weights there have
been no results proven so far. The analysis of the alternative ""Follow the
Perturbed Leader"" (FPL) algorithm from Kalai (2003} (based on Hannan's
algorithm) is easier. We derive loss bounds for adaptive learning rate and both
finite expert classes with uniform weights and countable expert classes with
arbitrary weights. For the former setup, our loss bounds match the best known
results so far, while for the latter our results are (to our knowledge) new.",2004-05-12T16:41:01Z,"Marcus Hutter, Jan Poland"
0407016v1,Learning for Adaptive Real-time Search,"Real-time heuristic search is a popular model of acting and learning in
intelligent autonomous agents. Learning real-time search agents improve their
performance over time by acquiring and refining a value function guiding the
application of their actions. As computing the perfect value function is
typically intractable, a heuristic approximation is acquired instead. Most
studies of learning in real-time search (and reinforcement learning) assume
that a simple value-function-greedy policy is used to select actions. This is
in contrast to practice, where high-performance is usually attained by
interleaving planning and acting via a lookahead search of a non-trivial depth.
In this paper, we take a step toward bridging this gap and propose a novel
algorithm that (i) learns a heuristic function to be used specifically with a
lookahead-based policy, (ii) selects the lookahead depth adaptively in each
state, (iii) gives the user control over the trade-off between exploration and
exploitation. We extensively evaluate the algorithm in the sliding tile puzzle
testbed comparing it to the classical LRTA* and the more recent weighted LRTA*,
bounded LRTA*, and FALCONS. Improvements of 5 to 30 folds in convergence speed
are observed.",2004-07-06T22:18:25Z,Vadim Bulitko
0410015v1,"L1 regularization is better than L2 for learning and predicting chaotic
  systems","Emergent behaviors are in the focus of recent research interest. It is then
of considerable importance to investigate what optimizations suit the learning
and prediction of chaotic systems, the putative candidates for emergence. We
have compared L1 and L2 regularizations on predicting chaotic time series using
linear recurrent neural networks. The internal representation and the weights
of the networks were optimized in a unifying framework. Computational tests on
different problems indicate considerable advantages for the L1 regularization:
It had considerably better learning time and better interpolating capabilities.
We shall argue that optimization viewed as a maximum likelihood estimation
justifies our results, because L1 regularization fits heavy-tailed
distributions -- an apparently general feature of emergent systems -- better.",2004-10-07T10:57:08Z,"Z. Szabo, A. Lorincz"
0411099v1,A Note on the PAC Bayesian Theorem,"We prove general exponential moment inequalities for averages of [0,1]-valued
iid random variables and use them to tighten the PAC Bayesian Theorem. The
logarithmic dependence on the sample count in the enumerator of the PAC
Bayesian bound is halved.",2004-11-30T08:36:59Z,Andreas Maurer
0502067v1,"Master Algorithms for Active Experts Problems based on Increasing Loss
  Values","We specify an experts algorithm with the following characteristics: (a) it
uses only feedback from the actions actually chosen (bandit setup), (b) it can
be applied with countably infinite expert classes, and (c) it copes with losses
that may grow in time appropriately slowly. We prove loss bounds against an
adaptive adversary. From this, we obtain master algorithms for ""active experts
problems"", which means that the master's actions may influence the behavior of
the adversary. Our algorithm can significantly outperform standard experts
algorithms on such problems. Finally, we combine it with a universal expert
class. This results in a (computationally infeasible) universal master
algorithm which performs - in a certain sense - almost as well as any
computable strategy, for any online problem.",2005-02-15T14:59:49Z,"Jan Poland, Marcus Hutter"
0504042v1,The Bayesian Decision Tree Technique with a Sweeping Strategy,"The uncertainty of classification outcomes is of crucial importance for many
safety critical applications including, for example, medical diagnostics. In
such applications the uncertainty of classification can be reliably estimated
within a Bayesian model averaging technique that allows the use of prior
information. Decision Tree (DT) classification models used within such a
technique gives experts additional information by making this classification
scheme observable. The use of the Markov Chain Monte Carlo (MCMC) methodology
of stochastic sampling makes the Bayesian DT technique feasible to perform.
However, in practice, the MCMC technique may become stuck in a particular DT
which is far away from a region with a maximal posterior. Sampling such DTs
causes bias in the posterior estimates, and as a result the evaluation of
classification uncertainty may be incorrect. In a particular case, the negative
effect of such sampling may be reduced by giving additional prior information
on the shape of DTs. In this paper we describe a new approach based on sweeping
the DTs without additional priors on the favorite shape of DTs. The
performances of Bayesian DT techniques with the standard and sweeping
strategies are compared on a synthetic data as well as on real datasets.
Quantitatively evaluating the uncertainty in terms of entropy of class
posterior probabilities, we found that the sweeping strategy is superior to the
standard strategy.",2005-04-11T17:45:09Z,"V. Schetinin, J. E. Fieldsend, D. Partridge, W. J. Krzanowski, R. M. Everson, T. C. Bailey, A. Hernandez"
0504043v1,"Experimental Comparison of Classification Uncertainty for Randomised and
  Bayesian Decision Tree Ensembles","In this paper we experimentally compare the classification uncertainty of the
randomised Decision Tree (DT) ensemble technique and the Bayesian DT technique
with a restarting strategy on a synthetic dataset as well as on some datasets
commonly used in the machine learning community. For quantitative evaluation of
classification uncertainty, we use an Uncertainty Envelope dealing with the
class posterior distribution and a given confidence probability. Counting the
classifier outcomes, this technique produces feasible evaluations of the
classification uncertainty. Using this technique in our experiments, we found
that the Bayesian DT technique is superior to the randomised DT ensemble
technique.",2005-04-11T17:53:35Z,"V. Schetinin, D. Partridge, W. J. Krzanowski, R. M. Everson, J. E. Fieldsend, T. C. Bailey, A. Hernandez"
0504078v1,Adaptive Online Prediction by Following the Perturbed Leader,"When applying aggregating strategies to Prediction with Expert Advice, the
learning rate must be adaptively tuned. The natural choice of
sqrt(complexity/current loss) renders the analysis of Weighted Majority
derivatives quite complicated. In particular, for arbitrary weights there have
been no results proven so far. The analysis of the alternative ""Follow the
Perturbed Leader"" (FPL) algorithm from Kalai & Vempala (2003) (based on
Hannan's algorithm) is easier. We derive loss bounds for adaptive learning rate
and both finite expert classes with uniform weights and countable expert
classes with arbitrary weights. For the former setup, our loss bounds match the
best known results so far, while for the latter our results are new.",2005-04-16T16:48:49Z,"Marcus Hutter, Jan Poland"
0504086v1,Componentwise Least Squares Support Vector Machines,"This chapter describes componentwise Least Squares Support Vector Machines
(LS-SVMs) for the estimation of additive models consisting of a sum of
nonlinear components. The primal-dual derivations characterizing LS-SVMs for
the estimation of the additive model result in a single set of linear equations
with size growing in the number of data-points. The derivation is elaborated
for the classification as well as the regression case. Furthermore, different
techniques are proposed to discover structure in the data by looking for sparse
components in the model based on dedicated regularization schemes on the one
hand and fusion of the componentwise LS-SVMs training with a validation
criterion on the other hand. (keywords: LS-SVMs, additive models,
regularization, structure detection)",2005-04-19T15:01:25Z,"Kristiaan Pelckmans, Ivan Goethals, Jos De Brabanter, Johan A. K. Suykens, Bart De Moor"
0505083v1,Defensive forecasting,"We consider how to make probability forecasts of binary labels. Our main
mathematical result is that for any continuous gambling strategy used for
detecting disagreement between the forecasts and the actual labels, there
exists a forecasting strategy whose forecasts are ideal as far as this gambling
strategy is concerned. A forecasting strategy obtained in this way from a
gambling strategy demonstrating a strong law of large numbers is simplified and
studied empirically.",2005-05-30T21:12:00Z,"Vladimir Vovk, Akimichi Takemura, Glenn Shafer"
0506041v3,Competitive on-line learning with a convex loss function,"We consider the problem of sequential decision making under uncertainty in
which the loss caused by a decision depends on the following binary
observation. In competitive on-line learning, the goal is to design decision
algorithms that are almost as good as the best decision rules in a wide
benchmark class, without making any assumptions about the way the observations
are generated. However, standard algorithms in this area can only deal with
finite-dimensional (often countable) benchmark classes. In this paper we give
similar results for decision rules ranging over an arbitrary reproducing kernel
Hilbert space. For example, it is shown that for a wide class of loss functions
(including the standard square, absolute, and log loss functions) the average
loss of the master algorithm, over the first $N$ observations, does not exceed
the average loss of the best decision rule with a bounded norm plus
$O(N^{-1/2})$. Our proof technique is very different from the standard ones and
is based on recent results about defensive forecasting. Given the probabilities
produced by a defensive forecasting algorithm, which are known to be well
calibrated and to have good resolution in the long run, we use the expected
loss minimization principle to find a suitable decision.",2005-06-11T18:11:22Z,Vladimir Vovk
0508073v1,Universal Learning of Repeated Matrix Games,"We study and compare the learning dynamics of two universal learning
algorithms, one based on Bayesian learning and the other on prediction with
expert advice. Both approaches have strong asymptotic performance guarantees.
When confronted with the task of finding good long-term strategies in repeated
2x2 matrix games, they behave quite differently.",2005-08-16T16:27:25Z,"Jan Poland, Marcus Hutter"
0510080v1,When Ignorance is Bliss,"It is commonly-accepted wisdom that more information is better, and that
information should never be ignored. Here we argue, using both a Bayesian and a
non-Bayesian analysis, that in some situations you are better off ignoring
information if your uncertainty is represented by a set of probability
measures. These include situations in which the information is relevant for the
prediction task at hand. In the non-Bayesian analysis, we show how ignoring
information avoids dilation, the phenomenon that additional pieces of
information sometimes lead to an increase in uncertainty. In the Bayesian
analysis, we show that for small sample sizes and certain prediction tasks, the
Bayesian posterior based on a noninformative prior yields worse predictions
than simply ignoring the given information.",2005-10-25T22:14:33Z,"Peter D. Grunwald, Joseph Y. Halpern"
0511075v1,"Identifying Interaction Sites in ""Recalcitrant"" Proteins: Predicted
  Protein and Rna Binding Sites in Rev Proteins of Hiv-1 and Eiav Agree with
  Experimental Data","Protein-protein and protein nucleic acid interactions are vitally important
for a wide range of biological processes, including regulation of gene
expression, protein synthesis, and replication and assembly of many viruses. We
have developed machine learning approaches for predicting which amino acids of
a protein participate in its interactions with other proteins and/or nucleic
acids, using only the protein sequence as input. In this paper, we describe an
application of classifiers trained on datasets of well-characterized
protein-protein and protein-RNA complexes for which experimental structures are
available. We apply these classifiers to the problem of predicting protein and
RNA binding sites in the sequence of a clinically important protein for which
the structure is not known: the regulatory protein Rev, essential for the
replication of HIV-1 and other lentiviruses. We compare our predictions with
published biochemical, genetic and partial structural information for HIV-1 and
EIAV Rev and with our own published experimental mapping of RNA binding sites
in EIAV Rev. The predicted and experimentally determined binding sites are in
very good agreement. The ability to predict reliably the residues of a protein
that directly contribute to specific binding events - without the requirement
for structural information regarding either the protein or complexes in which
it participates - can potentially generate new disease intervention strategies.",2005-11-21T01:47:53Z,"Michael Terribilini, Jae-Hyung Lee, Changhui Yan, Robert L. Jernigan, Susan Carpenter, Vasant Honavar, Drena Dobbs"
0603110v1,"Asymptotic Learnability of Reinforcement Problems with Arbitrary
  Dependence","We address the problem of reinforcement learning in which observations may
exhibit an arbitrary form of stochastic dependence on past observations and
actions. The task for an agent is to attain the best possible asymptotic reward
where the true generating environment is unknown but belongs to a known
countable family of environments. We find some sufficient conditions on the
class of environments under which an agent exists which attains the best
asymptotic reward for any environment in the class. We analyze how tight these
conditions are and how they relate to different probabilistic assumptions known
in reinforcement learning and related fields, such as Markov Decision Processes
and mixing conditions.",2006-03-28T16:22:42Z,"Daniil Ryabko, Marcus Hutter"
0604010v2,Nearly optimal exploration-exploitation decision thresholds,"While in general trading off exploration and exploitation in reinforcement
learning is hard, under some formulations relatively simple solutions exist. In
this paper, we first derive upper bounds for the utility of selecting different
actions in the multi-armed bandit setting. Unlike the common statistical upper
confidence bounds, these explicitly link the planning horizon, uncertainty and
the need for exploration explicit. The resulting algorithm can be seen as a
generalisation of the classical Thompson sampling algorithm. We experimentally
test these algorithms, as well as $\epsilon$-greedy and the value of perfect
information heuristics. Finally, we also introduce the idea of bagging for
reinforcement learning. By employing a version of online bootstrapping, we can
efficiently sample from an approximate posterior distribution.",2006-04-05T10:29:48Z,Christos Dimitrakakis
0605024v1,A Formal Measure of Machine Intelligence,"A fundamental problem in artificial intelligence is that nobody really knows
what intelligence is. The problem is especially acute when we need to consider
artificial systems which are significantly different to humans. In this paper
we approach this problem in the following way: We take a number of well known
informal definitions of human intelligence that have been given by experts, and
extract their essential features. These are then mathematically formalised to
produce a general measure of intelligence for arbitrary machines. We believe
that this measure formally captures the concept of machine intelligence in the
broadest reasonable sense.",2006-05-06T16:56:43Z,"Shane Legg, Marcus Hutter"
0607138v1,"A Foundation to Perception Computing, Logic and Automata","In this report, a novel approach to intelligence and learning is introduced,
this approach is based on what we call 'perception logic'. Based on this logic,
a computing mechanism and automata are introduced. Multi-resolution analysis of
perceptual information is given, in which learning is accomplished in at most
O(log(N))epochs, where N is the number of samples, and the convergence is
guarnteed. This approach combines the favors of computational modeles in the
sense that they are structured and mathematically well-defined, and the
adaptivity of soft computing approaches, in addition to the continuity and
real-time response of dynamical systems.",2006-07-30T10:44:48Z,Mohamed A. Belal
0610170v1,"Low-complexity modular policies: learning to play Pac-Man and a new
  framework beyond MDPs","In this paper we propose a method that learns to play Pac-Man. We define a
set of high-level observation and action modules. Actions are temporally
extended, and multiple action modules may be in effect concurrently. A decision
of the agent is represented as a rule-based policy. For learning, we apply the
cross-entropy method, a recent global optimization algorithm. The learned
policies reached better score than the hand-crafted policy, and neared the
score of average human players. We argue that learning is successful mainly
because (i) the policy space includes the combination of individual actions and
thus it is sufficiently rich, (ii) the search is biased towards low-complexity
policies and low complexity solutions can be found quickly if they exist. Based
on these principles, we formulate a new theoretical framework, which can be
found in the Appendix as supporting material.",2006-10-30T16:44:58Z,"Istvan Szita, Andras Lorincz"
0611164v1,"Player co-modelling in a strategy board game: discovering how to play
  fast","In this paper we experiment with a 2-player strategy board game where playing
models are evolved using reinforcement learning and neural networks. The models
are evolved to speed up automatic game development based on human involvement
at varying levels of sophistication and density when compared to fully
autonomous playing. The experimental results suggest a clear and measurable
association between the ability to win games and the ability to do that fast,
while at the same time demonstrating that there is a minimum level of human
involvement beyond which no learning really occurs.",2006-11-30T15:36:27Z,Dimitris Kalles
0701125v1,Universal Algorithmic Intelligence: A mathematical top->down approach,"Sequential decision theory formally solves the problem of rational agents in
uncertain worlds if the true environmental prior probability distribution is
known. Solomonoff's theory of universal induction formally solves the problem
of sequence prediction for unknown prior distribution. We combine both ideas
and get a parameter-free theory of universal Artificial Intelligence. We give
strong arguments that the resulting AIXI model is the most intelligent unbiased
agent possible. We outline how the AIXI model can formally solve a number of
problem classes, including sequence prediction, strategic games, function
minimization, reinforcement and supervised learning. The major drawback of the
AIXI model is that it is uncomputable. To overcome this problem, we construct a
modified algorithm AIXItl that is still effectively more intelligent than any
other time t and length l bounded agent. The computation time of AIXItl is of
the order t x 2^l. The discussion includes formal definitions of intelligence
order relations, the horizon problem and relations of the AIXI theory to other
AI approaches.",2007-01-20T00:18:06Z,Marcus Hutter
0704.1409v3,Preconditioned Temporal Difference Learning,"This paper has been withdrawn by the author. This draft is withdrawn for its
poor quality in english, unfortunately produced by the author when he was just
starting his science route. Look at the ICML version instead:
http://icml2008.cs.helsinki.fi/papers/111.pdf",2007-04-11T13:17:01Z,Yao HengShuai
0706.0585v1,A Novel Model of Working Set Selection for SMO Decomposition Methods,"In the process of training Support Vector Machines (SVMs) by decomposition
methods, working set selection is an important technique, and some exciting
schemes were employed into this field. To improve working set selection, we
propose a new model for working set selection in sequential minimal
optimization (SMO) decomposition methods. In this model, it selects B as
working set without reselection. Some properties are given by simple proof, and
experiments demonstrate that the proposed method is in general faster than
existing methods.",2007-06-05T05:55:07Z,"Zhendong Zhao, Lei Yuan, Yuxuan Wang, Forrest Sheng Bao, Shunyi Zhang Yanfei Sun"
0707.0704v1,Model Selection Through Sparse Maximum Likelihood Estimation,"We consider the problem of estimating the parameters of a Gaussian or binary
distribution in such a way that the resulting undirected graphical model is
sparse. Our approach is to solve a maximum likelihood problem with an added
l_1-norm penalty term. The problem as formulated is convex but the memory
requirements and complexity of existing interior point methods are prohibitive
for problems with more than tens of nodes. We present two new algorithms for
solving problems with at least a thousand nodes in the Gaussian case. Our first
algorithm uses block coordinate descent, and can be interpreted as recursive
l_1-norm penalized regression. Our second algorithm, based on Nesterov's first
order method, yields a complexity estimate with a better dependence on problem
size than existing interior point methods. Using a log determinant relaxation
of the log partition function (Wainwright & Jordan (2006)), we show that these
same algorithms can be used to solve an approximate sparse maximum likelihood
problem for the binary case. We test our algorithms on synthetic data, as well
as on gene expression and senate voting records data.",2007-07-04T22:13:42Z,"Onureena Banerjee, Laurent El Ghaoui, Alexandre d'Aspremont"
0707.0705v4,Optimal Solutions for Sparse Principal Component Analysis,"Given a sample covariance matrix, we examine the problem of maximizing the
variance explained by a linear combination of the input variables while
constraining the number of nonzero coefficients in this combination. This is
known as sparse principal component analysis and has a wide array of
applications in machine learning and engineering. We formulate a new
semidefinite relaxation to this problem and derive a greedy algorithm that
computes a full set of good solutions for all target numbers of non zero
coefficients, with total complexity O(n^3), where n is the number of variables.
We then use the same relaxation to derive sufficient conditions for global
optimality of a solution, which can be tested in O(n^3) per pattern. We discuss
applications in subset selection and sparse recovery and show on artificial
examples and biological data that our algorithm does provide globally optimal
solutions in many cases.",2007-07-04T22:28:28Z,"Alexandre d'Aspremont, Francis Bach, Laurent El Ghaoui"
0707.1452v1,"Clusters, Graphs, and Networks for Analysing Internet-Web-Supported
  Communication within a Virtual Community","The proposal is to use clusters, graphs and networks as models in order to
analyse the Web structure. Clusters, graphs and networks provide knowledge
representation and organization. Clusters were generated by co-site analysis.
The sample is a set of academic Web sites from the countries belonging to the
European Union. These clusters are here revisited from the point of view of
graph theory and social network analysis. This is a quantitative and structural
analysis. In fact, the Internet is a computer network that connects people and
organizations. Thus we may consider it to be a social network. The set of Web
academic sites represents an empirical social network, and is viewed as a
virtual community. The network structural properties are here analysed applying
together cluster analysis, graph theory and social network analysis.",2007-07-10T13:47:32Z,Xavier Polanco
0709.3967v1,Classification of Images Using Support Vector Machines,"Support Vector Machines (SVMs) are a relatively new supervised classification
technique to the land cover mapping community. They have their roots in
Statistical Learning Theory and have gained prominence because they are robust,
accurate and are effective even when using a small training sample. By their
nature SVMs are essentially binary classifiers, however, they can be adopted to
handle the multiple classification tasks common in remote sensing studies. The
two approaches commonly used are the One-Against-One (1A1) and One-Against-All
(1AA) techniques. In this paper, these approaches are evaluated in as far as
their impact and implication for land cover mapping. The main finding from this
research is that whereas the 1AA technique is more predisposed to yielding
unclassified and mixed pixels, the resulting classification accuracy is not
significantly different from 1A1 approach. It is the authors conclusions that
ultimately the choice of technique adopted boils down to personal preference
and the uniqueness of the dataset at hand.",2007-09-25T14:37:40Z,"Gidudu Anthony, Hulley Greg, Marwala Tshilidzi"
0711.1814v1,"Building Rules on Top of Ontologies for the Semantic Web with Inductive
  Logic Programming","Building rules on top of ontologies is the ultimate goal of the logical layer
of the Semantic Web. To this aim an ad-hoc mark-up language for this layer is
currently under discussion. It is intended to follow the tradition of hybrid
knowledge representation and reasoning systems such as $\mathcal{AL}$-log that
integrates the description logic $\mathcal{ALC}$ and the function-free Horn
clausal language \textsc{Datalog}. In this paper we consider the problem of
automating the acquisition of these rules for the Semantic Web. We propose a
general framework for rule induction that adopts the methodological apparatus
of Inductive Logic Programming and relies on the expressive and deductive power
of $\mathcal{AL}$-log. The framework is valid whatever the scope of induction
(description vs. prediction) is. Yet, for illustrative purposes, we also
discuss an instantiation of the framework which aims at description and turns
out to be useful in Ontology Refinement.
  Keywords: Inductive Logic Programming, Hybrid Knowledge Representation and
Reasoning Systems, Ontologies, Semantic Web.
  Note: To appear in Theory and Practice of Logic Programming (TPLP)",2007-11-12T17:15:34Z,Francesca A. Lisi
0801.2069v2,Factored Value Iteration Converges,"In this paper we propose a novel algorithm, factored value iteration (FVI),
for the approximate solution of factored Markov decision processes (fMDPs). The
traditional approximate value iteration algorithm is modified in two ways. For
one, the least-squares projection operator is modified so that it does not
increase max-norm, and thus preserves convergence. The other modification is
that we uniformly sample polynomially many samples from the (exponentially
large) state space. This way, the complexity of our algorithm becomes
polynomial in the size of the fMDP description length. We prove that the
algorithm is convergent. We also derive an upper bound on the difference
between our approximate solution and the optimal one, and also on the error
introduced by sampling. We analyze various projection operators with respect to
their computation complexity and their convergence when combined with
approximate value iteration.",2008-01-14T13:09:06Z,"Istvan Szita, Andras Lorincz"
0803.3490v2,Robustness and Regularization of Support Vector Machines,"We consider regularized support vector machines (SVMs) and show that they are
precisely equivalent to a new robust optimization formulation. We show that
this equivalence of robust optimization and regularization has implications for
both algorithms, and analysis. In terms of algorithms, the equivalence suggests
more general SVM-like algorithms for classification that explicitly build in
protection to noise, and at the same time control overfitting. On the analysis
front, the equivalence of robustness and regularization, provides a robust
optimization interpretation for the success of regularized SVMs. We use the
this new robustness interpretation of SVMs to give a new proof of consistency
of (kernelized) SVMs, thus establishing robustness as the reason regularized
SVMs generalize well.",2008-03-25T03:51:59Z,"Huan Xu, Constantine Caramanis, Shie Mannor"
0804.0188v2,Support Vector Machine Classification with Indefinite Kernels,"We propose a method for support vector machine classification using
indefinite kernels. Instead of directly minimizing or stabilizing a nonconvex
loss function, our algorithm simultaneously computes support vectors and a
proxy kernel matrix used in forming the loss. This can be interpreted as a
penalized kernel learning problem where indefinite kernel matrices are treated
as a noisy observations of a true Mercer kernel. Our formulation keeps the
problem convex and relatively large problems can be solved efficiently using
the projected gradient or analytic center cutting plane methods. We compare the
performance of our technique with other methods on several classic data sets.",2008-04-01T14:55:33Z,"Ronny Luss, Alexandre d'Aspremont"
0804.0924v2,"A Unified Semi-Supervised Dimensionality Reduction Framework for
  Manifold Learning","We present a general framework of semi-supervised dimensionality reduction
for manifold learning which naturally generalizes existing supervised and
unsupervised learning frameworks which apply the spectral decomposition.
Algorithms derived under our framework are able to employ both labeled and
unlabeled examples and are able to handle complex problems where data form
separate clusters of manifolds. Our framework offers simple views, explains
relationships among existing frameworks and provides further extensions which
can improve existing algorithms. Furthermore, a new semi-supervised
kernelization framework called ``KPCA trick'' is proposed to handle non-linear
problems.",2008-04-06T18:14:34Z,"Ratthachat Chatpatanasiri, Boonserm Kijsirikul"
0804.1441v3,On Kernelization of Supervised Mahalanobis Distance Learners,"This paper focuses on the problem of kernelizing an existing supervised
Mahalanobis distance learner. The following features are included in the paper.
Firstly, three popular learners, namely, ""neighborhood component analysis"",
""large margin nearest neighbors"" and ""discriminant neighborhood embedding"",
which do not have kernel versions are kernelized in order to improve their
classification performances. Secondly, an alternative kernelization framework
called ""KPCA trick"" is presented. Implementing a learner in the new framework
gains several advantages over the standard framework, e.g. no mathematical
formulas and no reprogramming are required for a kernel implementation, the
framework avoids troublesome problems such as singularity, etc. Thirdly, while
the truths of representer theorems are just assumptions in previous papers
related to ours, here, representer theorems are formally proven. The proofs
validate both the kernel trick and the KPCA trick in the context of Mahalanobis
distance learning. Fourthly, unlike previous works which always apply brute
force methods to select a kernel, we investigate two approaches which can be
efficiently adopted to construct an appropriate kernel for a given dataset.
Finally, numerical results on various real-world datasets are presented.",2008-04-09T09:40:51Z,"Ratthachat Chatpatanasiri, Teesid Korsrilabutr, Pasakorn Tangchanachaianan, Boonserm Kijsirikul"
0805.2368v1,A Kernel Method for the Two-Sample Problem,"We propose a framework for analyzing and comparing distributions, allowing us
to design statistical tests to determine if two samples are drawn from
different distributions. Our test statistic is the largest difference in
expectations over functions in the unit ball of a reproducing kernel Hilbert
space (RKHS). We present two tests based on large deviation bounds for the test
statistic, while a third is based on the asymptotic distribution of this
statistic. The test statistic can be computed in quadratic time, although
efficient linear time approximations are available. Several classical metrics
on distributions are recovered when the function space used to compute the
difference in expectations is allowed to be more general (eg. a Banach space).
We apply our two-sample tests to a variety of problems, including attribute
matching for databases using the Hungarian marriage method, where they perform
strongly. Excellent performance is also obtained when comparing distributions
over graphs, for which these are the first such tests.",2008-05-15T17:46:53Z,"Arthur Gretton, Karsten Borgwardt, Malte J. Rasch, Bernhard Scholkopf, Alexander J. Smola"
0805.2891v2,Learning Low-Density Separators,"We define a novel, basic, unsupervised learning problem - learning the lowest
density homogeneous hyperplane separator of an unknown probability
distribution. This task is relevant to several problems in machine learning,
such as semi-supervised learning and clustering stability. We investigate the
question of existence of a universally consistent algorithm for this problem.
We propose two natural learning paradigms and prove that, on input unlabeled
random samples generated by any member of a rich family of distributions, they
are guaranteed to converge to the optimal separator for that distribution. We
complement this result by showing that no learning algorithm for our task can
achieve uniform learning rates (that are independent of the data generating
distribution).",2008-05-19T17:55:08Z,"Shai Ben-David, Tyler Lu, David Pal, Miroslava Sotakova"
0806.4341v1,On Sequences with Non-Learnable Subsequences,"The remarkable results of Foster and Vohra was a starting point for a series
of papers which show that any sequence of outcomes can be learned (with no
prior knowledge) using some universal randomized forecasting algorithm and
forecast-dependent checking rules. We show that for the class of all
computationally efficient outcome-forecast-based checking rules, this property
is violated. Moreover, we present a probabilistic algorithm generating with
probability close to one a sequence with a subsequence which simultaneously
miscalibrates all partially weakly computable randomized forecasting
algorithms. %subsequences non-learnable by each randomized algorithm.
  According to the Dawid's prequential framework we consider partial recursive
randomized algorithms.",2008-06-26T15:21:00Z,Vladimir V. V'yugin
0806.4391v1,Prediction with Expert Advice in Games with Unbounded One-Step Gains,"The games of prediction with expert advice are considered in this paper. We
present some modification of Kalai and Vempala algorithm of following the
perturbed leader for the case of unrestrictedly large one-step gains. We show
that in general case the cumulative gain of any probabilistic prediction
algorithm can be much worse than the gain of some expert of the pool.
Nevertheless, we give the lower bound for this cumulative gain in general case
and construct a universal algorithm which has the optimal performance; we also
prove that in case when one-step gains of experts of the pool have ``limited
deviations'' the performance of our algorithm is close to the performance of
the best expert.",2008-06-26T20:21:06Z,Vladimir V. V'yugin
0806.4484v2,On empirical meaning of randomness with respect to a real parameter,"We study the empirical meaning of randomness with respect to a family of
probability distributions $P_\theta$, where $\theta$ is a real parameter, using
algorithmic randomness theory. In the case when for a computable probability
distribution $P_\theta$ an effectively strongly consistent estimate exists, we
show that the Levin's a priory semicomputable semimeasure of the set of all
$P_\theta$-random sequences is positive if and only if the parameter $\theta$
is a computable real number. The different methods for generating
``meaningful'' $P_\theta$-random sequences with noncomputable $\theta$ are
discussed.",2008-06-27T10:49:33Z,Vladimir V'yugin
0806.4686v2,Sparse Online Learning via Truncated Gradient,"We propose a general method called truncated gradient to induce sparsity in
the weights of online learning algorithms with convex loss functions. This
method has several essential properties: The degree of sparsity is continuous
-- a parameter controls the rate of sparsification from no sparsification to
total sparsification. The approach is theoretically motivated, and an instance
of it can be regarded as an online counterpart of the popular
$L_1$-regularization method in the batch setting. We prove that small rates of
sparsification result in only small additional regret with respect to typical
online learning guarantees. The approach works well empirically. We apply the
approach to several datasets and find that for datasets with large numbers of
features, substantial sparsity is discoverable.",2008-06-28T14:19:50Z,"John Langford, Lihong Li, Tong Zhang"
0807.1997v4,Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples,"Multi-instance learning attempts to learn from a training set consisting of
labeled bags each containing many unlabeled instances. Previous studies
typically treat the instances in the bags as independently and identically
distributed. However, the instances in a bag are rarely independent, and
therefore a better performance can be expected if the instances are treated in
an non-i.i.d. way that exploits the relations among instances. In this paper,
we propose a simple yet effective multi-instance learning method, which regards
each bag as a graph and uses a specific kernel to distinguish the graphs by
considering the features of the nodes as well as the features of the edges that
convey some relations among instances. The effectiveness of the proposed method
is validated by experiments.",2008-07-12T20:19:18Z,"Zhi-Hua Zhou, Yu-Yin Sun, Yu-Feng Li"
0808.2984v1,"Building an interpretable fuzzy rule base from data using Orthogonal
  Least Squares Application to a depollution problem","In many fields where human understanding plays a crucial role, such as
bioprocesses, the capacity of extracting knowledge from data is of critical
importance. Within this framework, fuzzy learning methods, if properly used,
can greatly help human experts. Amongst these methods, the aim of orthogonal
transformations, which have been proven to be mathematically robust, is to
build rules from a set of training data and to select the most important ones
by linear regression or rank revealing techniques. The OLS algorithm is a good
representative of those methods. However, it was originally designed so that it
only cared about numerical performance. Thus, we propose some modifications of
the original method to take interpretability into account. After recalling the
original algorithm, this paper presents the changes made to the original
method, then discusses some results obtained from benchmark problems. Finally,
the algorithm is applied to a real-world fault detection depollution problem.",2008-08-21T19:54:04Z,"Sbastien Destercke, Serge Guillaume, Brigitte Charnomordic"
0808.3231v4,Multi-Instance Multi-Label Learning,"In this paper, we propose the MIML (Multi-Instance Multi-Label learning)
framework where an example is described by multiple instances and associated
with multiple class labels. Compared to traditional learning frameworks, the
MIML framework is more convenient and natural for representing complicated
objects which have multiple semantic meanings. To learn from MIML examples, we
propose the MimlBoost and MimlSvm algorithms based on a simple degeneration
strategy, and experiments show that solving problems involving complicated
objects with multiple semantic meanings in the MIML framework can lead to good
performance. Considering that the degeneration process may lose information, we
propose the D-MimlSvm algorithm which tackles MIML problems directly in a
regularization framework. Moreover, we show that even when we do not have
access to the real objects and thus cannot capture more information from real
objects by using the MIML representation, MIML is still useful. We propose the
InsDif and SubCod algorithms. InsDif works by transforming single-instances
into the MIML representation for learning, while SubCod works by transforming
single-label examples into the MIML representation for learning. Experiments
show that in some tasks they are able to achieve better performance than
learning the single-instances or single-label examples directly.",2008-08-24T06:31:43Z,"Zhi-Hua Zhou, Min-Ling Zhang, Sheng-Jun Huang, Yu-Feng Li"
0809.2792v3,Predicting Abnormal Returns From News Using Text Classification,"We show how text from news articles can be used to predict intraday price
movements of financial assets using support vector machines. Multiple kernel
learning is used to combine equity returns with text as predictive features to
increase classification performance and we develop an analytic center cutting
plane method to solve the kernel learning problem efficiently. We observe that
while the direction of returns is not predictable using either text or returns,
their size is, with text features producing significantly better performance
than historical returns alone.",2008-09-16T20:05:00Z,"Ronny Luss, Alexandre d'Aspremont"
0811.4413v6,A Spectral Algorithm for Learning Hidden Markov Models,"Hidden Markov Models (HMMs) are one of the most fundamental and widely used
statistical tools for modeling discrete time series. In general, learning HMMs
from data is computationally hard (under cryptographic assumptions), and
practitioners typically resort to search heuristics which suffer from the usual
local optima issues. We prove that under a natural separation condition (bounds
on the smallest singular value of the HMM parameters), there is an efficient
and provably correct algorithm for learning HMMs. The sample complexity of the
algorithm does not explicitly depend on the number of distinct (discrete)
observations---it implicitly depends on this quantity through spectral
properties of the underlying HMM. This makes the algorithm particularly
applicable to settings with a large number of observations, such as those in
natural language processing where the space of observation is sometimes the
words in a language. The algorithm is also simple, employing only a singular
value decomposition and matrix multiplications.",2008-11-26T20:22:51Z,"Daniel Hsu, Sham M. Kakade, Tong Zhang"
0811.4458v2,Learning Class-Level Bayes Nets for Relational Data,"Many databases store data in relational format, with different types of
entities and information about links between the entities. The field of
statistical-relational learning (SRL) has developed a number of new statistical
models for such data. In this paper we focus on learning class-level or
first-order dependencies, which model the general database statistics over
attributes of linked objects and links (e.g., the percentage of A grades given
in computer science classes). Class-level statistical relationships are
important in themselves, and they support applications like policy making,
strategic planning, and query optimization. Most current SRL methods find
class-level dependencies, but their main task is to support instance-level
predictions about the attributes or links of specific entities. We focus only
on class-level prediction, and describe algorithms for learning class-level
models that are orders of magnitude faster for this task. Our algorithms learn
Bayes nets with relational structure, leveraging the efficiency of single-table
nonrelational Bayes net learners. An evaluation of our methods on three data
sets shows that they are computationally feasible for realistic table sizes,
and that the learned structures represent the statistical information in the
databases well. After learning compiles the database statistics into a Bayes
net, querying these statistics via Bayes net inference is faster than with SQL
queries, and does not depend on the size of the database.",2008-11-27T01:02:33Z,"Oliver Schulte, Hassan Khosravi, Flavia Moser, Martin Ester"
0812.4044v3,The Offset Tree for Learning with Partial Labels,"We present an algorithm, called the Offset Tree, for learning to make
decisions in situations where the payoff of only one choice is observed, rather
than all choices. The algorithm reduces this setting to binary classification,
allowing one to reuse of any existing, fully supervised binary classification
algorithm in this partial information setting. We show that the Offset Tree is
an optimal reduction to binary classification. In particular, it has regret at
most $(k-1)$ times the regret of the binary classifier it uses (where $k$ is
the number of choices), and no reduction to binary classification can do
better. This reduction is also computationally optimal, both at training and
test time, requiring just $O(\log_2 k)$ work to train on an example or make a
prediction.
  Experiments with the Offset Tree show that it generally performs better than
several alternative approaches.",2008-12-21T17:45:27Z,"Alina Beygelzimer, John Langford"
0812.4235v2,Client-server multi-task learning from distributed datasets,"A client-server architecture to simultaneously solve multiple learning tasks
from distributed datasets is described. In such architecture, each client is
associated with an individual learning task and the associated dataset of
examples. The goal of the architecture is to perform information fusion from
multiple datasets while preserving privacy of individual data. The role of the
server is to collect data in real-time from the clients and codify the
information in a common database. The information coded in this database can be
used by all the clients to solve their individual learning task, so that each
client can exploit the informative content of all the datasets without actually
having access to private data of others. The proposed algorithmic framework,
based on regularization theory and kernel methods, uses a suitable class of
mixed effect kernels. The new method is illustrated through a simulated music
recommendation system.",2008-12-22T16:34:39Z,"Francesco Dinuzzo, Gianluigi Pillonetto, Giuseppe De Nicolao"
0902.1227v2,Discovering general partial orders in event streams,"Frequent episode discovery is a popular framework for pattern discovery in
event streams. An episode is a partially ordered set of nodes with each node
associated with an event type. Efficient (and separate) algorithms exist for
episode discovery when the associated partial order is total (serial episode)
and trivial (parallel episode). In this paper, we propose efficient algorithms
for discovering frequent episodes with general partial orders. These algorithms
can be easily specialized to discover serial or parallel episodes. Also, the
algorithms are flexible enough to be specialized for mining in the space of
certain interesting subclasses of partial orders. We point out that there is an
inherent combinatorial explosion in frequent partial order mining and most
importantly, frequency alone is not a sufficient measure of interestingness. We
propose a new interestingness measure for general partial order episodes and a
discovery method based on this measure, for filtering out uninteresting partial
orders. Simulations demonstrate the effectiveness of our algorithms.",2009-02-07T07:50:02Z,"Avinash Achar, Srivatsan Laxman, Raajay Viswanathan, P. S. Sastry"
0902.3176v4,Error-Correcting Tournaments,"We present a family of pairwise tournaments reducing $k$-class classification
to binary classification. These reductions are provably robust against a
constant fraction of binary errors. The results improve on the PECOC
construction \cite{SECOC} with an exponential improvement in computation, from
$O(k)$ to $O(\log_2 k)$, and the removal of a square root in the regret
dependence, matching the best possible computation and regret up to a constant.",2009-02-18T16:01:24Z,"Alina Beygelzimer, John Langford, Pradeep Ravikumar"
0902.3430v3,Domain Adaptation: Learning Bounds and Algorithms,"This paper addresses the general problem of domain adaptation which arises in
a variety of applications where the distribution of the labeled sample
available somewhat differs from that of the test data. Building on previous
work by Ben-David et al. (2007), we introduce a novel distance between
distributions, discrepancy distance, that is tailored to adaptation problems
with arbitrary loss functions. We give Rademacher complexity bounds for
estimating the discrepancy distance from finite samples for different loss
functions. Using this distance, we derive novel generalization bounds for
domain adaptation for a wide family of loss functions. We also present a series
of novel adaptation bounds for large classes of regularization-based
algorithms, including support vector machines and kernel ridge regression based
on the empirical discrepancy. This motivates our analysis of the problem of
minimizing the empirical discrepancy for various loss functions for which we
also give novel algorithms. We report the results of preliminary experiments
that demonstrate the benefits of our discrepancy minimization algorithms for
domain adaptation.",2009-02-19T18:42:16Z,"Yishay Mansour, Mehryar Mohri, Afshin Rostamizadeh"
0903.2851v2,A parameter-free hedging algorithm,"We study the problem of decision-theoretic online learning (DTOL). Motivated
by practical applications, we focus on DTOL when the number of actions is very
large. Previous algorithms for learning in this framework have a tunable
learning rate parameter, and a barrier to using online-learning in practical
applications is that it is not understood how to set this parameter optimally,
particularly when the number of actions is large.
  In this paper, we offer a clean solution by proposing a novel and completely
parameter-free algorithm for DTOL. We introduce a new notion of regret, which
is more natural for applications with a large number of actions. We show that
our algorithm achieves good performance with respect to this new notion of
regret; in addition, it also achieves performance close to that of the best
bounds achieved by previous algorithms with optimally-tuned parameters,
according to previous notions of regret.",2009-03-16T20:48:33Z,"Kamalika Chaudhuri, Yoav Freund, Daniel Hsu"
0903.2972v3,Optimistic Simulated Exploration as an Incentive for Real Exploration,"Many reinforcement learning exploration techniques are overly optimistic and
try to explore every state. Such exploration is impossible in environments with
the unlimited number of states. I propose to use simulated exploration with an
optimistic model to discover promising paths for real exploration. This reduces
the needs for the real exploration.",2009-03-17T14:24:13Z,Ivo Danihelka
0903.4217v2,Conditional Probability Tree Estimation Analysis and Algorithms,"We consider the problem of estimating the conditional probability of a label
in time $O(\log n)$, where $n$ is the number of possible labels. We analyze a
natural reduction of this problem to a set of binary regression problems
organized in a tree structure, proving a regret bound that scales with the
depth of the tree. Motivated by this analysis, we propose the first online
algorithm which provably constructs a logarithmic depth tree on the set of
labels to solve this problem. We test the algorithm empirically, showing that
it works succesfully on a dataset with roughly $10^6$ labels.",2009-03-25T00:28:44Z,"Alina Beygelzimer, John Langford, Yuri Lifshits, Gregory Sorkin, Alex Strehl"
0904.0643v1,Performing Nonlinear Blind Source Separation with Signal Invariants,"Given a time series of multicomponent measurements x(t), the usual objective
of nonlinear blind source separation (BSS) is to find a ""source"" time series
s(t), comprised of statistically independent combinations of the measured
components. In this paper, the source time series is required to have a density
function in (s,ds/dt)-space that is equal to the product of density functions
of individual components. This formulation of the BSS problem has a solution
that is unique, up to permutations and component-wise transformations.
Separability is shown to impose constraints on certain locally invariant
(scalar) functions of x, which are derived from local higher-order correlations
of the data's velocity dx/dt. The data are separable if and only if they
satisfy these constraints, and, if the constraints are satisfied, the sources
can be explicitly constructed from the data. The method is illustrated by using
it to separate two speech-like sounds recorded with a single microphone.",2009-04-03T19:29:47Z,David N. Levin
0904.1579v1,Online prediction of ovarian cancer,"In this paper we apply computer learning methods to diagnosing ovarian cancer
using the level of the standard biomarker CA125 in conjunction with information
provided by mass-spectrometry. We are working with a new data set collected
over a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,
our algorithm gives probability predictions for the disease. To estimate
classification accuracy we convert probability predictions into strict
predictions. Our algorithm makes fewer errors than almost any linear
combination of the CA125 level and one peak's intensity (taken on the log
scale). To check the power of our algorithm we use it to test the hypothesis
that CA125 and the peaks do not contain useful information for the prediction
of the disease at a particular time before the diagnosis. Our algorithm
produces $p$-values that are better than those produced by the algorithm that
has been previously applied to this data set. Our conclusion is that the
proposed algorithm is more reliable for prediction on new data.",2009-04-09T18:26:36Z,"Fedor Zhdanov, Vladimir Vovk, Brian Burford, Dmitry Devetyarov, Ilia Nouretdinov, Alex Gammerman"
0904.2595v1,A Methodology for Learning Players' Styles from Game Records,"We describe a preliminary investigation into learning a Chess player's style
from game records. The method is based on attempting to learn features of a
player's individual evaluation function using the method of temporal
differences, with the aid of a conventional Chess engine architecture. Some
encouraging results were obtained in learning the styles of two recent Chess
world champions, and we report on our attempt to use the learnt styles to
discriminate between the players from game records by trying to detect who was
playing white and who was playing black. We also discuss some limitations of
our approach and propose possible directions for future research. The method we
have presented may also be applicable to other strategic games, and may even be
generalisable to other domains where sequences of agents' actions are recorded.",2009-04-16T21:30:30Z,"Mark Levene, Trevor Fenner"
0904.2623v2,Exponential Family Graph Matching and Ranking,"We present a method for learning max-weight matching predictors in bipartite
graphs. The method consists of performing maximum a posteriori estimation in
exponential families with sufficient statistics that encode permutations and
data features. Although inference is in general hard, we show that for one very
relevant application - web page ranking - exact inference is efficient. For
general model instances, an appropriate sampler is readily available. Contrary
to existing max-margin matching models, our approach is statistically
consistent and, in addition, experiments with increasing sample sizes indicate
superior improvement over such models. We apply the method to graph matching in
computer vision as well as to a standard benchmark dataset for learning web
page ranking, in which we obtain state-of-the-art results, in particular
improving on max-margin variants. The drawback of this method with respect to
max-margin alternatives is its runtime for large graphs, which is comparatively
high.",2009-04-17T03:48:02Z,"James Petterson, Tiberio Caetano, Julian McAuley, Jin Yu"
0904.3352v1,"Optimistic Initialization and Greediness Lead to Polynomial Time
  Learning in Factored MDPs - Extended Version","In this paper we propose an algorithm for polynomial-time reinforcement
learning in factored Markov decision processes (FMDPs). The factored optimistic
initial model (FOIM) algorithm, maintains an empirical model of the FMDP in a
conventional way, and always follows a greedy policy with respect to its model.
The only trick of the algorithm is that the model is initialized
optimistically. We prove that with suitable initialization (i) FOIM converges
to the fixed point of approximate value iteration (AVI); (ii) the number of
steps when the agent makes non-near-optimal decisions (with respect to the
solution of AVI) is polynomial in all relevant quantities; (iii) the per-step
costs of the algorithm are also polynomial. To our best knowledge, FOIM is the
first algorithm with these properties. This extended version contains the
rigorous proofs of the main theorem. A version of this paper appeared in
ICML'09.",2009-04-21T22:07:24Z,"Istvan Szita, Andras Lorincz"
0904.3667v1,Considerations upon the Machine Learning Technologies,"Artificial intelligence offers superior techniques and methods by which
problems from diverse domains may find an optimal solution. The Machine
Learning technologies refer to the domain of artificial intelligence aiming to
develop the techniques allowing the computers to ""learn"". Some systems based on
Machine Learning technologies tend to eliminate the necessity of the human
intelligence while the others adopt a man-machine collaborative approach.",2009-04-23T11:48:38Z,"Alin Munteanu, Cristina Ofelia Sofran"
0905.3369v2,Learning Nonlinear Dynamic Models,"We present a novel approach for learning nonlinear dynamic models, which
leads to a new set of tools capable of solving problems that are otherwise
difficult. We provide theory showing this new approach is consistent for models
with long range structure, and apply the approach to motion capture and
high-dimensional video data, yielding results superior to standard
alternatives.",2009-05-20T18:08:18Z,"John Langford, Ruslan Salakhutdinov, Tong Zhang"
0906.0052v1,A Minimum Description Length Approach to Multitask Feature Selection,"Many regression problems involve not one but several response variables
(y's). Often the responses are suspected to share a common underlying
structure, in which case it may be advantageous to share information across
them; this is known as multitask learning. As a special case, we can use
multiple responses to better identify shared predictive features -- a project
we might call multitask feature selection.
  This thesis is organized as follows. Section 1 introduces feature selection
for regression, focusing on ell_0 regularization methods and their
interpretation within a Minimum Description Length (MDL) framework. Section 2
proposes a novel extension of MDL feature selection to the multitask setting.
The approach, called the ""Multiple Inclusion Criterion"" (MIC), is designed to
borrow information across regression tasks by more easily selecting features
that are associated with multiple responses. We show in experiments on
synthetic and real biological data sets that MIC can reduce prediction error in
settings where features are at least partially shared across responses. Section
3 surveys hypothesis testing by regression with a single response, focusing on
the parallel between the standard Bonferroni correction and an MDL approach.
Mirroring the ideas in Section 2, Section 4 proposes a novel MIC approach to
hypothesis testing with multiple responses and shows that on synthetic data
with significant sharing of features across responses, MIC sometimes
outperforms standard FDR-controlling methods in terms of finding true positives
for a given level of false positives. Section 5 concludes.",2009-05-30T03:41:37Z,Brian Tomasik
0906.1814v1,Large-Margin kNN Classification Using a Deep Encoder Network,"KNN is one of the most popular classification methods, but it often fails to
work well with inappropriate choice of distance metric or due to the presence
of numerous class-irrelevant features. Linear feature transformation methods
have been widely applied to extract class-relevant information to improve kNN
classification, which is very limited in many applications. Kernels have been
used to learn powerful non-linear feature transformations, but these methods
fail to scale to large datasets. In this paper, we present a scalable
non-linear feature mapping method based on a deep neural network pretrained
with restricted boltzmann machines for improving kNN classification in a
large-margin framework, which we call DNet-kNN. DNet-kNN can be used for both
classification and for supervised dimensionality reduction. The experimental
results on two benchmark handwritten digit datasets show that DNet-kNN has much
better performance than large-margin kNN using a linear mapping and kNN based
on a deep autoencoder pretrained with retricted boltzmann machines.",2009-06-09T20:06:45Z,"Martin Renqiang Min, David A. Stanley, Zineng Yuan, Anthony Bonner, Zhaolei Zhang"
0908.4144v1,ABC-LogitBoost for Multi-class Classification,"We develop abc-logitboost, based on the prior work on abc-boost and robust
logitboost. Our extensive experiments on a variety of datasets demonstrate the
considerable improvement of abc-logitboost over logitboost and abc-mart.",2009-08-28T07:09:19Z,Ping Li
0909.2934v1,A Convergent Online Single Time Scale Actor Critic Algorithm,"Actor-Critic based approaches were among the first to address reinforcement
learning in a general setting. Recently, these algorithms have gained renewed
interest due to their generality, good convergence properties, and possible
biological relevance. In this paper, we introduce an online temporal difference
based actor-critic algorithm which is proved to converge to a neighborhood of a
local maximum of the average reward. Linear function approximation is used by
the critic in order estimate the value function, and the temporal difference
signal, which is passed from the critic to the actor. The main distinguishing
feature of the present convergence proof is that both the actor and the critic
operate on a similar time scale, while in most current convergence proofs they
are required to have very different time scales in order to converge. Moreover,
the same temporal difference signal is used to update the parameters of both
the actor and the critic. A limitation of the proposed approach, compared to
results available for two time scale convergence, is that convergence is
guaranteed only to a neighborhood of an optimal value, rather to an optimal
value itself. The single time scale and identical temporal difference signal
used by the actor and the critic, may provide a step towards constructing more
biologically realistic models of reinforcement learning in the brain.",2009-09-16T07:08:44Z,"D. Di Castro, R. Meir"
0909.3593v2,Exploiting Unlabeled Data to Enhance Ensemble Diversity,"Ensemble learning aims to improve generalization ability by using multiple
base learners. It is well-known that to construct a good ensemble, the base
learners should be accurate as well as diverse. In this paper, unlabeled data
is exploited to facilitate ensemble learning by helping augment the diversity
among the base learners. Specifically, a semi-supervised ensemble method named
UDEED is proposed. Unlike existing semi-supervised ensemble methods where
error-prone pseudo-labels are estimated for unlabeled data to enlarge the
labeled data to improve accuracy, UDEED works by maximizing accuracies of base
learners on labeled data while maximizing diversity among them on unlabeled
data. Experiments show that UDEED can effectively utilize unlabeled data for
ensemble learning and is highly competitive to well-established semi-supervised
ensemble methods.",2009-09-19T16:10:19Z,"Min-Ling Zhang, Zhi-Hua Zhou"
0910.0902v3,Reduced-Rank Hidden Markov Models,"We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization
of HMMs that can model smooth state evolution as in Linear Dynamical Systems
(LDSs) as well as non-log-concave predictive distributions as in
continuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n
discrete observations, with a transition matrix of rank k <= m. This implies
the dynamics evolve in a k-dimensional subspace, while the shape of the set of
predictive distributions is determined by m. Latent state belief is represented
with a k-dimensional state vector and inference is carried out entirely in R^k,
making RR-HMMs as computationally efficient as k-state HMMs yet more
expressive. To learn RR-HMMs, we relax the assumptions of a recently proposed
spectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it
to learn k-dimensional observable representations of rank-k RR-HMMs. The
algorithm is consistent and free of local optima, and we extend its performance
guarantees to cover the RR-HMM case. We show how this algorithm can be used in
conjunction with a kernel density estimator to efficiently model
high-dimensional multivariate continuous data. We also relax the assumption
that single observations are sufficient to disambiguate state, and extend the
algorithm accordingly. Experiments on synthetic data and a toy video, as well
as on a difficult robot vision modeling problem, yield accurate models that
compare favorably with standard alternatives in simulation quality and
prediction capability.",2009-10-06T06:00:47Z,"Sajid M. Siddiqi, Byron Boots, Geoffrey J. Gordon"
0911.0460v2,Feature-Weighted Linear Stacking,"Ensemble methods, such as stacking, are designed to boost predictive accuracy
by blending the predictions of multiple machine learning models. Recent work
has shown that the use of meta-features, additional inputs describing each
example in a dataset, can boost the performance of ensemble methods, but the
greatest reported gains have come from nonlinear procedures requiring
significant tuning and training time. Here, we present a linear technique,
Feature-Weighted Linear Stacking (FWLS), that incorporates meta-features for
improved accuracy while retaining the well-known virtues of linear regression
regarding speed, stability, and interpretability. FWLS combines model
predictions linearly using coefficients that are themselves linear functions of
meta-features. This technique was a key facet of the solution of the second
place team in the recently concluded Netflix Prize competition. Significant
increases in accuracy over standard linear stacking are demonstrated on the
Netflix Prize collaborative filtering dataset.",2009-11-03T08:17:05Z,"Joseph Sill, Gabor Takacs, Lester Mackey, David Lin"
0911.1386v1,Machine Learning: When and Where the Horses Went Astray?,"Machine Learning is usually defined as a subfield of AI, which is busy with
information extraction from raw data sets. Despite of its common acceptance and
widespread recognition, this definition is wrong and groundless. Meaningful
information does not belong to the data that bear it. It belongs to the
observers of the data and it is a shared agreement and a convention among them.
Therefore, this private information cannot be extracted from the data by any
means. Therefore, all further attempts of Machine Learning apologists to
justify their funny business are inappropriate.",2009-11-07T02:52:53Z,Emanuel Diamant
0911.5104v2,A Bayesian Rule for Adaptive Control based on Causal Interventions,"Explaining adaptive behavior is a central problem in artificial intelligence
research. Here we formalize adaptive agents as mixture distributions over
sequences of inputs and outputs (I/O). Each distribution of the mixture
constitutes a `possible world', but the agent does not know which of the
possible worlds it is actually facing. The problem is to adapt the I/O stream
in a way that is compatible with the true world. A natural measure of
adaptation can be obtained by the Kullback-Leibler (KL) divergence between the
I/O distribution of the true world and the I/O distribution expected by the
agent that is uncertain about possible worlds. In the case of pure input
streams, the Bayesian mixture provides a well-known solution for this problem.
We show, however, that in the case of I/O streams this solution breaks down,
because outputs are issued by the agent itself and require a different
probabilistic syntax as provided by intervention calculus. Based on this
calculus, we obtain a Bayesian control rule that allows modeling adaptive
behavior with mixture distributions over I/O streams. This rule might allow for
a novel approach to adaptive control based on a minimum KL-principle.",2009-11-26T15:52:33Z,"Pedro A. Ortega, Daniel A. Braun"
0912.2385v1,Closing the Learning-Planning Loop with Predictive State Representations,"A central problem in artificial intelligence is that of planning to maximize
future reward under uncertainty in a partially observable environment. In this
paper we propose and demonstrate a novel algorithm which accurately learns a
model of such an environment directly from sequences of action-observation
pairs. We then close the loop from observations to actions by planning in the
learned model and recovering a policy which is near-optimal in the original
environment. Specifically, we present an efficient and statistically consistent
spectral algorithm for learning the parameters of a Predictive State
Representation (PSR). We demonstrate the algorithm by learning a model of a
simulated high-dimensional, vision-based mobile robot planning task, and then
perform approximate point-based planning in the learned PSR. Analysis of our
results shows that the algorithm learns a state space which efficiently
captures the essential features of the environment. This representation allows
accurate prediction with a small number of parameters, and enables successful
and efficient planning.",2009-12-12T00:59:26Z,"Byron Boots, Sajid M. Siddiqi, Geoffrey J. Gordon"
0912.4473v2,Learning to Predict Combinatorial Structures,"The major challenge in designing a discriminative learning algorithm for
predicting structured data is to address the computational issues arising from
the exponential size of the output space. Existing algorithms make different
assumptions to ensure efficient, polynomial time estimation of model
parameters. For several combinatorial structures, including cycles, partially
ordered sets, permutations and other graph classes, these assumptions do not
hold. In this thesis, we address the problem of designing learning algorithms
for predicting combinatorial structures by introducing two new assumptions: (i)
The first assumption is that a particular counting problem can be solved
efficiently. The consequence is a generalisation of the classical ridge
regression for structured prediction. (ii) The second assumption is that a
particular sampling problem can be solved efficiently. The consequence is a new
technique for designing and analysing probabilistic structured prediction
models. These results can be applied to solve several complex learning problems
including but not limited to multi-label classification, multi-category
hierarchical classification, and label ranking.",2009-12-22T18:03:55Z,Shankar Vembu
0912.5029v1,"Complexity of stochastic branch and bound methods for belief tree search
  in Bayesian reinforcement learning","There has been a lot of recent work on Bayesian methods for reinforcement
learning exhibiting near-optimal online performance. The main obstacle facing
such methods is that in most problems of interest, the optimal solution
involves planning in an infinitely large tree. However, it is possible to
obtain stochastic lower and upper bounds on the value of each tree node. This
enables us to use stochastic branch and bound algorithms to search the tree
efficiently. This paper proposes two such algorithms and examines their
complexity in this setting.",2009-12-26T16:32:46Z,Christos Dimitrakakis
1001.2709v1,Kernel machines with two layers and multiple kernel learning,"In this paper, the framework of kernel machines with two layers is
introduced, generalizing classical kernel methods. The new learning methodology
provide a formal connection between computational architectures with multiple
layers and the theme of kernel learning in standard regularization methods.
First, a representer theorem for two-layer networks is presented, showing that
finite linear combinations of kernels on each layer are optimal architectures
whenever the corresponding functions solve suitable variational problems in
reproducing kernel Hilbert spaces (RKHS). The input-output map expressed by
these architectures turns out to be equivalent to a suitable single-layer
kernel machines in which the kernel function is also learned from the data.
Recently, the so-called multiple kernel learning methods have attracted
considerable attention in the machine learning literature. In this paper,
multiple kernel learning methods are shown to be specific cases of kernel
machines with two layers in which the second layer is linear. Finally, a simple
and effective multiple kernel learning method called RLS2 (regularized least
squares with two layers) is introduced, and his performances on several
learning problems are extensively analyzed. An open source MATLAB toolbox to
train and validate RLS2 models with a Graphic User Interface is available.",2010-01-15T15:10:39Z,Francesco Dinuzzo
1002.3086v1,Convergence of Bayesian Control Rule,"Recently, new approaches to adaptive control have sought to reformulate the
problem as a minimization of a relative entropy criterion to obtain tractable
solutions. In particular, it has been shown that minimizing the expected
deviation from the causal input-output dependencies of the true plant leads to
a new promising stochastic control rule called the Bayesian control rule. This
work proves the convergence of the Bayesian control rule under two sufficient
assumptions: boundedness, which is an ergodicity condition; and consistency,
which is an instantiation of the sure-thing principle.",2010-02-16T14:14:59Z,"Pedro A. Ortega, Daniel A. Braun"
1002.3174v3,A new approach to content-based file type detection,"File type identification and file type clustering may be difficult tasks that
have an increasingly importance in the field of computer and network security.
Classical methods of file type detection including considering file extensions
and magic bytes can be easily spoofed. Content-based file type detection is a
newer way that is taken into account recently. In this paper, a new
content-based method for the purpose of file type detection and file type
clustering is proposed that is based on the PCA and neural networks. The
proposed method has a good accuracy and is fast enough.",2010-02-17T10:18:07Z,"M. C. Amirani, M. Toorani, A. A. Beheshti"
1002.4862v1,Less Regret via Online Conditioning,"We analyze and evaluate an online gradient descent algorithm with adaptive
per-coordinate adjustment of learning rates. Our algorithm can be thought of as
an online version of batch gradient descent with a diagonal preconditioner.
This approach leads to regret bounds that are stronger than those of standard
online gradient descent for general online convex optimization problems.
Experimentally, we show that our algorithm is competitive with state-of-the-art
algorithms for large scale machine learning problems.",2010-02-25T20:31:05Z,"Matthew Streeter, H. Brendan McMahan"
1003.0034v1,A New Understanding of Prediction Markets Via No-Regret Learning,"We explore the striking mathematical connections that exist between market
scoring rules, cost function based prediction markets, and no-regret learning.
We show that any cost function based prediction market can be interpreted as an
algorithm for the commonly studied problem of learning from expert advice by
equating trades made in the market with losses observed by the learning
algorithm. If the loss of the market organizer is bounded, this bound can be
used to derive an O(sqrt(T)) regret bound for the corresponding learning
algorithm. We then show that the class of markets with convex cost functions
exactly corresponds to the class of Follow the Regularized Leader learning
algorithms, with the choice of a cost function in the market corresponding to
the choice of a regularizer in the learning problem. Finally, we show an
equivalence between market scoring rules and prediction markets with convex
cost functions. This implies that market scoring rules can also be interpreted
naturally as Follow the Regularized Leader algorithms, and may be of
independent interest. These connections provide new insight into how it is that
commonly studied markets, such as the Logarithmic Market Scoring Rule, can
aggregate opinions into accurate estimates of the likelihood of future events.",2010-02-26T23:27:22Z,"Yiling Chen, Jennifer Wortman Vaughan"
1003.0120v2,Learning from Logged Implicit Exploration Data,"We provide a sound and consistent foundation for the use of \emph{nonrandom}
exploration data in ""contextual bandit"" or ""partially labeled"" settings where
only the value of a chosen action is learned.
  The primary challenge in a variety of settings is that the exploration
policy, in which ""offline"" data is logged, is not explicitly known. Prior
solutions here require either control of the actions during the learning
process, recorded random exploration, or actions chosen obliviously in a
repeated manner. The techniques reported here lift these restrictions, allowing
the learning of a policy for choosing actions given features from historical
data where no randomization occurred or was logged.
  We empirically verify our solution on two reasonably sized sets of real-world
data obtained from Yahoo!.",2010-02-27T17:53:46Z,"Alex Strehl, John Langford, Sham Kakade, Lihong Li"
1004.1230v1,"Ontology-supported processing of clinical text using medical knowledge
  integration for multi-label classification of diagnosis coding","This paper discusses the knowledge integration of clinical information
extracted from distributed medical ontology in order to ameliorate a machine
learning-based multi-label coding assignment system. The proposed approach is
implemented using a decision tree based cascade hierarchical technique on the
university hospital data for patients with Coronary Heart Disease (CHD). The
preliminary results obtained show a satisfactory finding.",2010-04-08T03:06:24Z,"Phanu Waraporn, Phayung Meesad, Gareth Clayton"
1005.0125v1,Adaptive Bases for Reinforcement Learning,"We consider the problem of reinforcement learning using function
approximation, where the approximating basis can change dynamically while
interacting with the environment. A motivation for such an approach is
maximizing the value function fitness to the problem faced. Three errors are
considered: approximation square error, Bellman residual, and projected Bellman
residual. Algorithms under the actor-critic framework are presented, and shown
to converge. The advantage of such an adaptive basis is demonstrated in
simulations.",2010-05-02T06:40:21Z,"Dotan Di Castro, Shie Mannor"
1006.2899v2,"Approximated Structured Prediction for Learning Large Scale Graphical
  Models","This manuscripts contains the proofs for ""A Primal-Dual Message-Passing
Algorithm for Approximated Large Scale Structured Prediction"".",2010-06-15T06:55:03Z,"Tamir Hazan, Raquel Urtasun"
1006.4039v3,"Distributed Autonomous Online Learning: Regrets and Intrinsic
  Privacy-Preserving Properties","Online learning has become increasingly popular on handling massive data. The
sequential nature of online learning, however, requires a centralized learner
to store data and update parameters. In this paper, we consider online learning
with {\em distributed} data sources. The autonomous learners update local
parameters based on local data sources and periodically exchange information
with a small subset of neighbors in a communication network. We derive the
regret bound for strongly convex functions that generalizes the work by Ram et
al. (2010) for convex functions. Most importantly, we show that our algorithm
has \emph{intrinsic} privacy-preserving properties, and we prove the sufficient
and necessary conditions for privacy preservation in the network. These
conditions imply that for networks with greater-than-one connectivity, a
malicious learner cannot reconstruct the subgradients (and sensitive raw data)
of other learners, which makes our algorithm appealing in privacy sensitive
applications.",2010-06-21T11:30:06Z,"Feng Yan, Shreyas Sundaram, S. V. N. Vishwanathan, Yuan Qi"
1006.5188v1,Feature Construction for Relational Sequence Learning,"We tackle the problem of multi-class relational sequence learning using
relevant patterns discovered from a set of labelled sequences. To deal with
this problem, firstly each relational sequence is mapped into a feature vector
using the result of a feature construction method. Since, the efficacy of
sequence learning algorithms strongly depends on the features used to represent
the sequences, the second step is to find an optimal subset of the constructed
features leading to high classification accuracy. This feature selection task
has been solved adopting a wrapper approach that uses a stochastic local search
algorithm embedding a naive Bayes classifier. The performance of the proposed
method applied to a real-world dataset shows an improvement when compared to
other established methods, such as hidden Markov models, Fisher kernels and
conditional random fields for relational sequences.",2010-06-27T08:56:11Z,"Nicola Di Mauro, Teresa M. A. Basile, Stefano Ferilli, Floriana Esposito"
1007.2449v1,A Brief Introduction to Temporality and Causality,"Causality is a non-obvious concept that is often considered to be related to
temporality. In this paper we present a number of past and present approaches
to the definition of temporality and causality from philosophical, physical,
and computational points of view. We note that time is an important ingredient
in many relationships and phenomena. The topic is then divided into the two
main areas of temporal discovery, which is concerned with finding relations
that are stretched over time, and causal discovery, where a claim is made as to
the causal influence of certain events on others. We present a number of
computational tools used for attempting to automatically discover temporal and
causal relations in data.",2010-07-14T22:41:30Z,Kamran Karimi
1008.1566v5,"Separate Training for Conditional Random Fields Using Co-occurrence Rate
  Factorization","The standard training method of Conditional Random Fields (CRFs) is very slow
for large-scale applications. As an alternative, piecewise training divides the
full graph into pieces, trains them independently, and combines the learned
weights at test time. In this paper, we present \emph{separate} training for
undirected models based on the novel Co-occurrence Rate Factorization (CR-F).
Separate training is a local training method. In contrast to MEMMs, separate
training is unaffected by the label bias problem. Experiments show that
separate training (i) is unaffected by the label bias problem; (ii) reduces the
training time from weeks to seconds; and (iii) obtains competitive results to
the standard and piecewise training on linear-chain CRFs.",2010-08-09T19:02:04Z,"Zhemin Zhu, Djoerd Hiemstra, Peter Apers, Andreas Wombacher"
1008.1643v2,A Learning Algorithm based on High School Teaching Wisdom,"A learning algorithm based on primary school teaching and learning is
presented. The methodology is to continuously evaluate a student and to give
them training on the examples for which they repeatedly fail, until, they can
correctly answer all types of questions. This incremental learning procedure
produces better learning curves by demanding the student to optimally dedicate
their learning time on the failed examples. When used in machine learning, the
algorithm is found to train a machine on a data with maximum variance in the
feature space so that the generalization ability of the network improves. The
algorithm has interesting applications in data mining, model evaluations and
rare objects discovery.",2010-08-10T07:44:08Z,Ninan Sajeeth Philip
1009.0605v2,"Gaussian Process Bandits for Tree Search: Theory and Application to
  Planning in Discounted MDPs","We motivate and analyse a new Tree Search algorithm, GPTS, based on recent
theoretical advances in the use of Gaussian Processes for Bandit problems. We
consider tree paths as arms and we assume the target/reward function is drawn
from a GP distribution. The posterior mean and variance, after observing data,
are used to define confidence intervals for the function values, and we
sequentially play arms with highest upper confidence bounds. We give an
efficient implementation of GPTS and we adapt previous regret bounds by
determining the decay rate of the eigenvalues of the kernel matrix on the whole
set of tree paths. We consider two kernels in the feature space of binary
vectors indexed by the nodes of the tree: linear and Gaussian. The regret grows
in square root of the number of iterations T, up to a logarithmic factor, with
a constant that improves with bigger Gaussian kernel widths. We focus on
practical values of T, smaller than the number of arms. Finally, we apply GPTS
to Open Loop Planning in discounted Markov Decision Processes by modelling the
reward as a discounted sum of independent Gaussian Processes. We report similar
regret bounds to those of the OLOP algorithm.",2010-09-03T08:36:07Z,"Louis Dorard, John Shawe-Taylor"
1010.4466v1,On the Foundations of Adversarial Single-Class Classification,"Motivated by authentication, intrusion and spam detection applications we
consider single-class classification (SCC) as a two-person game between the
learner and an adversary. In this game the learner has a sample from a target
distribution and the goal is to construct a classifier capable of
distinguishing observations from the target distribution from observations
emitted from an unknown other distribution. The ideal SCC classifier must
guarantee a given tolerance for the false-positive error (false alarm rate)
while minimizing the false negative error (intruder pass rate). Viewing SCC as
a two-person zero-sum game we identify both deterministic and randomized
optimal classification strategies for different game variants. We demonstrate
that randomized classification can provide a significant advantage. In the
deterministic setting we show how to reduce SCC to two-class classification
where in the two-class problem the other class is a synthetically generated
distribution. We provide an efficient and practical algorithm for constructing
and solving the two class problem. The algorithm distinguishes low density
regions of the target distribution and is shown to be consistent.",2010-10-21T13:28:09Z,"Ran El-Yaniv, Mordechai Nisenson"
1012.0930v3,Efficient Optimization of Performance Measures by Classifier Adaptation,"In practical applications, machine learning algorithms are often needed to
learn classifiers that optimize domain specific performance measures.
Previously, the research has focused on learning the needed classifier in
isolation, yet learning nonlinear classifier for nonlinear and nonsmooth
performance measures is still hard. In this paper, rather than learning the
needed classifier by optimizing specific performance measure directly, we
circumvent this problem by proposing a novel two-step approach called as CAPO,
namely to first train nonlinear auxiliary classifiers with existing learning
methods, and then to adapt auxiliary classifiers for specific performance
measures. In the first step, auxiliary classifiers can be obtained efficiently
by taking off-the-shelf learning algorithms. For the second step, we show that
the classifier adaptation problem can be reduced to a quadratic program
problem, which is similar to linear SVMperf and can be efficiently solved. By
exploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear
classifier which optimizes a large variety of performance measures including
all the performance measure based on the contingency table and AUC, whilst
keeping high computational efficiency. Empirical studies show that CAPO is
effective and of high computational efficiency, and even it is more efficient
than linear SVMperf.",2010-12-04T16:08:08Z,"Nan Li, Ivor W. Tsang, Zhi-Hua Zhou"
1012.2609v4,"Inverse-Category-Frequency based supervised term weighting scheme for
  text categorization","Term weighting schemes often dominate the performance of many classifiers,
such as kNN, centroid-based classifier and SVMs. The widely used term weighting
scheme in text categorization, i.e., tf.idf, is originated from information
retrieval (IR) field. The intuition behind idf for text categorization seems
less reasonable than IR. In this paper, we introduce inverse category frequency
(icf) into term weighting scheme and propose two novel approaches, i.e., tf.icf
and icf-based supervised term weighting schemes. The tf.icf adopts icf to
substitute idf factor and favors terms occurring in fewer categories, rather
than fewer documents. And the icf-based approach combines icf and relevance
frequency (rf) to weight terms in a supervised way. Our cross-classifier and
cross-corpus experiments have shown that our proposed approaches are superior
or comparable to six supervised term weighting schemes and three traditional
schemes in terms of macro-F1 and micro-F1.",2010-12-13T01:22:36Z,"Deqing Wang, Hui Zhang"
1101.0428v1,"The Local Optimality of Reinforcement Learning by Value Gradients, and
  its Relationship to Policy Gradient Learning","In this theoretical paper we are concerned with the problem of learning a
value function by a smooth general function approximator, to solve a
deterministic episodic control problem in a large continuous state space. It is
shown that learning the gradient of the value-function at every point along a
trajectory generated by a greedy policy is a sufficient condition for the
trajectory to be locally extremal, and often locally optimal, and we argue that
this brings greater efficiency to value-function learning. This contrasts to
traditional value-function learning in which the value-function must be learnt
over the whole of state space.
  It is also proven that policy-gradient learning applied to a greedy policy on
a value-function produces a weight update equivalent to a value-gradient weight
update, which provides a surprising connection between these two alternative
paradigms of reinforcement learning, and a convergence proof for control
problems with a value function represented by a general smooth function
approximator.",2011-01-02T20:20:27Z,"Michael Fairbank, Eduardo Alonso"
1101.2320v1,"Review and Evaluation of Feature Selection Algorithms in Synthetic
  Problems","The main purpose of Feature Subset Selection is to find a reduced subset of
attributes from a data set described by a feature set. The task of a feature
selection algorithm (FSA) is to provide with a computational solution motivated
by a certain definition of relevance or by a reliable evaluation measure. In
this paper several fundamental algorithms are studied to assess their
performance in a controlled experimental scenario. A measure to evaluate FSAs
is devised that computes the degree of matching between the output given by a
FSA and the known optimal solutions. An extensive experimental study on
synthetic problems is carried out to assess the behaviour of the algorithms in
terms of solution accuracy and size as a function of the relevance,
irrelevance, redundancy and size of the data samples. The controlled
experimental conditions facilitate the derivation of better-supported and
meaningful conclusions.",2011-01-12T10:49:51Z,"L. A. Belanche, F. F. Gonzlez"
1104.3929v1,Understanding Exhaustive Pattern Learning,"Pattern learning in an important problem in Natural Language Processing
(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved
to be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)
showed great advantages on other tasks, such as machine translation. In this
article, we first formalize EPL, and then show that the probability given by an
EPL model is constant-factor approximation of the probability given by an
ensemble method that integrates exponential number of models obtained with
various segmentations of the training data. This work for the first time
provides theoretical justification for the widely used EPL algorithm in NLP,
which was previously viewed as a flawed heuristic method. Better understanding
of EPL may lead to improved pattern learning algorithms in future.",2011-04-20T02:49:59Z,Libin Shen
1104.5256v1,Learning Undirected Graphical Models with Structure Penalty,"In undirected graphical models, learning the graph structure and learning the
functions that relate the predictive variables (features) to the responses
given the structure are two topics that have been widely investigated in
machine learning and statistics. Learning graphical models in two stages will
have problems because graph structure may change after considering the
features. The main contribution of this paper is the proposed method that
learns the graph structure and functions on the graph at the same time. General
graphical models with binary outcomes conditioned on predictive variables are
proved to be equivalent to multivariate Bernoulli model. The reparameterization
of the potential functions in graphical model by conditional log odds ratios in
multivariate Bernoulli model offers advantage in the representation of the
conditional independence structure in the model. Additionally, we impose a
structure penalty on groups of conditional log odds ratios to learn the graph
structure. These groups of functions are designed with overlaps to enforce
hierarchical function selection. In this way, we are able to shrink higher
order interactions to obtain a sparse graph structure. Simulation studies show
that the method is able to recover the graph structure. The analysis of county
data from Census Bureau gives interesting relations between unemployment rate,
crime and others discovered by the model.",2011-04-27T21:40:09Z,Shilin Ding
1104.5601v1,Mean-Variance Optimization in Markov Decision Processes,"We consider finite horizon Markov decision processes under performance
measures that involve both the mean and the variance of the cumulative reward.
We show that either randomized or history-based policies can improve
performance. We prove that the complexity of computing a policy that maximizes
the mean reward under a variance constraint is NP-hard for some cases, and
strongly NP-hard for others. We finally offer pseudopolynomial exact and
approximation algorithms.",2011-04-29T11:39:40Z,"Shie Mannor, John Tsitsiklis"
1105.2868v1,Semantic Vector Machines,"We first present our work in machine translation, during which we used
aligned sentences to train a neural network to embed n-grams of different
languages into an $d$-dimensional space, such that n-grams that are the
translation of each other are close with respect to some metric. Good n-grams
to n-grams translation results were achieved, but full sentences translation is
still problematic. We realized that learning semantics of sentences and
documents was the key for solving a lot of natural language processing
problems, and thus moved to the second part of our work: sentence compression.
We introduce a flexible neural network architecture for learning embeddings of
words and sentences that extract their semantics, propose an efficient
implementation in the Torch framework and present embedding results comparable
to the ones obtained with classical neural language models, while being more
powerful.",2011-05-14T07:13:25Z,Etter Vincent
1105.2943v1,Feature Selection for MAUC-Oriented Classification Systems,"Feature selection is an important pre-processing step for many pattern
classification tasks. Traditionally, feature selection methods are designed to
obtain a feature subset that can lead to high classification accuracy. However,
classification accuracy has recently been shown to be an inappropriate
performance metric of classification systems in many cases. Instead, the Area
Under the receiver operating characteristic Curve (AUC) and its multi-class
extension, MAUC, have been proved to be better alternatives. Hence, the target
of classification system design is gradually shifting from seeking a system
with the maximum classification accuracy to obtaining a system with the maximum
AUC/MAUC. Previous investigations have shown that traditional feature selection
methods need to be modified to cope with this new objective. These methods most
often are restricted to binary classification problems only. In this study, a
filter feature selection method, namely MAUC Decomposition based Feature
Selection (MDFS), is proposed for multi-class classification problems. To the
best of our knowledge, MDFS is the first method specifically designed to select
features for building classification systems with maximum MAUC. Extensive
empirical results demonstrate the advantage of MDFS over several compared
feature selection methods.",2011-05-15T12:35:56Z,"Rui Wang, Ke Tang"
1105.5464v1,Learning to Order Things,"There are many applications in which it is desirable to order rather than
classify instances. Here we consider the problem of learning how to order
instances given feedback in the form of preference judgments, i.e., statements
to the effect that one instance should be ranked ahead of another. We outline a
two-stage approach in which one first learns by conventional means a binary
preference function indicating whether it is advisable to rank one instance
before another. Here we consider an on-line algorithm for learning preference
functions that is based on Freund and Schapire's 'Hedge' algorithm. In the
second stage, new instances are ordered so as to maximize agreement with the
learned preference function. We show that the problem of finding the ordering
that agrees best with a learned preference function is NP-complete.
Nevertheless, we describe simple greedy algorithms that are guaranteed to find
a good approximation. Finally, we show how metasearch can be formulated as an
ordering problem, and present experimental results on learning a combination of
'search experts', each of which is a domain-specific query expansion strategy
for a web search engine.",2011-05-27T01:54:11Z,"W. W. Cohen, R. E. Schapire, Y. Singer"
1106.0483v1,Learning unbelievable marginal probabilities,"Loopy belief propagation performs approximate inference on graphical models
with loops. One might hope to compensate for the approximation by adjusting
model parameters. Learning algorithms for this purpose have been explored
previously, and the claim has been made that every set of locally consistent
marginals can arise from belief propagation run on a graphical model. On the
contrary, here we show that many probability distributions have marginals that
cannot be reached by belief propagation using any set of model parameters or
any learning algorithm. We call such marginals `unbelievable.' This problem
occurs whenever the Hessian of the Bethe free energy is not positive-definite
at the target marginals. All learning algorithms for belief propagation
necessarily fail in these cases, producing beliefs or sets of beliefs that may
even be worse than the pre-learning approximation. We then show that averaging
inaccurate beliefs, each obtained from belief propagation using model
parameters perturbed about some learned mean values, can achieve the
unbelievable marginals.",2011-06-02T18:48:59Z,"Xaq Pitkow, Yashar Ahmadian, Ken D. Miller"
1106.0666v2,"Experiments with Infinite-Horizon, Policy-Gradient Estimation","In this paper, we present algorithms that perform gradient ascent of the
average reward in a partially observable Markov decision process (POMDP). These
algorithms are based on GPOMDP, an algorithm introduced in a companion paper
(Baxter and Bartlett, this volume), which computes biased estimates of the
performance gradient in POMDPs. The algorithm's chief advantages are that it
uses only one free parameter beta, which has a natural interpretation in terms
of bias-variance trade-off, it requires no knowledge of the underlying state,
and it can be applied to infinite state, control and observation spaces. We
show how the gradient estimates produced by GPOMDP can be used to perform
gradient ascent, both with a traditional stochastic-gradient algorithm, and
with an algorithm based on conjugate-gradients that utilizes gradient
information to bracket maxima in line searches. Experimental results are
presented illustrating both the theoretical results of (Baxter and Bartlett,
this volume) on a toy problem, and practical aspects of the algorithms on a
number of more realistic problems.",2011-06-03T14:52:26Z,"J. Baxter, P. L. Bartlett, L. Weaver"
1106.0676v1,"Optimizing Dialogue Management with Reinforcement Learning: Experiments
  with the NJFun System","Designing the dialogue policy of a spoken dialogue system involves many
nontrivial choices. This paper presents a reinforcement learning approach for
automatically optimizing a dialogue policy, which addresses the technical
challenges in applying reinforcement learning to a working dialogue system with
human users. We report on the design, construction and empirical evaluation of
NJFun, an experimental spoken dialogue system that provides users with access
to information about fun things to do in New Jersey. Our results show that by
optimizing its performance via reinforcement learning, NJFun measurably
improves system performance.",2011-06-03T14:55:23Z,"M. Kearns, D. Litman, S. Singh, M. Walker"
1106.0681v1,Accelerating Reinforcement Learning through Implicit Imitation,"Imitation can be viewed as a means of enhancing learning in multiagent
environments. It augments an agent's ability to learn useful behaviors by
making intelligent use of the knowledge implicit in behaviors demonstrated by
cooperative teachers or other more experienced agents. We propose and study a
formal model of implicit imitation that can accelerate reinforcement learning
dramatically in certain cases. Roughly, by observing a mentor, a
reinforcement-learning agent can extract information about its own capabilities
in, and the relative value of, unvisited parts of the state space. We study two
specific instantiations of this model, one in which the learning agent and the
mentor have identical abilities, and one designed to deal with agents and
mentors with different action sets. We illustrate the benefits of implicit
imitation by integrating it with prioritized sweeping, and demonstrating
improved performance and convergence through observation of single and multiple
mentors. Though we make some stringent assumptions regarding observability and
possible interactions, we briefly comment on extensions of the model that relax
these restricitions.",2011-06-03T14:57:02Z,"C. Boutilier, B. Price"
1106.0707v1,Efficient Reinforcement Learning Using Recursive Least-Squares Methods,"The recursive least-squares (RLS) algorithm is one of the most well-known
algorithms used in adaptive filtering, system identification and adaptive
control. Its popularity is mainly due to its fast convergence speed, which is
considered to be optimal in practice. In this paper, RLS methods are used to
solve reinforcement learning problems, where two new reinforcement learning
algorithms using linear value function approximators are proposed and analyzed.
The two algorithms are called RLS-TD(lambda) and Fast-AHC (Fast Adaptive
Heuristic Critic), respectively. RLS-TD(lambda) can be viewed as the extension
of RLS-TD(0) from lambda=0 to general lambda within interval [0,1], so it is a
multi-step temporal-difference (TD) learning algorithm using RLS methods. The
convergence with probability one and the limit of convergence of RLS-TD(lambda)
are proved for ergodic Markov chains. Compared to the existing LS-TD(lambda)
algorithm, RLS-TD(lambda) has advantages in computation and is more suitable
for online learning. The effectiveness of RLS-TD(lambda) is analyzed and
verified by learning prediction experiments of Markov chains with a wide range
of parameter settings. The Fast-AHC algorithm is derived by applying the
proposed RLS-TD(lambda) algorithm in the critic network of the adaptive
heuristic critic method. Unlike conventional AHC algorithm, Fast-AHC makes use
of RLS methods to improve the learning-prediction efficiency in the critic.
Learning control experiments of the cart-pole balancing and the acrobot
swing-up problems are conducted to compare the data efficiency of Fast-AHC with
conventional AHC. From the experimental results, it is shown that the data
efficiency of learning control can also be improved by using RLS methods in the
learning-prediction process of the critic. The performance of Fast-AHC is also
compared with that of the AHC method using LS-TD(lambda). Furthermore, it is
demonstrated in the experiments that different initial values of the variance
matrix in RLS-TD(lambda) are required to get better performance not only in
learning prediction but also in learning control. The experimental results are
analyzed based on the existing theoretical work on the transient phase of
forgetting factor RLS methods.",2011-06-03T16:44:06Z,"H. He, D. Hu, X. Xu"
1106.4572v1,"Specific-to-General Learning for Temporal Events with Application to
  Learning Event Definitions from Video","We develop, analyze, and evaluate a novel, supervised, specific-to-general
learner for a simple temporal logic and use the resulting algorithm to learn
visual event definitions from video sequences. First, we introduce a simple,
propositional, temporal, event-description language called AMA that is
sufficiently expressive to represent many events yet sufficiently restrictive
to support learning. We then give algorithms, along with lower and upper
complexity bounds, for the subsumption and generalization problems for AMA
formulas. We present a positive-examples--only specific-to-general learning
method based on these algorithms. We also present a polynomial-time--computable
``syntactic'' subsumption test that implies semantic subsumption without being
equivalent to it. A generalization algorithm based on syntactic subsumption can
be used in place of semantic generalization to improve the asymptotic
complexity of the resulting learning algorithm. Finally, we apply this
algorithm to the task of learning relational event definitions from video and
show that it yields definitions that are competitive with hand-coded ones.",2011-06-22T20:58:18Z,"A. Fern, R. Givan, J. M. Siskind"
1107.4966v2,Lifted Graphical Models: A Survey,"This article presents a survey of work on lifted graphical models. We review
a general form for a lifted graphical model, a par-factor graph, and show how a
number of existing statistical relational representations map to this
formalism. We discuss inference algorithms, including lifted inference
algorithms, that efficiently compute the answers to probabilistic queries. We
also review work in learning lifted graphical models from data. It is our
belief that the need for statistical relational models (whether it goes by that
name or another) will grow in the coming decades, as we are inundated with data
which is a mix of structured and unstructured, with entities and relations
extracted in a noisy manner from text, and with the need to reason effectively
with this data. We hope that this synthesis of ideas from many different
research groups will provide an accessible starting point for new researchers
in this expanding field.",2011-07-25T14:56:18Z,"Lilyana Mihalkova, Lise Getoor"
1107.5236v2,"Submodular Optimization for Efficient Semi-supervised Support Vector
  Machines","In this work we present a quadratic programming approximation of the
Semi-Supervised Support Vector Machine (S3VM) problem, namely approximate
QP-S3VM, that can be efficiently solved using off the shelf optimization
packages. We prove that this approximate formulation establishes a relation
between the low density separation and the graph-based models of
semi-supervised learning (SSL) which is important to develop a unifying
framework for semi-supervised learning methods. Furthermore, we propose the
novel idea of representing SSL problems as submodular set functions and use
efficient submodular optimization algorithms to solve them. Using this new idea
we develop a representation of the approximate QP-S3VM as a maximization of a
submodular set function which makes it possible to optimize using efficient
greedy algorithms. We demonstrate that the proposed methods are accurate and
provide significant improvement in time complexity over the state of the art in
the literature.",2011-07-26T15:11:10Z,"Wael Emara, Mehmed Kantardzic"
1107.5537v1,Asymptotically Optimal Agents,"Artificial general intelligence aims to create agents capable of learning to
solve arbitrary interesting problems. We define two versions of asymptotic
optimality and prove that no agent can satisfy the strong version while in some
cases, depending on discounting, there does exist a non-computable weak
asymptotically optimal agent.",2011-07-27T16:51:48Z,"Tor Lattimore, Marcus Hutter"
1108.0039v2,"CBR with Commonsense Reasoning and Structure Mapping: An Application to
  Mediation","Mediation is an important method in dispute resolution. We implement a case
based reasoning approach to mediation integrating analogical and commonsense
reasoning components that allow an artificial mediation agent to satisfy
requirements expected from a human mediator, in particular: utilizing
experience with cases in different domains; and structurally transforming the
set of issues for a better solution. We utilize a case structure based on
ontologies reflecting the perceptions of the parties in dispute. The analogical
reasoning component, employing the Structure Mapping Theory from psychology,
provides a flexibility to respond innovatively in unusual circumstances, in
contrast with conventional approaches confined into specialized problem
domains. We aim to build a mediation case base incorporating real world
instances ranging from interpersonal or intergroup disputes to international
conflicts.",2011-07-30T05:12:17Z,"Atilim Gunes Baydin, Ramon Lopez de Mantaras, Simeon Simoff, Carles Sierra"
1108.2054v1,Uncertain Nearest Neighbor Classification,"This work deals with the problem of classifying uncertain data. With this aim
the Uncertain Nearest Neighbor (UNN) rule is here introduced, which represents
the generalization of the deterministic nearest neighbor rule to the case in
which uncertain objects are available. The UNN rule relies on the concept of
nearest neighbor class, rather than on that of nearest neighbor object. The
nearest neighbor class of a test object is the class that maximizes the
probability of providing its nearest neighbor. It is provided evidence that the
former concept is much more powerful than the latter one in the presence of
uncertainty, in that it correctly models the right semantics of the nearest
neighbor decision rule when applied to the uncertain scenario. An effective and
efficient algorithm to perform uncertain nearest neighbor classification of a
generic (un)certain test object is designed, based on properties that greatly
reduce the temporal cost associated with nearest neighbor class probability
computation. Experimental results are presented, showing that the UNN rule is
effective and efficient in classifying uncertain data.",2011-08-09T21:28:42Z,"Fabrizio Angiulli, Fabio Fassetti"
1108.2283v2,A survey on independence-based Markov networks learning,"This work reports the most relevant technical aspects in the problem of
learning the \emph{Markov network structure} from data. Such problem has become
increasingly important in machine learning, and many other application fields
of machine learning. Markov networks, together with Bayesian networks, are
probabilistic graphical models, a widely used formalism for handling
probability distributions in intelligent systems. Learning graphical models
from data have been extensively applied for the case of Bayesian networks, but
for Markov networks learning it is not tractable in practice. However, this
situation is changing with time, given the exponential growth of computers
capacity, the plethora of available digital data, and the researching on new
learning technologies. This work stresses on a technology called
independence-based learning, which allows the learning of the independence
structure of those networks from data in an efficient and sound manner,
whenever the dataset is sufficiently large, and data is a representative
sampling of the target distribution. In the analysis of such technology, this
work surveys the current state-of-the-art algorithms for learning Markov
networks structure, discussing its current limitations, and proposing a series
of open problems where future works may produce some advances in the area in
terms of quality and efficiency. The paper concludes by opening a discussion
about how to develop a general formalism for improving the quality of the
structures learned, when data is scarce.",2011-08-10T20:25:08Z,Federico Schlter
1108.3446v2,Premise Selection for Mathematics by Corpus Analysis and Kernel Methods,"Smart premise selection is essential when using automated reasoning as a tool
for large-theory formal proof development. A good method for premise selection
in complex mathematical libraries is the application of machine learning to
large corpora of proofs. This work develops learning-based premise selection in
two ways. First, a newly available minimal dependency analysis of existing
high-level formal mathematical proofs is used to build a large knowledge base
of proof dependencies, providing precise data for ATP-based re-verification and
for training premise selection algorithms. Second, a new machine learning
algorithm for premise selection based on kernel methods is proposed and
implemented. To evaluate the impact of both techniques, a benchmark consisting
of 2078 large-theory mathematical problems is constructed,extending the older
MPTP Challenge benchmark. The combined effect of the techniques results in a
50% improvement on the benchmark over the Vampire/SInE state-of-the-art system
for automated reasoning in large theories.",2011-08-17T11:18:55Z,"Jesse Alama, Tom Heskes, Daniel Khlwein, Evgeni Tsivtsivadze, Josef Urban"
1108.5668v1,Datum-Wise Classification: A Sequential Approach to Sparsity,"We propose a novel classification technique whose aim is to select an
appropriate representation for each datapoint, in contrast to the usual
approach of selecting a representation encompassing the whole dataset. This
datum-wise representation is found by using a sparsity inducing empirical risk,
which is a relaxation of the standard L 0 regularized risk. The classification
problem is modeled as a sequential decision process that sequentially chooses,
for each datapoint, which features to use before classifying. Datum-Wise
Classification extends naturally to multi-class tasks, and we describe a
specific case where our inference has equivalent complexity to a traditional
linear classifier, while still using a variable number of features. We compare
our classifier to classical L 1 regularized linear models (L 1-SVM and LARS) on
a set of common binary and multi-class datasets and show that for an equal
average number of features used we can get improved performance using our
method.",2011-08-29T17:46:08Z,"Gabriel Dulac-Arnold, Ludovic Denoyer, Philippe Preux, Patrick Gallinari"
1108.6211v2,Transfer from Multiple MDPs,"Transfer reinforcement learning (RL) methods leverage on the experience
collected on a set of source tasks to speed-up RL algorithms. A simple and
effective approach is to transfer samples from source tasks and include them
into the training set used to solve a given target task. In this paper, we
investigate the theoretical properties of this transfer method and we introduce
novel algorithms adapting the transfer process on the basis of the similarity
between source and target tasks. Finally, we report illustrative experimental
results in a continuous chain problem.",2011-08-31T12:46:11Z,"Alessandro Lazaric, Marcello Restelli"
1109.4684v1,"Exhaustive and Efficient Constraint Propagation: A Semi-Supervised
  Learning Perspective and Its Applications","This paper presents a novel pairwise constraint propagation approach by
decomposing the challenging constraint propagation problem into a set of
independent semi-supervised learning subproblems which can be solved in
quadratic time using label propagation based on k-nearest neighbor graphs.
Considering that this time cost is proportional to the number of all possible
pairwise constraints, our approach actually provides an efficient solution for
exhaustively propagating pairwise constraints throughout the entire dataset.
The resulting exhaustive set of propagated pairwise constraints are further
used to adjust the similarity matrix for constrained spectral clustering. Other
than the traditional constraint propagation on single-source data, our approach
is also extended to more challenging constraint propagation on multi-source
data where each pairwise constraint is defined over a pair of data points from
different sources. This multi-source constraint propagation has an important
application to cross-modal multimedia retrieval. Extensive results have shown
the superior performance of our approach.",2011-09-22T00:56:22Z,"Zhiwu Lu, Horace H. S. Ip, Yuxin Peng"
1110.0593v1,"Two Projection Pursuit Algorithms for Machine Learning under
  Non-Stationarity","This thesis derives, tests and applies two linear projection algorithms for
machine learning under non-stationarity. The first finds a direction in a
linear space upon which a data set is maximally non-stationary. The second aims
to robustify two-way classification against non-stationarity. The algorithm is
tested on a key application scenario, namely Brain Computer Interfacing.",2011-10-04T07:34:13Z,Duncan A. J. Blythe
1110.2211v1,Learning Symbolic Models of Stochastic Domains,"In this article, we work towards the goal of developing agents that can learn
to act in complex worlds. We develop a probabilistic, relational planning rule
representation that compactly models noisy, nondeterministic action effects,
and show how such rules can be effectively learned. Through experiments in
simple planning domains and a 3D simulated blocks world with realistic physics,
we demonstrate that this learning algorithm allows agents to effectively model
world dynamics.",2011-10-10T21:58:58Z,"L. P. Kaelbling, H. M. Pasula, L. S. Zettlemoyer"
1110.5667v1,Inducing Probabilistic Programs by Bayesian Program Merging,"This report outlines an approach to learning generative models from data. We
express models as probabilistic programs, which allows us to capture abstract
patterns within the examples. By choosing our language for programs to be an
extension of the algebraic data type of the examples, we can begin with a
program that generates all and only the examples. We then introduce greater
abstraction, and hence generalization, incrementally to the extent that it
improves the posterior probability of the examples given the program. Motivated
by previous approaches to model merging and program induction, we search for
such explanatory abstractions using program transformations. We consider two
types of transformation: Abstraction merges common subexpressions within a
program into new functions (a form of anti-unification). Deargumentation
simplifies functions by reducing the number of arguments. We demonstrate that
this approach finds key patterns in the domain of nested lists, including
parameterized sub-functions and stochastic recursion.",2011-10-25T21:06:39Z,"Irvin Hwang, Andreas Stuhlmller, Noah D. Goodman"
1111.0432v2,"Approximate Stochastic Subgradient Estimation Training for Support
  Vector Machines","Subgradient algorithms for training support vector machines have been quite
successful for solving large-scale and online learning problems. However, they
have been restricted to linear kernels and strongly convex formulations. This
paper describes efficient subgradient approaches without such limitations. Our
approaches make use of randomized low-dimensional approximations to nonlinear
kernels, and minimization of a reduced primal formulation using an algorithm
based on robust stochastic approximation, which do not require strong
convexity. Experiments illustrate that our approaches produce solutions of
comparable prediction accuracy with the solutions acquired from existing SVM
solvers, but often in much shorter time. We also suggest efficient prediction
schemes that depend only on the dimension of kernel approximation, not on the
number of support vectors.",2011-11-02T09:24:26Z,"Sangkyun Lee, Stephen J. Wright"
1111.0712v1,Online Learning with Preference Feedback,"We propose a new online learning model for learning with preference feedback.
The model is especially suited for applications like web search and recommender
systems, where preference data is readily available from implicit user feedback
(e.g. clicks). In particular, at each time step a potentially structured object
(e.g. a ranking) is presented to the user in response to a context (e.g.
query), providing him or her with some unobserved amount of utility. As
feedback the algorithm receives an improved object that would have provided
higher utility. We propose a learning algorithm with provable regret bounds for
this online learning setting and demonstrate its effectiveness on a web-search
application. The new learning model also applies to many other interactive
learning problems and admits several interesting extensions.",2011-11-03T01:58:45Z,"Pannagadatta K. Shivaswamy, Thorsten Joachims"
1111.3735v1,A Bayesian Model for Plan Recognition in RTS Games applied to StarCraft,"The task of keyhole (unobtrusive) plan recognition is central to adaptive
game AI. ""Tech trees"" or ""build trees"" are the core of real-time strategy (RTS)
game strategic (long term) planning. This paper presents a generic and simple
Bayesian model for RTS build tree prediction from noisy observations, which
parameters are learned from replays (game logs). This unsupervised machine
learning approach involves minimal work for the game developers as it leverage
players' data (com- mon in RTS). We applied it to StarCraft1 and showed that it
yields high quality and robust predictions, that can feed an adaptive AI.",2011-11-16T09:26:14Z,"Gabriel Synnaeve, Pierre Bessire"
1112.5309v2,"POWERPLAY: Training an Increasingly General Problem Solver by
  Continually Searching for the Simplest Still Unsolvable Problem","Most of computer science focuses on automatically solving given computational
problems. I focus on automatically inventing or discovering problems in a way
inspired by the playful behavior of animals and humans, to train a more and
more general problem solver from scratch in an unsupervised fashion. Consider
the infinite set of all computable descriptions of tasks with possibly
computable solutions. The novel algorithmic framework POWERPLAY (2011)
continually searches the space of possible pairs of new tasks and modifications
of the current problem solver, until it finds a more powerful problem solver
that provably solves all previously learned tasks plus the new one, while the
unmodified predecessor does not. Wow-effects are achieved by continually making
previously learned skills more efficient such that they require less time and
space. New skills may (partially) re-use previously learned skills. POWERPLAY's
search orders candidate pairs of tasks and solver modifications by their
conditional computational (time & space) complexity, given the stored
experience so far. The new task and its corresponding task-solving skill are
those first found and validated. The computational costs of validating new
tasks need not grow with task repertoire size. POWERPLAY's ongoing search for
novelty keeps breaking the generalization abilities of its present solver. This
is related to Goedel's sequence of increasingly powerful formal theories based
on adding formerly unprovable statements to the axioms without affecting
previously provable theorems. The continually increasing repertoire of problem
solving procedures can be exploited by a parallel search for solutions to
additional externally posed tasks. POWERPLAY may be viewed as a greedy but
practical implementation of basic principles of creativity. A first
experimental analysis can be found in separate papers [53,54].",2011-12-22T13:50:46Z,Jrgen Schmidhuber
1201.4777v2,A probabilistic methodology for multilabel classification,"Multilabel classification is a relatively recent subfield of machine
learning. Unlike to the classical approach, where instances are labeled with
only one category, in multilabel classification, an arbitrary number of
categories is chosen to label an instance. Due to the problem complexity (the
solution is one among an exponential number of alternatives), a very common
solution (the binary method) is frequently used, learning a binary classifier
for every category, and combining them all afterwards. The assumption taken in
this solution is not realistic, and in this work we give examples where the
decisions for all the labels are not taken independently, and thus, a
supervised approach should learn those existing relationships among categories
to make a better classification. Therefore, we show here a generic methodology
that can improve the results obtained by a set of independent probabilistic
binary classifiers, by using a combination procedure with a classifier trained
on the co-occurrences of the labels. We show an exhaustive experimentation in
three different standard corpora of labeled documents (Reuters-21578,
Ohsumed-23 and RCV1), which present noticeable improvements in all of them,
when using our methodology, in three probabilistic base classifiers.",2012-01-23T17:25:34Z,"Alfonso E. Romero, Luis M. de Campos"
1201.5217v1,Unsupervised Classification Using Immune Algorithm,"Unsupervised classification algorithm based on clonal selection principle
named Unsupervised Clonal Selection Classification (UCSC) is proposed in this
paper. The new proposed algorithm is data driven and self-adaptive, it adjusts
its parameters to the data to make the classification operation as fast as
possible. The performance of UCSC is evaluated by comparing it with the well
known K-means algorithm using several artificial and real-life data sets. The
experiments show that the proposed UCSC algorithm is more reliable and has high
classification precision comparing to traditional classification methods such
as K-means.",2012-01-25T09:44:06Z,"M. T. Al-Muallim, R. El-Kouatly"
1201.6583v1,Empowerment for Continuous Agent-Environment Systems,"This paper develops generalizations of empowerment to continuous states.
Empowerment is a recently introduced information-theoretic quantity motivated
by hypotheses about the efficiency of the sensorimotor loop in biological
organisms, but also from considerations stemming from curiosity-driven
learning. Empowemerment measures, for agent-environment systems with stochastic
transitions, how much influence an agent has on its environment, but only that
influence that can be sensed by the agent sensors. It is an
information-theoretic generalization of joint controllability (influence on
environment) and observability (measurement by sensors) of the environment by
the agent, both controllability and observability being usually defined in
control theory as the dimensionality of the control/observation spaces. Earlier
work has shown that empowerment has various interesting and relevant
properties, e.g., it allows us to identify salient states using only the
dynamics, and it can act as intrinsic reward without requiring an external
reward. However, in this previous work empowerment was limited to the case of
small-scale and discrete domains and furthermore state transition probabilities
were assumed to be known. The goal of this paper is to extend empowerment to
the significantly more important and relevant case of continuous vector-valued
state spaces and initially unknown state transition probabilities. The
continuous state space is addressed by Monte-Carlo approximation; the unknown
transitions are addressed by model learning and prediction for which we apply
Gaussian processes regression with iterated forecasting. In a number of
well-known continuous control tasks we examine the dynamics induced by
empowerment and include an application to exploration and online model
learning.",2012-01-31T15:46:27Z,"Tobias Jung, Daniel Polani, Peter Stone"
1201.6604v1,"Gaussian Processes for Sample Efficient Reinforcement Learning with
  RMAX-like Exploration","We present an implementation of model-based online reinforcement learning
(RL) for continuous domains with deterministic transitions that is specifically
designed to achieve low sample complexity. To achieve low sample complexity,
since the environment is unknown, an agent must intelligently balance
exploration and exploitation, and must be able to rapidly generalize from
observations. While in the past a number of related sample efficient RL
algorithms have been proposed, to allow theoretical analysis, mainly
model-learners with weak generalization capabilities were considered. Here, we
separate function approximation in the model learner (which does require
samples) from the interpolation in the planner (which does not require
samples). For model-learning we apply Gaussian processes regression (GP) which
is able to automatically adjust itself to the complexity of the problem (via
Bayesian hyperparameter selection) and, in practice, often able to learn a
highly accurate model from very little data. In addition, a GP provides a
natural way to determine the uncertainty of its predictions, which allows us to
implement the ""optimism in the face of uncertainty"" principle used to
efficiently control exploration. Our method is evaluated on four common
benchmark domains.",2012-01-31T16:36:51Z,"Tobias Jung, Peter Stone"
1201.6615v1,"Feature Selection for Value Function Approximation Using Bayesian Model
  Selection","Feature selection in reinforcement learning (RL), i.e. choosing basis
functions such that useful approximations of the unkown value function can be
obtained, is one of the main challenges in scaling RL to real-world
applications. Here we consider the Gaussian process based framework GPTD for
approximate policy evaluation, and propose feature selection through marginal
likelihood optimization of the associated hyperparameters. Our approach has two
appealing benefits: (1) given just sample transitions, we can solve the policy
evaluation problem fully automatically (without looking at the learning task,
and, in theory, independent of the dimensionality of the state space), and (2)
model selection allows us to consider more sophisticated kernels, which in turn
enable us to identify relevant subspaces and eliminate irrelevant state
variables such that we can achieve substantial computational savings and
improved prediction performance.",2012-01-31T16:57:55Z,"Tobias Jung, Peter Stone"
1202.5597v3,Hybrid Batch Bayesian Optimization,"Bayesian Optimization aims at optimizing an unknown non-convex/concave
function that is costly to evaluate. We are interested in application scenarios
where concurrent function evaluations are possible. Under such a setting, BO
could choose to either sequentially evaluate the function, one input at a time
and wait for the output of the function before making the next selection, or
evaluate the function at a batch of multiple inputs at once. These two
different settings are commonly referred to as the sequential and batch
settings of Bayesian Optimization. In general, the sequential setting leads to
better optimization performance as each function evaluation is selected with
more information, whereas the batch setting has an advantage in terms of the
total experimental time (the number of iterations). In this work, our goal is
to combine the strength of both settings. Specifically, we systematically
analyze Bayesian optimization using Gaussian process as the posterior estimator
and provide a hybrid algorithm that, based on the current state, dynamically
switches between a sequential policy and a batch policy with variable batch
sizes. We provide theoretical justification for our algorithm and present
experimental results on eight benchmark BO problems. The results show that our
method achieves substantial speedup (up to %78) compared to a pure sequential
policy, without suffering any significant performance loss.",2012-02-25T02:00:51Z,"Javad Azimi, Ali Jalali, Xiaoli Fern"
1203.0550v3,Algorithms for Learning Kernels Based on Centered Alignment,"This paper presents new and effective algorithms for learning kernels. In
particular, as shown by our empirical results, these algorithms consistently
outperform the so-called uniform combination solution that has proven to be
difficult to improve upon in the past, as well as other algorithms for learning
kernels based on convex combinations of base kernels in both classification and
regression. Our algorithms are based on the notion of centered alignment which
is used as a similarity measure between kernels or kernel matrices. We present
a number of novel algorithmic, theoretical, and empirical results for learning
kernels based on our notion of centered alignment. In particular, we describe
efficient algorithms for learning a maximum alignment kernel by showing that
the problem can be reduced to a simple QP and discuss a one-stage algorithm for
learning both a kernel and a hypothesis based on that kernel using an
alignment-based regularization. Our theoretical results include a novel
concentration bound for centered alignment between kernel matrices, the proof
of the existence of effective predictors for kernels with high alignment, both
for classification and for regression, and the proof of stability-based
generalization bounds for a broad family of algorithms for learning kernels
based on centered alignment. We also report the results of experiments with our
centered alignment-based algorithms in both classification and regression.",2012-03-02T19:20:42Z,"Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh"
1203.2990v2,Evolving Culture vs Local Minima,"We propose a theory that relates difficulty of learning in deep architectures
to culture and language. It is articulated around the following hypotheses: (1)
learning in an individual human brain is hampered by the presence of effective
local minima; (2) this optimization difficulty is particularly important when
it comes to learning higher-level abstractions, i.e., concepts that cover a
vast and highly-nonlinear span of sensory configurations; (3) such high-level
abstractions are best represented in brains by the composition of many levels
of representation, i.e., by deep architectures; (4) a human brain can learn
such high-level abstractions if guided by the signals produced by other humans,
which act as hints or indirect supervision for these high-level abstractions;
and (5), language and the recombination and optimization of mental concepts
provide an efficient evolutionary recombination operator, and this gives rise
to rapid search in the space of communicable ideas that help humans build up
better high-level internal representations of their world. These hypotheses put
together imply that human culture and the evolution of ideas have been crucial
to counter an optimization difficulty: this optimization difficulty would
otherwise make it very difficult for human brains to capture high-level
knowledge of the world. The theory is grounded in experimental observations of
the difficulties of training deep artificial neural networks. Plausible
consequences of this theory for the efficiency of cultural evolutions are
sketched.",2012-03-14T02:38:35Z,Yoshua Bengio
1206.0855v1,A Mixed Observability Markov Decision Process Model for Musical Pitch,"Partially observable Markov decision processes have been widely used to
provide models for real-world decision making problems. In this paper, we will
provide a method in which a slightly different version of them called Mixed
observability Markov decision process, MOMDP, is going to join with our
problem. Basically, we aim at offering a behavioural model for interaction of
intelligent agents with musical pitch environment and we will show that how
MOMDP can shed some light on building up a decision making model for musical
pitch conveniently.",2012-06-05T09:35:44Z,"Pouyan Rafiei Fard, Keyvan Yahya"
1206.3382v2,"Simple Regret Optimization in Online Planning for Markov Decision
  Processes","We consider online planning in Markov decision processes (MDPs). In online
planning, the agent focuses on its current state only, deliberates about the
set of possible policies from that state onwards and, when interrupted, uses
the outcome of that exploratory deliberation to choose what action to perform
next. The performance of algorithms for online planning is assessed in terms of
simple regret, which is the agent's expected performance loss when the chosen
action, rather than an optimal one, is followed.
  To date, state-of-the-art algorithms for online planning in general MDPs are
either best effort, or guarantee only polynomial-rate reduction of simple
regret over time. Here we introduce a new Monte-Carlo tree search algorithm,
BRUE, that guarantees exponential-rate reduction of simple regret and error
probability. This algorithm is based on a simple yet non-standard state-space
sampling scheme, MCTS2e, in which different parts of each sample are dedicated
to different exploratory objectives. Our empirical evaluation shows that BRUE
not only provides superior performance guarantees, but is also very effective
in practice and favorably compares to state-of-the-art. We then extend BRUE
with a variant of ""learning by forgetting."" The resulting set of algorithms,
BRUE(alpha), generalizes BRUE, improves the exponential factor in the upper
bound on its reduction rate, and exhibits even more attractive empirical
performance.",2012-06-15T07:23:28Z,"Zohar Feldman, Carmel Domshlak"
1206.4604v1,Learning the Experts for Online Sequence Prediction,"Online sequence prediction is the problem of predicting the next element of a
sequence given previous elements. This problem has been extensively studied in
the context of individual sequence prediction, where no prior assumptions are
made on the origin of the sequence. Individual sequence prediction algorithms
work quite well for long sequences, where the algorithm has enough time to
learn the temporal structure of the sequence. However, they might give poor
predictions for short sequences. A possible remedy is to rely on the general
model of prediction with expert advice, where the learner has access to a set
of $r$ experts, each of which makes its own predictions on the sequence. It is
well known that it is possible to predict almost as well as the best expert if
the sequence length is order of $\log(r)$. But, without firm prior knowledge on
the problem, it is not clear how to choose a small set of {\em good} experts.
In this paper we describe and analyze a new algorithm that learns a good set of
experts using a training set of previously observed sequences. We demonstrate
the merits of our approach by applying it on the task of click prediction on
the web.",2012-06-18T14:42:16Z,"Elad Eban, Aharon Birnbaum, Shai Shalev-Shwartz, Amir Globerson"
1206.4639v1,Adaptive Regularization for Weight Matrices,"Algorithms for learning distributions over weight-vectors, such as AROW were
recently shown empirically to achieve state-of-the-art performance at various
problems, with strong theoretical guaranties. Extending these algorithms to
matrix models pose challenges since the number of free parameters in the
covariance of the distribution scales as $n^4$ with the dimension $n$ of the
matrix, and $n$ tends to be large in real applications. We describe, analyze
and experiment with two new algorithms for learning distribution of matrix
models. Our first algorithm maintains a diagonal covariance over the parameters
and can handle large covariance matrices. The second algorithm factors the
covariance to capture inter-features correlation while keeping the number of
parameters linear in the size of the original matrix. We analyze both
algorithms in the mistake bound model and show a superior precision performance
of our approach over other algorithms in two tasks: retrieving similar images,
and ranking similar documents. The factored algorithm is shown to attain faster
convergence rate.",2012-06-18T15:17:49Z,"Koby Crammer, Gal Chechik"
1206.4652v1,The Most Persistent Soft-Clique in a Set of Sampled Graphs,"When searching for characteristic subpatterns in potentially noisy graph
data, it appears self-evident that having multiple observations would be better
than having just one. However, it turns out that the inconsistencies introduced
when different graph instances have different edge sets pose a serious
challenge. In this work we address this challenge for the problem of finding
maximum weighted cliques.
  We introduce the concept of most persistent soft-clique. This is subset of
vertices, that 1) is almost fully or at least densely connected, 2) occurs in
all or almost all graph instances, and 3) has the maximum weight. We present a
measure of clique-ness, that essentially counts the number of edge missing to
make a subset of vertices into a clique. With this measure, we show that the
problem of finding the most persistent soft-clique problem can be cast either
as: a) a max-min two person game optimization problem, or b) a min-min soft
margin optimization problem. Both formulations lead to the same solution when
using a partial Lagrangian method to solve the optimization problems. By
experiments on synthetic data and on real social network data, we show that the
proposed method is able to reliably find soft cliques in graph data, even if
that is distorted by random noise or unreliable observations.",2012-06-18T15:24:31Z,"Novi Quadrianto, Chao Chen, Christoph Lampert"
1206.6262v1,Scaling Life-long Off-policy Learning,"We pursue a life-long learning approach to artificial intelligence that makes
extensive use of reinforcement learning algorithms. We build on our prior work
with general value functions (GVFs) and the Horde architecture. GVFs have been
shown able to represent a wide variety of facts about the world's dynamics that
may be useful to a long-lived agent (Sutton et al. 2011). We have also
previously shown scaling - that thousands of on-policy GVFs can be learned
accurately in real-time on a mobile robot (Modayil, White & Sutton 2011). That
work was limited in that it learned about only one policy at a time, whereas
the greatest potential benefits of life-long learning come from learning about
many policies in parallel, as we explore in this paper. Many new challenges
arise in this off-policy learning setting. To deal with convergence and
efficiency challenges, we utilize the recently introduced GTD({\lambda})
algorithm. We show that GTD({\lambda}) with tile coding can simultaneously
learn hundreds of predictions for five simple target policies while following a
single random behavior policy, assessing accuracy with interspersed on-policy
tests. To escape the need for the tests, which preclude further scaling, we
introduce and empirically vali- date two online estimators of the off-policy
objective (MSPBE). Finally, we use the more efficient of the two estimators to
demonstrate off-policy learning at scale - the learning of value functions for
one thousand policies in real time on a physical robot. This ability
constitutes a significant step towards scaling life-long off-policy learning.",2012-06-27T13:27:56Z,"Adam White, Joseph Modayil, Richard S. Sutton"
1206.6473v1,Compositional Planning Using Optimal Option Models,"In this paper we introduce a framework for option model composition. Option
models are temporal abstractions that, like macro-operators in classical
planning, jump directly from a start state to an end state. Prior work has
focused on constructing option models from primitive actions, by intra-option
model learning; or on using option models to construct a value function, by
inter-option planning. We present a unified view of intra- and inter-option
model learning, based on a major generalisation of the Bellman equation. Our
fundamental operation is the recursive composition of option models into other
option models. This key idea enables compositional planning over many levels of
abstraction. We illustrate our framework using a dynamic programming algorithm
that simultaneously constructs optimal option models for multiple subgoals, and
also searches over those option models to provide rapid progress towards other
subgoals.",2012-06-27T19:59:59Z,"David Silver, Kamil Ciosek"
1206.6814v1,An Empirical Comparison of Algorithms for Aggregating Expert Predictions,"Predicting the outcomes of future events is a challenging problem for which a
variety of solution methods have been explored and attempted. We present an
empirical comparison of a variety of online and offline adaptive algorithms for
aggregating experts' predictions of the outcomes of five years of US National
Football League games (1319 games) using expert probability elicitations
obtained from an Internet contest called ProbabilitySports. We find that it is
difficult to improve over simple averaging of the predictions in terms of
prediction accuracy, but that there is room for improvement in quadratic loss.
Somewhat surprisingly, a Bayesian estimation algorithm which estimates the
variance of each expert's prediction exhibits the most consistent superior
performance over simple averaging among our collection of algorithms.",2012-06-27T15:37:14Z,"Varsha Dani, Omid Madani, David M Pennock, Sumit Sanghai, Brian Galebach"
1206.6838v1,Continuous Time Markov Networks,"A central task in many applications is reasoning about processes that change
in a continuous time. The mathematical framework of Continuous Time Markov
Processes provides the basic foundations for modeling such systems. Recently,
Nodelman et al introduced continuous time Bayesian networks (CTBNs), which
allow a compact representation of continuous-time processes over a factored
state space. In this paper, we introduce continuous time Markov networks
(CTMNs), an alternative representation language that represents a different
type of continuous-time dynamics. In many real life processes, such as
biological and chemical systems, the dynamics of the process can be naturally
described as an interplay between two forces - the tendency of each entity to
change its state, and the overall fitness or energy function of the entire
system. In our model, the first force is described by a continuous-time
proposal process that suggests possible local changes to the state of the
system at different rates. The second force is represented by a Markov network
that encodes the fitness, or desirability, of different states; a proposed
local change is then accepted with a probability that is a function of the
change in the fitness distribution. We show that the fitness distribution is
also the stationary distribution of the Markov process, so that this
representation provides a characterization of a temporal process whose
stationary distribution has a compact graphical representation. This allows us
to naturally capture a different type of structure in complex dynamical
processes, such as evolving biological sequences. We describe the semantics of
the representation, its basic properties, and how it compares to CTBNs. We also
provide algorithms for learning such models from data, and discuss its
applicability to biological sequence evolution.",2012-06-27T16:19:16Z,"Tal El-Hay, Nir Friedman, Daphne Koller, Raz Kupferman"
1207.1406v1,"A Conditional Random Field for Discriminatively-trained Finite-state
  String Edit Distance","The need to measure sequence similarity arises in information extraction,
object identity, data mining, biological sequence analysis, and other domains.
This paper presents discriminative string-edit CRFs, a finitestate conditional
random field model for edit sequences between strings. Conditional random
fields have advantages over generative approaches to this problem, such as pair
HMMs or the work of Ristad and Yianilos, because as conditionally-trained
methods, they enable the use of complex, arbitrary actions and features of the
input strings. As in generative models, the training data does not have to
specify the edit sequences between the given string pairs. Unlike generative
models, however, our model is trained on both positive and negative instances
of string pairs. We present positive experimental results on several data sets.",2012-07-04T16:20:45Z,"Andrew McCallum, Kedar Bellare, Fernando Pereira"
1207.4158v1,On the Choice of Regions for Generalized Belief Propagation,"Generalized belief propagation (GBP) has proven to be a promising technique
for approximate inference tasks in AI and machine learning. However, the choice
of a good set of clusters to be used in GBP has remained more of an art then a
science until this day. This paper proposes a sequential approach to adding new
clusters of nodes and their interactions (i.e. ""regions"") to the approximation.
We first review and analyze the recently introduced region graphs and find that
three kinds of operations (""split"", ""merge"" and ""death"") leave the free energy
and (under some conditions) the fixed points of GBP invariant. This leads to
the notion of ""weakly irreducible"" regions as the natural candidates to be
added to the approximation. Computational complexity of the GBP algorithm is
controlled by restricting attention to regions with small ""region-width"".
Combining the above with an efficient (i.e. local in the graph) measure to
predict the improved accuracy of GBP leads to the sequential ""region pursuit""
algorithm for adding new regions bottom-up to the region graph. Experiments
show that this algorithm can indeed perform close to optimally.",2012-07-11T15:01:36Z,Max Welling
1207.4167v1,"Predictive State Representations: A New Theory for Modeling Dynamical
  Systems","Modeling dynamical systems, both for control purposes and to make predictions
about their behavior, is ubiquitous in science and engineering. Predictive
state representations (PSRs) are a recently introduced class of models for
discrete-time dynamical systems. The key idea behind PSRs and the closely
related OOMs (Jaeger's observable operator models) is to represent the state of
the system as a set of predictions of observable outcomes of experiments one
can do in the system. This makes PSRs rather different from history-based
models such as nth-order Markov models and hidden-state-based models such as
HMMs and POMDPs. We introduce an interesting construct, the systemdynamics
matrix, and show how PSRs can be derived simply from it. We also use this
construct to show formally that PSRs are more general than both nth-order
Markov models and HMMs/POMDPs. Finally, we discuss the main difference between
PSRs and OOMs and conclude with directions for future work.",2012-07-11T15:05:10Z,"Satinder Singh, Michael James, Matthew Rudary"
1207.5536v1,MCTS Based on Simple Regret,"UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games
and Markov decision processes, is based on UCB, a sampling policy for the
Multi-armed Bandit problem (MAB) that minimizes the cumulative regret. However,
search differs from MAB in that in MCTS it is usually only the final ""arm pull""
(the actual move selection) that collects a reward, rather than all ""arm
pulls"". Therefore, it makes more sense to minimize the simple regret, as
opposed to the cumulative regret. We begin by introducing policies for
multi-armed bandits with lower finite-time and asymptotic simple regret than
UCB, using it to develop a two-stage scheme (SR+CR) for MCTS which outperforms
UCT empirically.
  Optimizing the sampling process is itself a metareasoning problem, a solution
of which can use value of information (VOI) techniques. Although the theory of
VOI for search exists, applying it to MCTS is non-trivial, as typical myopic
assumptions fail. Lacking a complete working VOI theory for MCTS, we
nevertheless propose a sampling scheme that is ""aware"" of VOI, achieving an
algorithm that in empirical evaluation outperforms both UCT and the other
proposed algorithms.",2012-07-23T21:13:40Z,"David Tolpin, Solomon Eyal Shimony"
1207.5589v1,VOI-aware MCTS,"UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games
and Markov decision processes, is based on UCB1, a sampling policy for the
Multi-armed Bandit problem (MAB) that minimizes the cumulative regret. However,
search differs from MAB in that in MCTS it is usually only the final ""arm pull""
(the actual move selection) that collects a reward, rather than all ""arm
pulls"". In this paper, an MCTS sampling policy based on Value of Information
(VOI) estimates of rollouts is suggested. Empirical evaluation of the policy
and comparison to UCB1 and UCT is performed on random MAB instances as well as
on Computer Go.",2012-07-24T04:55:02Z,"David Tolpin, Solomon Eyal Shimony"
1209.3818v4,Evolution and the structure of learning agents,"This paper presents the thesis that all learning agents of finite information
size are limited by their informational structure in what goals they can
efficiently learn to achieve in a complex environment. Evolutionary change is
critical for creating the required structure for all learning agents in any
complex environment. The thesis implies that there is no efficient universal
learning algorithm. An agent can go past the learning limits imposed by its
structure only by slow evolutionary change or blind search which in a very
complex environment can only give an agent an inefficient universal learning
capability that can work only in evolutionary timescales or improbable luck.",2012-09-18T00:13:53Z,Alok Raj
1209.5251v1,On Move Pattern Trends in a Large Go Games Corpus,"We process a large corpus of game records of the board game of Go and propose
a way of extracting summary information on played moves. We then apply several
basic data-mining methods on the summary information to identify the most
differentiating features within the summary information, and discuss their
correspondence with traditional Go knowledge. We show statistically significant
mappings of the features to player attributes such as playing strength or
informally perceived ""playing style"" (e.g. territoriality or aggressivity),
describe accurate classifiers for these attributes, and propose applications
including seeding real-work ranks of internet players, aiding in Go study and
tuning of Go-playing programs, or contribution to Go-theoretical discussion on
the scope of ""playing style"".",2012-09-24T12:54:18Z,"Petr Baudi, Josef Moudk"
1209.5601v1,Feature selection with test cost constraint,"Feature selection is an important preprocessing step in machine learning and
data mining. In real-world applications, costs, including money, time and other
resources, are required to acquire the features. In some cases, there is a test
cost constraint due to limited resources. We shall deliberately select an
informative and cheap feature subset for classification. This paper proposes
the feature selection with test cost constraint problem for this issue. The new
problem has a simple form while described as a constraint satisfaction problem
(CSP). Backtracking is a general algorithm for CSP, and it is efficient in
solving the new problem on medium-sized data. As the backtracking algorithm is
not scalable to large datasets, a heuristic algorithm is also developed.
Experimental results show that the heuristic algorithm can find the optimal
solution in most cases. We also redefine some existing feature selection
problems in rough sets, especially in decision-theoretic rough sets, from the
viewpoint of CSP. These new definitions provide insight to some new research
directions.",2012-09-25T13:21:40Z,"Fan Min, Qinghua Hu, William Zhu"
1210.0077v1,Optimistic Agents are Asymptotically Optimal,"We use optimism to introduce generic asymptotically optimal reinforcement
learning agents. They achieve, with an arbitrary finite or compact class of
environments, asymptotically optimal behavior. Furthermore, in the finite
deterministic case we provide finite error bounds.",2012-09-29T04:58:22Z,"Peter Sunehag, Marcus Hutter"
1210.1317v1,"Learning Heterogeneous Similarity Measures for Hybrid-Recommendations in
  Meta-Mining","The notion of meta-mining has appeared recently and extends the traditional
meta-learning in two ways. First it does not learn meta-models that provide
support only for the learning algorithm selection task but ones that support
the whole data-mining process. In addition it abandons the so called black-box
approach to algorithm description followed in meta-learning. Now in addition to
the datasets, algorithms also have descriptors, workflows as well. For the
latter two these descriptions are semantic, describing properties of the
algorithms. With the availability of descriptors both for datasets and data
mining workflows the traditional modelling techniques followed in
meta-learning, typically based on classification and regression algorithms, are
no longer appropriate. Instead we are faced with a problem the nature of which
is much more similar to the problems that appear in recommendation systems. The
most important meta-mining requirements are that suggestions should use only
datasets and workflows descriptors and the cold-start problem, e.g. providing
workflow suggestions for new datasets.
  In this paper we take a different view on the meta-mining modelling problem
and treat it as a recommender problem. In order to account for the meta-mining
specificities we derive a novel metric-based-learning recommender approach. Our
method learns two homogeneous metrics, one in the dataset and one in the
workflow space, and a heterogeneous one in the dataset-workflow space. All
learned metrics reflect similarities established from the dataset-workflow
preference matrix. We demonstrate our method on meta-mining over biological
(microarray datasets) problems. The application of our method is not limited to
the meta-mining problem, its formulations is general enough so that it can be
applied on problems with similar requirements.",2012-10-04T07:17:37Z,"Phong Nguyen, Jun Wang, Melanie Hilario, Alexandros Kalousis"
1210.2640v1,"Multi-view constrained clustering with an incomplete mapping between
  views","Multi-view learning algorithms typically assume a complete bipartite mapping
between the different views in order to exchange information during the
learning process. However, many applications provide only a partial mapping
between the views, creating a challenge for current methods. To address this
problem, we propose a multi-view algorithm based on constrained clustering that
can operate with an incomplete mapping. Given a set of pairwise constraints in
each view, our approach propagates these constraints using a local similarity
measure to those instances that can be mapped to the other views, allowing the
propagated constraints to be transferred across views via the partial mapping.
It uses co-EM to iteratively estimate the propagation within each view based on
the current clustering model, transfer the constraints across views, and then
update the clustering model. By alternating the learning process between views,
this approach produces a unified clustering model that is consistent with all
views. We show that this approach significantly improves clustering performance
over several other methods for transferring constraints and allows multi-view
clustering to be reliably applied when given a limited mapping between the
views. Our evaluation reveals that the propagated constraints have high
precision with respect to the true clusters in the data, explaining their
benefit to clustering performance in both single- and multi-view learning
scenarios.",2012-10-09T15:25:01Z,"Eric Eaton, Marie desJardins, Sara Jacob"
1210.4870v1,Crowdsourcing Control: Moving Beyond Multiple Choice,"To ensure quality results from crowdsourced tasks, requesters often aggregate
worker responses and use one of a plethora of strategies to infer the correct
answer from the set of noisy responses. However, all current models assume
prior knowledge of all possible outcomes of the task. While not an unreasonable
assumption for tasks that can be posited as multiple-choice questions (e.g.
n-ary classification), we observe that many tasks do not naturally fit this
paradigm, but instead demand a free-response formulation where the outcome
space is of infinite size (e.g. audio transcription). We model such tasks with
a novel probabilistic graphical model, and design and implement LazySusan, a
decision-theoretic controller that dynamically requests responses as necessary
in order to infer answers to these tasks. We also design an EM algorithm to
jointly learn the parameters of our model while inferring the correct answers
to multiple tasks at a time. Live experiments on Amazon Mechanical Turk
demonstrate the superiority of LazySusan at solving SAT Math questions,
eliminating 83.2% of the error and achieving greater net utility compared to
the state-ofthe-art strategy, majority-voting. We also show in live experiments
that our EM algorithm outperforms majority-voting on a visualization task that
we design.",2012-10-16T17:41:19Z,"Christopher H. Lin,  Mausam, Daniel Weld"
1210.8291v1,Learning in the Model Space for Fault Diagnosis,"The emergence of large scaled sensor networks facilitates the collection of
large amounts of real-time data to monitor and control complex engineering
systems. However, in many cases the collected data may be incomplete or
inconsistent, while the underlying environment may be time-varying or
un-formulated. In this paper, we have developed an innovative cognitive fault
diagnosis framework that tackles the above challenges. This framework
investigates fault diagnosis in the model space instead of in the signal space.
Learning in the model space is implemented by fitting a series of models using
a series of signal segments selected with a rolling window. By investigating
the learning techniques in the fitted model space, faulty models can be
discriminated from healthy models using one-class learning algorithm. The
framework enables us to construct fault library when unknown faults occur,
which can be regarded as cognitive fault isolation. This paper also
theoretically investigates how to measure the pairwise distance between two
models in the model space and incorporates the model distance into the learning
algorithm in the model space. The results on three benchmark applications and
one simulated model for the Barcelona water distribution network have confirmed
the effectiveness of the proposed framework.",2012-10-31T10:42:32Z,"Huanhuan Chen, Peter Tino, Xin Yao, Ali Rodan"
1210.8385v1,First Experiments with PowerPlay,"Like a scientist or a playing child, PowerPlay not only learns new skills to
solve given problems, but also invents new interesting problems by itself. By
design, it continually comes up with the fastest to find, initially novel, but
eventually solvable tasks. It also continually simplifies or compresses or
speeds up solutions to previous tasks. Here we describe first experiments with
PowerPlay. A self-delimiting recurrent neural network SLIM RNN is used as a
general computational problem solving architecture. Its connection weights can
encode arbitrary, self-delimiting, halting or non-halting programs affecting
both environment (through effectors) and internal states encoding abstractions
of event sequences. Our PowerPlay-driven SLIM RNN learns to become an
increasingly general solver of self-invented problems, continually adding new
problem solving procedures to its growing skill repertoire. Extending a recent
conference paper, we identify interesting, emerging, developmental stages of
our open-ended system. We also show how it automatically self-modularizes,
frequently re-using code for previously invented skills, always trying to
invent novel tasks that can be quickly validated because they do not require
too many weight changes affecting too many previous tasks.",2012-10-31T16:41:37Z,"Rupesh Kumar Srivastava, Bas R. Steunebrink, Jrgen Schmidhuber"
1212.0692v2,An Empirical Evaluation of Portfolios Approaches for solving CSPs,"Recent research in areas such as SAT solving and Integer Linear Programming
has shown that the performances of a single arbitrarily efficient solver can be
significantly outperformed by a portfolio of possibly slower on-average
solvers. We report an empirical evaluation and comparison of portfolio
approaches applied to Constraint Satisfaction Problems (CSPs). We compared
models developed on top of off-the-shelf machine learning algorithms with
respect to approaches used in the SAT field and adapted for CSPs, considering
different portfolio sizes and using as evaluation metrics the number of solved
problems and the time taken to solve them. Results indicate that the best SAT
approaches have top performances also in the CSP field and are slightly more
competitive than simple models built on top of classification algorithms.",2012-12-04T12:00:54Z,"Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro"
1212.2262v1,Bag-of-Words Representation for Biomedical Time Series Classification,"Automatic analysis of biomedical time series such as electroencephalogram
(EEG) and electrocardiographic (ECG) signals has attracted great interest in
the community of biomedical engineering due to its important applications in
medicine. In this work, a simple yet effective bag-of-words representation that
is able to capture both local and global structure similarity information is
proposed for biomedical time series representation. In particular, similar to
the bag-of-words model used in text document domain, the proposed method treats
a time series as a text document and extracts local segments from the time
series as words. The biomedical time series is then represented as a histogram
of codewords, each entry of which is the count of a codeword appeared in the
time series. Although the temporal order of the local segments is ignored, the
bag-of-words representation is able to capture high-level structural
information because both local and global structural information are well
utilized. The performance of the bag-of-words model is validated on three
datasets extracted from real EEG and ECG signals. The experimental results
demonstrate that the proposed method is not only insensitive to parameters of
the bag-of-words model such as local segment length and codebook size, but also
robust to noise.",2012-12-11T00:49:27Z,"Jin Wang, Ping Liu, Mary F. H. She, Saeid Nahavandi, and Abbas Kouzani"
1301.0567v1,"The Thing That We Tried Didn't Work Very Well : Deictic Representation
  in Reinforcement Learning","Most reinforcement learning methods operate on propositional representations
of the world state. Such representations are often intractably large and
generalize poorly. Using a deictic representation is believed to be a viable
alternative: they promise generalization while allowing the use of existing
reinforcement-learning methods. Yet, there are few experiments on learning with
deictic representations reported in the literature. In this paper we explore
the effectiveness of two forms of deictic representation and a na\""{i}ve
propositional representation in a simple blocks-world domain. We find,
empirically, that the deictic representations actually worsen learning
performance. We conclude with a discussion of possible causes of these results
and strategies for more effective learning in domains with objects.",2012-12-12T15:56:10Z,"Sarah Finney, Natalia Gardiol, Leslie Pack Kaelbling, Tim Oates"
1301.0598v1,Asymptotic Model Selection for Naive Bayesian Networks,"We develop a closed form asymptotic formula to compute the marginal
likelihood of data given a naive Bayesian network model with two hidden states
and binary features. This formula deviates from the standard BIC score. Our
work provides a concrete example that the BIC score is generally not valid for
statistical models that belong to a stratified exponential family. This stands
in contrast to linear and curved exponential families, where the BIC score has
been proven to provide a correct approximation for the marginal likelihood.",2012-12-12T15:58:13Z,"Dmitry Rusakov, Dan Geiger"
1301.2268v1,"Incorporating Expressive Graphical Models in Variational Approximations:
  Chain-Graphs and Hidden Variables","Global variational approximation methods in graphical models allow efficient
approximate inference of complex posterior distributions by using a simpler
model. The choice of the approximating model determines a tradeoff between the
complexity of the approximation procedure and the quality of the approximation.
In this paper, we consider variational approximations based on two classes of
models that are richer than standard Bayesian networks, Markov networks or
mixture models. As such, these classes allow to find better tradeoffs in the
spectrum of approximations. The first class of models are chain graphs, which
capture distributions that are partially directed. The second class of models
are directed graphs (Bayesian networks) with additional latent variables. Both
classes allow representation of multi-variable dependencies that cannot be
easily represented within a Bayesian network.",2013-01-10T16:23:26Z,"Tal El-Hay, Nir Friedman"
1301.2292v1,A Bayesian Multiresolution Independence Test for Continuous Variables,"In this paper we present a method ofcomputing the posterior probability
ofconditional independence of two or morecontinuous variables from
data,examined at several resolutions. Ourapproach is motivated by
theobservation that the appearance ofcontinuous data varies widely atvarious
resolutions, producing verydifferent independence estimatesbetween the
variablesinvolved. Therefore, it is difficultto ascertain independence
withoutexamining data at several carefullyselected resolutions. In our paper,
weaccomplish this using the exactcomputation of the posteriorprobability of
independence, calculatedanalytically given a resolution. Ateach examined
resolution, we assume amultinomial distribution with Dirichletpriors for the
discretized tableparameters, and compute the posteriorusing Bayesian
integration. Acrossresolutions, we use a search procedureto approximate the
Bayesian integral ofprobability over an exponential numberof possible
histograms. Our methodgeneralizes to an arbitrary numbervariables in a
straightforward manner.The test is suitable for Bayesiannetwork learning
algorithms that useindependence tests to infer the networkstructure, in domains
that contain anymix of continuous, ordinal andcategorical variables.",2013-01-10T16:25:12Z,"Dimitris Margaritis, Sebastian Thrun"
1301.2294v1,Expectation Propagation for approximate Bayesian inference,"This paper presents a new deterministic approximation technique in Bayesian
networks. This method, ""Expectation Propagation"", unifies two previous
techniques: assumed-density filtering, an extension of the Kalman filter, and
loopy belief propagation, an extension of belief propagation in Bayesian
networks. All three algorithms try to recover an approximate distribution which
is close in KL divergence to the true distribution. Loopy belief propagation,
because it propagates exact belief states, is useful for a limited class of
belief networks, such as those which are purely discrete. Expectation
Propagation approximates the belief states by only retaining certain
expectations, such as mean and variance, and iterates until these expectations
are consistent throughout the network. This makes it applicable to hybrid
networks with discrete and continuous nodes. Expectation Propagation also
extends belief propagation in the opposite direction - it can propagate richer
belief states that incorporate correlations between nodes. Experiments with
Gaussian mixture models show Expectation Propagation to be convincingly better
than methods with similar computational cost: Laplace's method, variational
Bayes, and Monte Carlo. Expectation Propagation also provides an efficient
algorithm for training Bayes point machine classifiers.",2013-01-10T16:25:20Z,Thomas P. Minka
1301.2310v1,Policy Improvement for POMDPs Using Normalized Importance Sampling,"We present a new method for estimating the expected return of a POMDP from
experience. The method does not assume any knowledge of the POMDP and allows
the experience to be gathered from an arbitrary sequence of policies. The
return is estimated for any new policy of the POMDP. We motivate the estimator
from function-approximation and importance sampling points-of-view and derive
its theoretical properties. Although the estimator is biased, it has low
variance and the bias is often irrelevant when the estimator is used for
pair-wise comparisons. We conclude by extending the estimator to policies with
memory and compare its performance in a greedy search algorithm to REINFORCE
algorithms showing an order of magnitude reduction in the number of trials
required.",2013-01-10T16:26:30Z,Christian R. Shelton
1301.2317v1,"Belief Optimization for Binary Networks: A Stable Alternative to Loopy
  Belief Propagation","We present a novel inference algorithm for arbitrary, binary, undirected
graphs. Unlike loopy belief propagation, which iterates fixed point equations,
we directly descend on the Bethe free energy. The algorithm consists of two
phases, first we update the pairwise probabilities, given the marginal
probabilities at each unit,using an analytic expression. Next, we update the
marginal probabilities, given the pairwise probabilities by following the
negative gradient of the Bethe free energy. Both steps are guaranteed to
decrease the Bethe free energy, and since it is lower bounded, the algorithm is
guaranteed to converge to a local minimum. We also show that the Bethe free
energy is equal to the TAP free energy up to second order in the weights. In
experiments we confirm that when belief propagation converges it usually finds
identical solutions as our belief optimization method. However, in cases where
belief propagation fails to converge, belief optimization continues to converge
to reasonable beliefs. The stable nature of belief optimization makes it
ideally suited for learning graphical models from data.",2013-01-10T16:27:02Z,"Max Welling, Yee Whye Teh"
1301.2343v1,Planning by Prioritized Sweeping with Small Backups,"Efficient planning plays a crucial role in model-based reinforcement
learning. Traditionally, the main planning operation is a full backup based on
the current estimates of the successor states. Consequently, its computation
time is proportional to the number of successor states. In this paper, we
introduce a new planning backup that uses only the current value of a single
successor state and has a computation time independent of the number of
successor states. This new backup, which we call a small backup, opens the door
to a new class of model-based reinforcement learning methods that exhibit much
finer control over their planning process than traditional methods. We
empirically demonstrate that this increased flexibility allows for more
efficient planning by showing that an implementation of prioritized sweeping
based on small backups achieves a substantial performance improvement over
classical implementations.",2013-01-10T21:54:42Z,"Harm van Seijen, Richard S. Sutton"
1301.3720v2,The IBMAP approach for Markov networks structure learning,"In this work we consider the problem of learning the structure of Markov
networks from data. We present an approach for tackling this problem called
IBMAP, together with an efficient instantiation of the approach: the IBMAP-HC
algorithm, designed for avoiding important limitations of existing
independence-based algorithms. These algorithms proceed by performing
statistical independence tests on data, trusting completely the outcome of each
test. In practice tests may be incorrect, resulting in potential cascading
errors and the consequent reduction in the quality of the structures learned.
IBMAP contemplates this uncertainty in the outcome of the tests through a
probabilistic maximum-a-posteriori approach. The approach is instantiated in
the IBMAP-HC algorithm, a structure selection strategy that performs a
polynomial heuristic local search in the space of possible structures. We
present an extensive empirical evaluation on synthetic and real data, showing
that our algorithm outperforms significantly the current independence-based
algorithms, in terms of data efficiency and quality of learned structures, with
equivalent computational complexities. We also show the performance of IBMAP-HC
in a real-world application of knowledge discovery: EDAs, which are
evolutionary algorithms that use structure learning on each generation for
modeling the distribution of populations. The experiments show that when
IBMAP-HC is used to learn the structure, EDAs improve the convergence to the
optimum.",2013-01-16T15:21:19Z,"Federico Schlter, Facundo Bromberg, Alejandro Edera"
1301.3840v1,"Utilities as Random Variables: Density Estimation and Structure
  Discovery","Decision theory does not traditionally include uncertainty over utility
functions. We argue that the a person's utility value for a given outcome can
be treated as we treat other domain attributes: as a random variable with a
density function over its possible values. We show that we can apply
statistical density estimation techniques to learn such a density function from
a database of partially elicited utility functions. In particular, we define a
Bayesian learning framework for this problem, assuming the distribution over
utilities is a mixture of Gaussians, where the mixture components represent
statistically coherent subpopulations. We can also extend our techniques to the
problem of discovering generalized additivity structure in the utility
functions in the population. We define a Bayesian model selection criterion for
utility function structure and a search procedure over structures. The
factorization of the utilities in the learned model, and the generalization
obtained from density estimation, allows us to provide robust estimates of
utilities using a significantly smaller number of utility elicitation
questions. We experiment with our technique on synthetic utility data and on a
real database of utility functions in the domain of prenatal diagnosis.",2013-01-16T15:49:11Z,"Urszula Chajewska, Daphne Koller"
1301.3861v1,Inference for Belief Networks Using Coupling From the Past,"Inference for belief networks using Gibbs sampling produces a distribution
for unobserved variables that differs from the correct distribution by a
(usually) unknown error, since convergence to the right distribution occurs
only asymptotically. The method of ""coupling from the past"" samples from
exactly the correct distribution by (conceptually) running dependent Gibbs
sampling simulations from every possible starting state from a time far enough
in the past that all runs reach the same state at time t=0. Explicitly
considering every possible state is intractable for large networks, however. We
propose a method for layered noisy-or networks that uses a compact, but often
imprecise, summary of a set of states. This method samples from exactly the
correct distribution, and requires only about twice the time per step as
ordinary Gibbs sampling, but it may require more simulation steps than would be
needed if chains were tracked exactly.",2013-01-16T15:50:34Z,"Michael Harvey, Radford M. Neal"
1301.3878v1,PEGASUS: A Policy Search Method for Large MDPs and POMDPs,"We propose a new approach to the problem of searching a space of policies for
a Markov decision process (MDP) or a partially observable Markov decision
process (POMDP), given a model. Our approach is based on the following
observation: Any (PO)MDP can be transformed into an ""equivalent"" POMDP in which
all state transitions (given the current state and action) are deterministic.
This reduces the general problem of policy search to one in which we need only
consider POMDPs with deterministic transitions. We give a natural way of
estimating the value of all policies in these transformed POMDPs. Policy search
is then simply performed by searching for a policy with high estimated value.
We also establish conditions under which our value estimates will be good,
recovering theoretical results similar to those of Kearns, Mansour and Ng
(1999), but with ""sample complexity"" bounds that have only a polynomial rather
than exponential dependence on the horizon time. Our method applies to
arbitrary POMDPs, including ones with infinite state and action spaces. We also
present empirical results for our approach on a small discrete problem, and on
a complex continuous state/continuous action problem involving learning to ride
a bicycle.",2013-01-16T15:51:42Z,"Andrew Y. Ng, Michael I. Jordan"
1301.6683v1,Discovering the Hidden Structure of Complex Dynamic Systems,"Dynamic Bayesian networks provide a compact and natural representation for
complex dynamic systems. However, in many cases, there is no expert available
from whom a model can be elicited. Learning provides an alternative approach
for constructing models of dynamic systems. In this paper, we address some of
the crucial computational aspects of learning the structure of dynamic systems,
particularly those where some relevant variables are partially observed or even
entirely unknown. Our approach is based on the Structural Expectation
Maximization (SEM) algorithm. The main computational cost of the SEM algorithm
is the gathering of expected sufficient statistics. We propose a novel
approximation scheme that allows these sufficient statistics to be computed
efficiently. We also investigate the fundamental problem of discovering the
existence of hidden variables without exhaustive and expensive search. Our
approach is based on the observation that, in dynamic systems, ignoring a
hidden variable typically results in a violation of the Markov property. Thus,
our algorithm searches for such violations in the data, and introduces hidden
variables to explain them. We provide empirical results showing that the
algorithm is able to learn the dynamics of complex systems in a computationally
tractable way.",2013-01-23T15:57:10Z,"Xavier Boyen, Nir Friedman, Daphne Koller"
1301.6688v1,Learning Polytrees,"We consider the task of learning the maximum-likelihood polytree from data.
Our first result is a performance guarantee establishing that the optimal
branching (or Chow-Liu tree), which can be computed very easily, constitutes a
good approximation to the best polytree. We then show that it is not possible
to do very much better, since the learning problem is NP-hard even to
approximately solve within some constant factor.",2013-01-23T15:57:30Z,Sanjoy Dasgupta
1301.6690v1,Model-Based Bayesian Exploration,"Reinforcement learning systems are often concerned with balancing exploration
of untested actions against exploitation of actions that are known to be good.
The benefit of exploration can be estimated using the classical notion of Value
of Information - the expected improvement in future decision quality arising
from the information acquired by exploration. Estimating this quantity requires
an assessment of the agent's uncertainty about its current value estimates for
states. In this paper we investigate ways of representing and reasoning about
this uncertainty in algorithms where the system attempts to learn a model of
its environment. We explicitly represent uncertainty about the parameters of
the model and build probability distributions over Q-values based on these.
These distributions are used to compute a myopic approximation to the value of
information for each action and hence to select the action that best balances
exploration and exploitation.",2013-01-23T15:57:38Z,"Richard Dearden, Nir Friedman, David Andre"
1301.6725v1,Loopy Belief Propagation for Approximate Inference: An Empirical Study,"Recently, researchers have demonstrated that loopy belief propagation - the
use of Pearls polytree algorithm IN a Bayesian network WITH loops OF error-
correcting codes.The most dramatic instance OF this IS the near Shannon - limit
performance OF Turbo Codes codes whose decoding algorithm IS equivalent TO
loopy belief propagation IN a chain - structured Bayesian network. IN this
paper we ask : IS there something special about the error - correcting code
context, OR does loopy propagation WORK AS an approximate inference schemeIN a
more general setting? We compare the marginals computed using loopy propagation
TO the exact ones IN four Bayesian network architectures, including two real -
world networks : ALARM AND QMR.We find that the loopy beliefs often converge
AND WHEN they do, they give a good approximation TO the correct
marginals.However,ON the QMR network, the loopy beliefs oscillated AND had no
obvious relationship TO the correct posteriors. We present SOME initial
investigations INTO the cause OF these oscillations, AND show that SOME simple
methods OF preventing them lead TO the wrong results.",2013-01-23T16:00:02Z,"Kevin Murphy, Yair Weiss, Michael I. Jordan"
1301.6726v1,"Learning Bayesian Networks from Incomplete Data with Stochastic Search
  Algorithms","This paper describes stochastic search approaches, including a new stochastic
algorithm and an adaptive mutation operator, for learning Bayesian networks
from incomplete data. This problem is characterized by a huge solution space
with a highly multimodal landscape. State-of-the-art approaches all involve
using deterministic approaches such as the expectation-maximization algorithm.
These approaches are guaranteed to find local maxima, but do not explore the
landscape for other modes. Our approach evolves structure and the missing data.
We compare our stochastic algorithms and show they all produce accurate
results.",2013-01-23T16:00:06Z,"James W. Myers, Kathryn Blackmond Laskey, Tod S. Levitt"
1301.7374v1,Learning the Structure of Dynamic Probabilistic Networks,"Dynamic probabilistic networks are a compact representation of complex
stochastic processes. In this paper we examine how to learn the structure of a
DPN from data. We extend structure scoring rules for standard probabilistic
networks to the dynamic case, and show how to search for structure when some of
the variables are hidden. Finally, we examine two applications where such a
technology might be useful: predicting and classifying dynamic behaviors, and
learning causal orderings in biological processes. We provide empirical results
that demonstrate the applicability of our methods in both domains.",2013-01-30T15:03:42Z,"Nir Friedman, Kevin Murphy, Stuart Russell"
1301.7403v1,"A Multivariate Discretization Method for Learning Bayesian Networks from
  Mixed Data","In this paper we address the problem of discretization in the context of
learning Bayesian networks (BNs) from data containing both continuous and
discrete variables. We describe a new technique for <EM>multivariate</EM>
discretization, whereby each continuous variable is discretized while taking
into account its interaction with the other variables. The technique is based
on the use of a Bayesian scoring metric that scores the discretization policy
for a continuous variable given a BN structure and the observed data. Since the
metric is relative to the BN structure currently being evaluated, the
discretization of a variable needs to be dynamically adjusted as the BN
structure changes.",2013-01-30T15:06:05Z,"Stefano Monti, Gregory F. Cooper"
1302.1529v1,Exploring Parallelism in Learning Belief Networks,"It has been shown that a class of probabilistic domain models cannot be
learned correctly by several existing algorithms which employ a single-link
look ahead search. When a multi-link look ahead search is used, the
computational complexity of the learning algorithm increases. We study how to
use parallelism to tackle the increased complexity in learning such models and
to speed up learning in large domains. An algorithm is proposed to decompose
the learning task for parallel processing. A further task decomposition is used
to balance load among processors and to increase the speed-up and efficiency.
For learning from very large datasets, we present a regrouping of the available
processors such that slow data access through file can be replaced by fast
memory access. Our implementation in a parallel computer demonstrates the
effectiveness of the algorithm.",2013-02-06T15:54:31Z,"TongSheng Chu, Yang Xiang"
1302.1538v1,Sequential Update of Bayesian Network Structure,"There is an obvious need for improving the performance and accuracy of a
Bayesian network as new data is observed. Because of errors in model
construction and changes in the dynamics of the domains, we cannot afford to
ignore the information in new data. While sequential update of parameters for a
fixed structure can be accomplished using standard techniques, sequential
update of network structure is still an open problem. In this paper, we
investigate sequential update of Bayesian networks were both parameters and
structure are expected to change. We introduce a new approach that allows for
the flexible manipulation of the tradeoff between the quality of the learned
networks and the amount of information that is maintained about past
observations. We formally describe our approach including the necessary
modifications to the scoring functions for learning Bayesian networks, evaluate
its effectiveness through an empirical study, and extend it to the case of
missing data.",2013-02-06T15:55:21Z,"Nir Friedman, Moises Goldszmidt"
1302.1542v1,Learning Bayesian Nets that Perform Well,"A Bayesian net (BN) is more than a succinct way to encode a probabilistic
distribution; it also corresponds to a function used to answer queries. A BN
can therefore be evaluated by the accuracy of the answers it returns. Many
algorithms for learning BNs, however, attempt to optimize another criterion
(usually likelihood, possibly augmented with a regularizing term), which is
independent of the distribution of queries that are posed. This paper takes the
""performance criteria"" seriously, and considers the challenge of computing the
BN whose performance - read ""accuracy over the distribution of queries"" - is
optimal. We show that many aspects of this learning task are more difficult
than the corresponding subtasks in the standard model.",2013-02-06T15:55:43Z,"Russell Greiner, Adam J. Grove, Dale Schuurmans"
1302.1549v1,"Learning Belief Networks in Domains with Recursively Embedded Pseudo
  Independent Submodels","A pseudo independent (PI) model is a probabilistic domain model (PDM) where
proper subsets of a set of collectively dependent variables display marginal
independence. PI models cannot be learned correctly by many algorithms that
rely on a single link search. Earlier work on learning PI models has suggested
a straightforward multi-link search algorithm. However, when a domain contains
recursively embedded PI submodels, it may escape the detection of such an
algorithm. In this paper, we propose an improved algorithm that ensures the
learning of all embedded PI submodels whose sizes are upper bounded by a
predetermined parameter. We show that this improved learning capability only
increases the complexity slightly beyond that of the previous algorithm. The
performance of the new algorithm is demonstrated through experiment.",2013-02-06T15:56:57Z,"Jun Hu, Yang Xiang"
1302.1561v2,"Structure and Parameter Learning for Causal Independence and Causal
  Interaction Models","This paper discusses causal independence models and a generalization of these
models called causal interaction models. Causal interaction models are models
that have independent mechanisms where a mechanism can have several causes. In
addition to introducing several particular types of causal interaction models,
we show how we can apply the Bayesian approach to learning causal interaction
models obtaining approximate posterior distributions for the models and obtain
MAP and ML estimates for the parameters. We illustrate the approach with a
simulation study of learning model posteriors.",2013-02-06T15:58:24Z,"Christopher Meek, David Heckerman"
1302.1565v1,Learning Bayesian Networks from Incomplete Databases,"Bayesian approaches to learn the graphical structure of Bayesian Belief
Networks (BBNs) from databases share the assumption that the database is
complete, that is, no entry is reported as unknown. Attempts to relax this
assumption involve the use of expensive iterative methods to discriminate among
different structures. This paper introduces a deterministic method to learn the
graphical structure of a BBN from a possibly incomplete database. Experimental
evaluations show a significant robustness of this method and a remarkable
independence of its execution time from the number of missing data.",2013-02-06T15:58:45Z,"Marco Ramoni, Paola Sebastiani"
1302.4949v1,"A Characterization of the Dirichlet Distribution with Application to
  Learning Bayesian Networks","We provide a new characterization of the Dirichlet distribution. This
characterization implies that under assumptions made by several previous
authors for learning belief networks, a Dirichlet prior on the parameters is
inevitable.",2013-02-20T15:20:41Z,"Dan Geiger, David Heckerman"
1302.6617v1,"Arriving on time: estimating travel time distributions on large-scale
  road networks","Most optimal routing problems focus on minimizing travel time or distance
traveled. Oftentimes, a more useful objective is to maximize the probability of
on-time arrival, which requires statistical distributions of travel times,
rather than just mean values. We propose a method to estimate travel time
distributions on large-scale road networks, using probe vehicle data collected
from GPS. We present a framework that works with large input of data, and
scales linearly with the size of the network. Leveraging the planar topology of
the graph, the method computes efficiently the time correlations between
neighboring streets. First, raw probe vehicle traces are compressed into pairs
of travel times and number of stops for each traversed road segment using a
`stop-and-go' algorithm developed for this work. The compressed data is then
used as input for training a path travel time model, which couples a Markov
model along with a Gaussian Markov random field. Finally, scalable inference
algorithms are developed for obtaining path travel time distributions from the
composite MM-GMRF model. We illustrate the accuracy and scalability of our
model on a 505,000 road link network spanning the San Francisco Bay Area.",2013-02-26T22:36:46Z,"Timothy Hunter, Aude Hofleitner, Jack Reilly, Walid Krichene, Jerome Thai, Anastasios Kouvelas, Pieter Abbeel, Alexandre Bayen"
1304.6383v2,"The Stochastic Gradient Descent for the Primal L1-SVM Optimization
  Revisited","We reconsider the stochastic (sub)gradient approach to the unconstrained
primal L1-SVM optimization. We observe that if the learning rate is inversely
proportional to the number of steps, i.e., the number of times any training
pattern is presented to the algorithm, the update rule may be transformed into
the one of the classical perceptron with margin in which the margin threshold
increases linearly with the number of steps. Moreover, if we cycle repeatedly
through the possibly randomly permuted training set the dual variables defined
naturally via the expansion of the weight vector as a linear combination of the
patterns on which margin errors were made are shown to obey at the end of each
complete cycle automatically the box constraints arising in dual optimization.
This renders the dual Lagrangian a running lower bound on the primal objective
tending to it at the optimum and makes available an upper bound on the relative
accuracy achieved which provides a meaningful stopping criterion. In addition,
we propose a mechanism of presenting the same pattern repeatedly to the
algorithm which maintains the above properties. Finally, we give experimental
evidence that algorithms constructed along these lines exhibit a considerably
improved performance.",2013-04-23T19:24:02Z,"Constantinos Panagiotakopoulos, Petroula Tsampouka"
1305.1679v1,High Level Pattern Classification via Tourist Walks in Networks,"Complex networks refer to large-scale graphs with nontrivial connection
patterns. The salient and interesting features that the complex network study
offer in comparison to graph theory are the emphasis on the dynamical
properties of the networks and the ability of inherently uncovering pattern
formation of the vertices. In this paper, we present a hybrid data
classification technique combining a low level and a high level classifier. The
low level term can be equipped with any traditional classification techniques,
which realize the classification task considering only physical features (e.g.,
geometrical or statistical features) of the input data. On the other hand, the
high level term has the ability of detecting data patterns with semantic
meanings. In this way, the classification is realized by means of the
extraction of the underlying network's features constructed from the input
data. As a result, the high level classification process measures the
compliance of the test instances with the pattern formation of the training
data. Out of various high level perspectives that can be utilized to capture
semantic meaning, we utilize the dynamical features that are generated from a
tourist walker in a networked environment. Specifically, a weighted combination
of transient and cycle lengths generated by the tourist walk is employed for
that end. Interestingly, our study shows that the proposed technique is able to
further improve the already optimized performance of traditional classification
techniques.",2013-05-07T23:40:08Z,"Thiago Christiano Silva, Liang Zhao"
1305.2218v1,"Stochastic gradient descent algorithms for strongly convex functions at
  O(1/T) convergence rates","With a weighting scheme proportional to t, a traditional stochastic gradient
descent (SGD) algorithm achieves a high probability convergence rate of
O({\kappa}/T) for strongly convex functions, instead of O({\kappa} ln(T)/T). We
also prove that an accelerated SGD algorithm also achieves a rate of
O({\kappa}/T).",2013-05-09T21:31:47Z,Shenghuo Zhu
1305.4955v2,A Data Mining Approach to Solve the Goal Scoring Problem,"In soccer, scoring goals is a fundamental objective which depends on many
conditions and constraints. Considering the RoboCup soccer 2D-simulator, this
paper presents a data mining-based decision system to identify the best time
and direction to kick the ball towards the goal to maximize the overall chances
of scoring during a simulated soccer match. Following the CRISP-DM methodology,
data for modeling were extracted from matches of major international
tournaments (10691 kicks), knowledge about soccer was embedded via
transformation of variables and a Multilayer Perceptron was used to estimate
the scoring chance. Experimental performance assessment to compare this
approach against previous LDA-based approach was conducted from 100 matches.
Several statistical metrics were used to analyze the performance of the system
and the results showed an increase of 7.7% in the number of kicks, producing an
overall increase of 78% in the number of goals scored.",2013-05-21T20:29:02Z,"Renato Oliveira, Paulo Adeodato, Arthur Carvalho, Icamaan Viegas, Christian Diego, Tsang Ing-Ren"
1306.0539v1,"On the Performance Bounds of some Policy Search Dynamic Programming
  Algorithms","We consider the infinite-horizon discounted optimal control problem
formalized by Markov Decision Processes. We focus on Policy Search algorithms,
that compute an approximately optimal policy by following the standard Policy
Iteration (PI) scheme via an -approximate greedy operator (Kakade and Langford,
2002; Lazaric et al., 2010). We describe existing and a few new performance
bounds for Direct Policy Iteration (DPI) (Lagoudakis and Parr, 2003; Fern et
al., 2006; Lazaric et al., 2010) and Conservative Policy Iteration (CPI)
(Kakade and Langford, 2002). By paying a particular attention to the
concentrability constants involved in such guarantees, we notably argue that
the guarantee of CPI is much better than that of DPI, but this comes at the
cost of a relative--exponential in $\frac{1}{\epsilon}$-- increase of time
complexity. We then describe an algorithm, Non-Stationary Direct Policy
Iteration (NSDPI), that can either be seen as 1) a variation of Policy Search
by Dynamic Programming by Bagnell et al. (2003) to the infinite horizon
situation or 2) a simplified version of the Non-Stationary PI with growing
period of Scherrer and Lesner (2012). We provide an analysis of this algorithm,
that shows in particular that it enjoys the best of both worlds: its
performance guarantee is similar to that of CPI, but within a time complexity
similar to that of DPI.",2013-06-03T19:13:53Z,Bruno Scherrer
1306.2295v1,Markov random fields factorization with context-specific independences,"Markov random fields provide a compact representation of joint probability
distributions by representing its independence properties in an undirected
graph. The well-known Hammersley-Clifford theorem uses these conditional
independences to factorize a Gibbs distribution into a set of factors. However,
an important issue of using a graph to represent independences is that it
cannot encode some types of independence relations, such as the
context-specific independences (CSIs). They are a particular case of
conditional independences that is true only for a certain assignment of its
conditioning set; in contrast to conditional independences that must hold for
all its assignments. This work presents a method for factorizing a Markov
random field according to CSIs present in a distribution, and formally
guarantees that this factorization is correct. This is presented in our main
contribution, the context-specific Hammersley-Clifford theorem, a
generalization to CSIs of the Hammersley-Clifford theorem that applies for
conditional independences.",2013-06-10T19:36:31Z,"Alejandro Edera, Facundo Bromberg, Federico Schlter"
1306.6302v2,Solving Relational MDPs with Exogenous Events and Additive Rewards,"We formalize a simple but natural subclass of service domains for relational
planning problems with object-centered, independent exogenous events and
additive rewards capturing, for example, problems in inventory control.
Focusing on this subclass, we present a new symbolic planning algorithm which
is the first algorithm that has explicit performance guarantees for relational
MDPs with exogenous events. In particular, under some technical conditions, our
planning algorithm provides a monotonic lower bound on the optimal value
function. To support this algorithm we present novel evaluation and reduction
techniques for generalized first order decision diagrams, a knowledge
representation for real-valued functions over relational world states. Our
planning algorithm uses a set of focus states, which serves as a training set,
to simplify and approximate the symbolic solution, and can thus be seen to
perform learning for planning. A preliminary experimental evaluation
demonstrates the validity of our approach.",2013-06-26T17:59:49Z,"S. Joshi, R. Khardon, P. Tadepalli, A. Raghavan, A. Fern"
1306.6802v2,"Evaluation Measures for Hierarchical Classification: a unified view and
  novel approaches","Hierarchical classification addresses the problem of classifying items into a
hierarchy of classes. An important issue in hierarchical classification is the
evaluation of different classification algorithms, which is complicated by the
hierarchical relations among the classes. Several evaluation measures have been
proposed for hierarchical classification using the hierarchy in different ways.
This paper studies the problem of evaluation in hierarchical classification by
analyzing and abstracting the key components of the existing performance
measures. It also proposes two alternative generic views of hierarchical
evaluation and introduces two corresponding novel measures. The proposed
measures, along with the state-of-the art ones, are empirically tested on three
large datasets from the domain of text classification. The empirical results
illustrate the undesirable behavior of existing approaches and how the proposed
methods overcome most of these methods across a range of cases.",2013-06-28T11:49:53Z,"Aris Kosmopoulos, Ioannis Partalas, Eric Gaussier, Georgios Paliouras, Ion Androutsopoulos"
1308.0187v9,A Time and Space Efficient Junction Tree Architecture,"The junction tree algorithm is a way of computing marginals of boolean
multivariate probability distributions that factorise over sets of random
variables. The junction tree algorithm first constructs a tree called a
junction tree who's vertices are sets of random variables. The algorithm then
performs a generalised version of belief propagation on the junction tree. The
Shafer-Shenoy and Hugin architectures are two ways to perform this belief
propagation that tradeoff time and space complexities in different ways: Hugin
propagation is at least as fast as Shafer-Shenoy propagation and in the cases
that we have large vertices of high degree is significantly faster. However,
this speed increase comes at the cost of an increased space complexity. This
paper first introduces a simple novel architecture, ARCH-1, which has the best
of both worlds: the speed of Hugin propagation and the low space requirements
of Shafer-Shenoy propagation. A more complicated novel architecture, ARCH-2, is
then introduced which has, up to a factor only linear in the maximum
cardinality of any vertex, time and space complexities at least as good as
ARCH-1 and in the cases that we have large vertices of high degree is
significantly faster than ARCH-1.",2013-07-31T16:56:59Z,Stephen Pasteris
1308.0227v7,An Enhanced Features Extractor for a Portfolio of Constraint Solvers,"Recent research has shown that a single arbitrarily efficient solver can be
significantly outperformed by a portfolio of possibly slower on-average
solvers. The solver selection is usually done by means of (un)supervised
learning techniques which exploit features extracted from the problem
specification. In this paper we present an useful and flexible framework that
is able to extract an extensive set of features from a Constraint
(Satisfaction/Optimization) Problem defined in possibly different modeling
languages: MiniZinc, FlatZinc or XCSP. We also report some empirical results
showing that the performances that can be obtained using these features are
effective and competitive with state of the art CSP portfolio techniques.",2013-08-01T14:40:14Z,"Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro"
1308.0356v1,"Design and Development of an Expert System to Help Head of University
  Departments","One of the basic tasks which is responded for head of each university
department, is employing lecturers based on some default factors such as
experience, evidences, qualifies and etc. In this respect, to help the heads,
some automatic systems have been proposed until now using machine learning
methods, decision support systems (DSS) and etc. According to advantages and
disadvantages of the previous methods, a full automatic system is designed in
this paper using expert systems. The proposed system is included two main
steps. In the first one, the human expert's knowledge is designed as decision
trees. The second step is included an expert system which is evaluated using
extracted rules of these decision trees. Also, to improve the quality of the
proposed system, a majority voting algorithm is proposed as post processing
step to choose the best lecturer which satisfied more expert's decision trees
for each course. The results are shown that the designed system average
accuracy is 78.88. Low computational complexity, simplicity to program and are
some of other advantages of the proposed system.",2013-08-01T21:04:07Z,"Shervan Fekri-Ershad, Hadi Tajalizadeh, Shahram Jafari"
1308.3513v1,"Hidden Parameter Markov Decision Processes: A Semiparametric Regression
  Approach for Discovering Latent Task Parametrizations","Control applications often feature tasks with similar, but not identical,
dynamics. We introduce the Hidden Parameter Markov Decision Process (HiP-MDP),
a framework that parametrizes a family of related dynamical systems with a
low-dimensional set of latent factors, and introduce a semiparametric
regression approach for learning its structure from data. In the control
setting, we show that a learned HiP-MDP rapidly identifies the dynamics of a
new task instance, allowing an agent to flexibly adapt to task variations.",2013-08-15T21:21:05Z,"Finale Doshi-Velez, George Konidaris"
1309.2080v1,"Structure Learning of Probabilistic Logic Programs by Searching the
  Clause Space","Learning probabilistic logic programming languages is receiving an increasing
attention and systems are available for learning the parameters (PRISM,
LeProbLog, LFI-ProbLog and EMBLEM) or both the structure and the parameters
(SEM-CP-logic and SLIPCASE) of these languages. In this paper we present the
algorithm SLIPCOVER for ""Structure LearnIng of Probabilistic logic programs by
searChing OVER the clause space"". It performs a beam search in the space of
probabilistic clauses and a greedy search in the space of theories, using the
log likelihood of the data as the guiding heuristics. To estimate the log
likelihood SLIPCOVER performs Expectation Maximization with EMBLEM. The
algorithm has been tested on five real world datasets and compared with
SLIPCASE, SEM-CP-logic, Aleph and two algorithms for learning Markov Logic
Networks (Learning using Structural Motifs (LSM) and ALEPH++ExactL1). SLIPCOVER
achieves higher areas under the precision-recall and ROC curves in most cases.",2013-09-09T09:24:44Z,"Elena Bellodi, Fabrizio Riguzzi"
1310.2955v1,Spontaneous Analogy by Piggybacking on a Perceptual System,"Most computational models of analogy assume they are given a delineated
source domain and often a specified target domain. These systems do not address
how analogs can be isolated from large domains and spontaneously retrieved from
long-term memory, a process we call spontaneous analogy. We present a system
that represents relational structures as feature bags. Using this
representation, our system leverages perceptual algorithms to automatically
create an ontology of relational structures and to efficiently retrieve analogs
for new relational structures from long-term memory. We provide a demonstration
of our approach that takes a set of unsegmented stories, constructs an ontology
of analogical schemas (corresponding to plot devices), and uses this ontology
to efficiently find analogs within new stories, yielding significant
time-savings over linear analog retrieval at a small accuracy cost.",2013-10-10T20:22:33Z,"Marc Pickett, David W. Aha"
1311.3735v1,Ensemble Relational Learning based on Selective Propositionalization,"Dealing with structured data needs the use of expressive representation
formalisms that, however, puts the problem to deal with the computational
complexity of the machine learning process. Furthermore, real world domains
require tools able to manage their typical uncertainty. Many statistical
relational learning approaches try to deal with these problems by combining the
construction of relevant relational features with a probabilistic tool. When
the combination is static (static propositionalization), the constructed
features are considered as boolean features and used offline as input to a
statistical learner; while, when the combination is dynamic (dynamic
propositionalization), the feature construction and probabilistic tool are
combined into a single process. In this paper we propose a selective
propositionalization method that search the optimal set of relational features
to be used by a probabilistic learner in order to minimize a loss function. The
new propositionalization approach has been combined with the random subspace
ensemble method. Experiments on real-world datasets shows the validity of the
proposed method.",2013-11-15T06:14:15Z,"Nicola Di Mauro, Floriana Esposito"
1311.3959v4,Clustering Markov Decision Processes For Continual Transfer,"We present algorithms to effectively represent a set of Markov decision
processes (MDPs), whose optimal policies have already been learned, by a
smaller source subset for lifelong, policy-reuse-based transfer learning in
reinforcement learning. This is necessary when the number of previous tasks is
large and the cost of measuring similarity counteracts the benefit of transfer.
The source subset forms an `$\epsilon$-net' over the original set of MDPs, in
the sense that for each previous MDP $M_p$, there is a source $M^s$ whose
optimal policy has $<\epsilon$ regret in $M_p$. Our contributions are as
follows. We present EXP-3-Transfer, a principled policy-reuse algorithm that
optimally reuses a given source policy set when learning for a new MDP. We
present a framework to cluster the previous MDPs to extract a source subset.
The framework consists of (i) a distance $d_V$ over MDPs to measure
policy-based similarity between MDPs; (ii) a cost function $g(\cdot)$ that uses
$d_V$ to measure how good a particular clustering is for generating useful
source tasks for EXP-3-Transfer and (iii) a provably convergent algorithm,
MHAV, for finding the optimal clustering. We validate our algorithms through
experiments in a surveillance domain.",2013-11-15T19:40:58Z,"M. M. Hassan Mahmud, Majd Hawasly, Benjamin Rosman, Subramanian Ramamoorthy"
1311.4086v1,A hybrid decision support system : application on healthcare,"Many systems based on knowledge, especially expert systems for medical
decision support have been developed. Only systems are based on production
rules, and cannot learn and evolve only by updating them. In addition, taking
into account several criteria induces an exorbitant number of rules to be
injected into the system. It becomes difficult to translate medical knowledge
or a support decision as a simple rule. Moreover, reasoning based on generic
cases became classic and can even reduce the range of possible solutions. To
remedy that, we propose an approach based on using a multi-criteria decision
guided by a case-based reasoning (CBR) approach.",2013-11-16T18:13:42Z,"Abdelhak Mansoul, Baghdad Atmani, Sofia Benbelkacem"
1311.4319v1,Ranking Algorithms by Performance,"A common way of doing algorithm selection is to train a machine learning
model and predict the best algorithm from a portfolio to solve a particular
problem. While this method has been highly successful, choosing only a single
algorithm has inherent limitations -- if the choice was bad, no remedial action
can be taken and parallelism cannot be exploited, to name but a few problems.
In this paper, we investigate how to predict the ranking of the portfolio
algorithms on a particular problem. This information can be used to choose the
single best algorithm, but also to allocate resources to the algorithms
according to their rank. We evaluate a range of approaches to predict the
ranking of a set of algorithms on a problem. We furthermore introduce a
framework for categorizing ranking predictions that allows to judge the
expressiveness of the predictive output. Our experimental evaluation
demonstrates on a range of data sets from the literature that it is beneficial
to consider the relationship between algorithms when predicting rankings. We
furthermore show that relatively naive approaches deliver rankings of good
quality already.",2013-11-18T10:22:53Z,Lars Kotthoff
1312.0049v1,One-Class Classification: Taxonomy of Study and Review of Techniques,"One-class classification (OCC) algorithms aim to build classification models
when the negative class is either absent, poorly sampled or not well defined.
This unique situation constrains the learning of efficient classifiers by
defining class boundary just with the knowledge of positive class. The OCC
problem has been considered and applied under many research themes, such as
outlier/novelty detection and concept learning. In this paper we present a
unified view of the general problem of OCC by presenting a taxonomy of study
for OCC problems, which is based on the availability of training data,
algorithms used and the application domains applied. We further delve into each
of the categories of the proposed taxonomy and present a comprehensive
literature review of the OCC algorithms, techniques and methodologies with a
focus on their significance, limitations and applications. We conclude our
paper by discussing some open research problems in the field of OCC and present
our vision for future research.",2013-11-30T01:52:36Z,"Shehroz S. Khan, Michael G. Madden"
1312.2710v1,"Improving circuit miniaturization and its efficiency using Rough Set
  Theory","High-speed, accuracy, meticulousness and quick response are notion of the
vital necessities for modern digital world. An efficient electronic circuit
unswervingly affects the maneuver of the whole system. Different tools are
required to unravel different types of engineering tribulations. Improving the
efficiency, accuracy and low power consumption in an electronic circuit is
always been a bottle neck problem. So the need of circuit miniaturization is
always there. It saves a lot of time and power that is wasted in switching of
gates, the wiring-crises is reduced, cross-sectional area of chip is reduced,
the number of transistors that can implemented in chip is multiplied many
folds. Therefore to trounce with this problem we have proposed an Artificial
intelligence (AI) based approach that make use of Rough Set Theory for its
implementation. Theory of rough set has been proposed by Z Pawlak in the year
1982. Rough set theory is a new mathematical tool which deals with uncertainty
and vagueness. Decisions can be generated using rough set theory by reducing
the unwanted and superfluous data. We have condensed the number of gates
without upsetting the productivity of the given circuit. This paper proposes an
approach with the help of rough set theory which basically lessens the number
of gates in the circuit, based on decision rules.",2013-12-10T08:11:14Z,"Sarvesh SS Rawat, Dheeraj Dilip Mor, Anugrah Kumar, Sanjiban Shekar Roy, Rohit kumar"
1312.3903v1,A Methodology for Player Modeling based on Machine Learning,"AI is gradually receiving more attention as a fundamental feature to increase
the immersion in digital games. Among the several AI approaches, player
modeling is becoming an important one. The main idea is to understand and model
the player characteristics and behaviors in order to develop a better AI. In
this work, we discuss several aspects of this new field. We proposed a taxonomy
to organize the area, discussing several facets of this topic, ranging from
implementation decisions up to what a model attempts to describe. We then
classify, in our taxonomy, some of the most important works in this field. We
also presented a generic approach to deal with player modeling using ML, and we
instantiated this approach to model players' preferences in the game
Civilization IV. The instantiation of this approach has several steps. We first
discuss a generic representation, regardless of what is being modeled, and
evaluate it performing experiments with the strategy game Civilization IV.
Continuing the instantiation of the proposed approach we evaluated the
applicability of using game score information to distinguish different
preferences. We presented a characterization of virtual agents in the game,
comparing their behavior with their stated preferences. Once we have
characterized these agents, we were able to observe that different preferences
generate different behaviors, measured by several game indicators. We then
tackled the preference modeling problem as a binary classification task, with a
supervised learning approach. We compared four different methods, based on
different paradigms (SVM, AdaBoost, NaiveBayes and JRip), evaluating them on a
set of matches played by different virtual agents. We conclude our work using
the learned models to infer human players' preferences. Using some of the
evaluated classifiers we obtained accuracies over 60% for most of the inferred
preferences.",2013-12-13T18:32:51Z,Marlos C. Machado
1403.6348v6,"Updating Formulas and Algorithms for Computing Entropy and Gini Index
  from Time-Changing Data Streams","Despite growing interest in data stream mining the most successful
incremental learners, such as VFDT, still use periodic recomputation to update
attribute information gains and Gini indices. This note provides simple
incremental formulas and algorithms for computing entropy and Gini index from
time-changing data streams.",2014-03-25T14:07:21Z,Blaz Sovdat
1404.1140v2,Scalable Planning and Learning for Multiagent POMDPs: Extended Version,"Online, sample-based planning algorithms for POMDPs have shown great promise
in scaling to problems with large state spaces, but they become intractable for
large action and observation spaces. This is particularly problematic in
multiagent POMDPs where the action and observation space grows exponentially
with the number of agents. To combat this intractability, we propose a novel
scalable approach based on sample-based planning and factored value functions
that exploits structure present in many multiagent settings. This approach
applies not only in the planning case, but also in the Bayesian reinforcement
learning setting. Experimental results show that we are able to provide high
quality solutions to large multiagent planning and learning problems.",2014-04-04T03:02:44Z,"Christopher Amato, Frans A. Oliehoek"
1405.0501v1,Exchangeable Variable Models,"A sequence of random variables is exchangeable if its joint distribution is
invariant under variable permutations. We introduce exchangeable variable
models (EVMs) as a novel class of probabilistic models whose basic building
blocks are partially exchangeable sequences, a generalization of exchangeable
sequences. We prove that a family of tractable EVMs is optimal under zero-one
loss for a large class of functions, including parity and threshold functions,
and strictly subsumes existing tractable independence-based model families.
Extensive experiments show that EVMs outperform state of the art classifiers
such as SVMs and probabilistic models which are solely based on independence
assumptions.",2014-05-02T20:13:06Z,"Mathias Niepert, Pedro Domingos"
1405.3318v1,Adaptive Monte Carlo via Bandit Allocation,"We consider the problem of sequentially choosing between a set of unbiased
Monte Carlo estimators to minimize the mean-squared-error (MSE) of a final
combined estimate. By reducing this task to a stochastic multi-armed bandit
problem, we show that well developed allocation strategies can be used to
achieve an MSE that approaches that of the best estimator chosen in retrospect.
We then extend these developments to a scenario where alternative estimators
have different, possibly stochastic costs. The outcome is a new set of adaptive
Monte Carlo strategies that provide stronger guarantees than previous
approaches while offering practical advantages.",2014-05-13T22:29:14Z,"James Neufeld, Andrs Gyrgy, Dale Schuurmans, Csaba Szepesvri"
1405.5358v1,Off-Policy Shaping Ensembles in Reinforcement Learning,"Recent advances of gradient temporal-difference methods allow to learn
off-policy multiple value functions in parallel with- out sacrificing
convergence guarantees or computational efficiency. This opens up new
possibilities for sound ensemble techniques in reinforcement learning. In this
work we propose learning an ensemble of policies related through
potential-based shaping rewards. The ensemble induces a combination policy by
using a voting mechanism on its components. Learning happens in real time, and
we empirically show the combination policy to outperform the individual
policies of the ensemble.",2014-05-21T10:20:15Z,"Anna Harutyunyan, Tim Brys, Peter Vrancx, Ann Nowe"
1406.3497v2,"Multi-objective Reinforcement Learning with Continuous Pareto Frontier
  Approximation Supplementary Material","This document contains supplementary material for the paper ""Multi-objective
Reinforcement Learning with Continuous Pareto Frontier Approximation"",
published at the Twenty-Ninth AAAI Conference on Artificial Intelligence
(AAAI-15). The paper is about learning a continuous approximation of the Pareto
frontier in Multi-Objective Markov Decision Problems (MOMDPs). We propose a
policy-based approach that exploits gradient information to generate solutions
close to the Pareto ones. Differently from previous policy-gradient
multi-objective algorithms, where n optimization routines are use to have n
solutions, our approach performs a single gradient-ascent run that at each step
generates an improved continuous approximation of the Pareto frontier. The idea
is to exploit a gradient-based approach to optimize the parameters of a
function that defines a manifold in the policy parameter space so that the
corresponding image in the objective space gets as close as possible to the
Pareto frontier. Besides deriving how to compute and estimate such gradient, we
will also discuss the non-trivial issue of defining a metric to assess the
quality of the candidate Pareto frontiers. Finally, the properties of the
proposed approach are empirically evaluated on two interesting MOMDPs.",2014-06-13T10:49:38Z,"Matteo Pirotta, Simone Parisi, Marcello Restelli"
1407.3341v1,Extreme State Aggregation Beyond MDPs,"We consider a Reinforcement Learning setup where an agent interacts with an
environment in observation-reward-action cycles without any (esp.\ MDP)
assumptions on the environment. State aggregation and more generally feature
reinforcement learning is concerned with mapping histories/raw-states to
reduced/aggregated states. The idea behind both is that the resulting reduced
process (approximately) forms a small stationary finite-state MDP, which can
then be efficiently solved or learnt. We considerably generalize existing
aggregation results by showing that even if the reduced process is not an MDP,
the (q-)value functions and (optimal) policies of an associated MDP with same
state-space size solve the original problem, as long as the solution can
approximately be represented as a function of the reduced states. This implies
an upper bound on the required state space size that holds uniformly for all RL
problems. It may also explain why RL algorithms designed for MDPs sometimes
perform well beyond MDPs.",2014-07-12T04:10:43Z,Marcus Hutter
1407.5656v2,"PGMHD: A Scalable Probabilistic Graphical Model for Massive Hierarchical
  Data Problems","In the big data era, scalability has become a crucial requirement for any
useful computational model. Probabilistic graphical models are very useful for
mining and discovering data insights, but they are not scalable enough to be
suitable for big data problems. Bayesian Networks particularly demonstrate this
limitation when their data is represented using few random variables while each
random variable has a massive set of values. With hierarchical data - data that
is arranged in a treelike structure with several levels - one would expect to
see hundreds of thousands or millions of values distributed over even just a
small number of levels. When modeling this kind of hierarchical data across
large data sets, Bayesian networks become infeasible for representing the
probability distributions for the following reasons: i) Each level represents a
single random variable with hundreds of thousands of values, ii) The number of
levels is usually small, so there are also few random variables, and iii) The
structure of the network is predefined since the dependency is modeled top-down
from each parent to each of its child nodes, so the network would contain a
single linear path for the random variables from each parent to each child
node. In this paper we present a scalable probabilistic graphical model to
overcome these limitations for massive hierarchical data. We believe the
proposed model will lead to an easily-scalable, more readable, and expressive
implementation for problems that require probabilistic-based solutions for
massive amounts of hierarchical data. We successfully applied this model to
solve two different challenging probabilistic-based problems on massive
hierarchical data sets for different domains, namely, bioinformatics and latent
semantic discovery over search logs.",2014-07-21T20:26:32Z,"Khalifeh AlJadda, Mohammed Korayem, Camilo Ortiz, Trey Grainger, John A. Miller, William S. York"
1407.7417v1,'Almost Sure' Chaotic Properties of Machine Learning Methods,"It has been demonstrated earlier that universal computation is 'almost
surely' chaotic. Machine learning is a form of computational fixed point
iteration, iterating over the computable function space. We showcase some
properties of this iteration, and establish in general that the iteration is
'almost surely' of chaotic nature. This theory explains the observation in the
counter intuitive properties of deep learning methods. This paper demonstrates
that these properties are going to be universal to any learning method.",2014-07-28T13:44:25Z,"Nabarun Mondal, Partha P. Ghosh"
1408.2035v1,Quantum Annealing for Clustering,"This paper studies quantum annealing (QA) for clustering, which can be seen
as an extension of simulated annealing (SA). We derive a QA algorithm for
clustering and propose an annealing schedule, which is crucial in practice.
Experiments show the proposed QA algorithm finds better clustering assignments
than SA. Furthermore, QA is as easy as SA to implement.",2014-08-09T05:31:06Z,"Kenichi Kurihara, Shu Tanaka, Seiji Miyashita"
1408.2045v1,Efficient Clustering with Limited Distance Information,"Given a point set S and an unknown metric d on S, we study the problem of
efficiently partitioning S into k clusters while querying few distances between
the points. In our model we assume that we have access to one versus all
queries that given a point s 2 S return the distances between s and all other
points. We show that given a natural assumption about the structure of the
instance, we can efficiently find an accurate clustering using only O(k)
distance queries. We use our algorithm to cluster proteins by sequence
similarity. This setting nicely fits our model because we can use a fast
sequence database search program to query a sequence against an entire dataset.
We conduct an empirical study that shows that even though we query a small
fraction of the distances between the points, we produce clusterings that are
close to a desired clustering given by manual classification.",2014-08-09T05:41:26Z,"Konstantin Voevodski, Maria-Florina Balcan, Heiko Roglin, Shang-Hua Teng, Yu Xia"
1408.2196v1,Exponentiated Gradient Exploration for Active Learning,"Active learning strategies respond to the costly labelling task in a
supervised classification by selecting the most useful unlabelled examples in
training a predictive model. Many conventional active learning algorithms focus
on refining the decision boundary, rather than exploring new regions that can
be more informative. In this setting, we propose a sequential algorithm named
EG-Active that can improve any Active learning algorithm by an optimal random
exploration. Experimental results show a statistically significant and
appreciable improvement in the performance of our new approach over the
existing active feedback methods.",2014-08-10T07:47:50Z,Djallel Bouneffouf
1408.5241v1,"A two-stage architecture for stock price forecasting by combining SOM
  and fuzzy-SVM","This paper proposed a model to predict the stock price based on combining
Self-Organizing Map (SOM) and fuzzy-Support Vector Machines (f-SVM). Extraction
of fuzzy rules from raw data based on the combining of statistical machine
learning models is base of this proposed approach. In the proposed model, SOM
is used as a clustering algorithm to partition the whole input space into the
several disjoint regions. For each partition, a set of fuzzy rules is extracted
based on a f-SVM combining model. Then fuzzy rules sets are used to predict the
test data using fuzzy inference algorithms. The performance of the proposed
approach is compared with other models using four data sets",2014-08-22T09:33:50Z,"Duc-Hien Nguyen, Manh-Thanh Le"
1408.5246v1,"Improving the Interpretability of Support Vector Machines-based Fuzzy
  Rules","Support vector machines (SVMs) and fuzzy rule systems are functionally
equivalent under some conditions. Therefore, the learning algorithms developed
in the field of support vector machines can be used to adapt the parameters of
fuzzy systems. Extracting fuzzy models from support vector machines has the
inherent advantage that the model does not need to determine the number of
rules in advance. However, after the support vector machine learning, the
complexity is usually high, and interpretability is also impaired. This paper
not only proposes a complete framework for extracting interpretable SVM-based
fuzzy modeling, but also provides optimization issues of the models.
Simulations examples are given to embody the idea of this paper.",2014-08-22T09:55:06Z,"Duc-Hien Nguyen, Manh-Thanh Le"
1410.4604v1,Domain-Independent Optimistic Initialization for Reinforcement Learning,"In Reinforcement Learning (RL), it is common to use optimistic initialization
of value functions to encourage exploration. However, such an approach
generally depends on the domain, viz., the scale of the rewards must be known,
and the feature representation must have a constant norm. We present a simple
approach that performs optimistic initialization with less dependence on the
domain.",2014-10-16T23:30:08Z,"Marlos C. Machado, Sriram Srinivasan, Michael Bowling"
1410.5557v1,"Where do goals come from? A Generic Approach to Autonomous Goal-System
  Development","Goals express agents' intentions and allow them to organize their behavior
based on low-dimensional abstractions of high-dimensional world states. How can
agents develop such goals autonomously? This paper proposes a detailed
conceptual and computational account to this longstanding problem. We argue to
consider goals as high-level abstractions of lower-level intention mechanisms
such as rewards and values, and point out that goals need to be considered
alongside with a detection of the own actions' effects. We propose Latent Goal
Analysis as a computational learning formulation thereof, and show
constructively that any reward or value function can by explained by goals and
such self-detection as latent mechanisms. We first show that learned goals
provide a highly effective dimensionality reduction in a practical
reinforcement learning problem. Then, we investigate a developmental scenario
in which entirely task-unspecific rewards induced by visual saliency lead to
self and goal representations that constitute goal-directed reaching.",2014-10-21T07:24:03Z,"Matthias Rolf, Minoru Asada"
1410.6414v1,A Parallel and Efficient Algorithm for Learning to Match,"Many tasks in data mining and related fields can be formalized as matching
between objects in two heterogeneous domains, including collaborative
filtering, link prediction, image tagging, and web search. Machine learning
techniques, referred to as learning-to-match in this paper, have been
successfully applied to the problems. Among them, a class of state-of-the-art
methods, named feature-based matrix factorization, formalize the task as an
extension to matrix factorization by incorporating auxiliary features into the
model. Unfortunately, making those algorithms scale to real world problems is
challenging, and simple parallelization strategies fail due to the complex
cross talking patterns between sub-tasks. In this paper, we tackle this
challenge with a novel parallel and efficient algorithm for feature-based
matrix factorization. Our algorithm, based on coordinate descent, can easily
handle hundreds of millions of instances and features on a single machine. The
key recipe of this algorithm is an iterative relaxation of the objective to
facilitate parallel updates of parameters, with guaranteed convergence on
minimizing the original objective function. Experimental results demonstrate
that the proposed method is effective on a wide range of matching problems,
with efficiency significantly improved upon the baselines while accuracy
retained unchanged.",2014-10-22T01:04:00Z,"Jingbo Shang, Tianqi Chen, Hang Li, Zhengdong Lu, Yong Yu"
1410.8620v1,A Comparison of learning algorithms on the Arcade Learning Environment,"Reinforcement learning agents have traditionally been evaluated on small toy
problems. With advances in computing power and the advent of the Arcade
Learning Environment, it is now possible to evaluate algorithms on diverse and
difficult problems within a consistent framework. We discuss some challenges
posed by the arcade learning environment which do not manifest in simpler
environments. We then provide a comparison of model-free, linear learning
algorithms on this challenging problem set.",2014-10-31T02:19:19Z,"Aaron Defazio, Thore Graepel"
1412.7978v1,The Computational Theory of Intelligence: Information Entropy,"This paper presents an information theoretic approach to the concept of
intelligence in the computational sense. We introduce a probabilistic framework
from which computational intelligence is shown to be an entropy minimizing
process at the local level. Using this new scheme, we develop a simple data
driven clustering example and discuss its applications.",2014-12-24T07:41:45Z,Daniel Kovach
1505.00423v1,Optimal Time-Series Motifs,"Motifs are the most repetitive/frequent patterns of a time-series. The
discovery of motifs is crucial for practitioners in order to understand and
interpret the phenomena occurring in sequential data. Currently, motifs are
searched among series sub-sequences, aiming at selecting the most frequently
occurring ones. Search-based methods, which try out series sub-sequence as
motif candidates, are currently believed to be the best methods in finding the
most frequent patterns.
  However, this paper proposes an entirely new perspective in finding motifs.
We demonstrate that searching is non-optimal since the domain of motifs is
restricted, and instead we propose a principled optimization approach able to
find optimal motifs. We treat the occurrence frequency as a function and
time-series motifs as its parameters, therefore we \textit{learn} the optimal
motifs that maximize the frequency function. In contrast to searching, our
method is able to discover the most repetitive patterns (hence optimal), even
in cases where they do not explicitly occur as sub-sequences. Experiments on
several real-life time-series datasets show that the motifs found by our method
are highly more frequent than the ones found through searching, for exactly the
same distance threshold.",2015-05-03T12:11:43Z,"Josif Grabocka, Nicolas Schilling, Lars Schmidt-Thieme"
1505.01221v2,The Configurable SAT Solver Challenge (CSSC),"It is well known that different solution strategies work well for different
types of instances of hard combinatorial problems. As a consequence, most
solvers for the propositional satisfiability problem (SAT) expose parameters
that allow them to be customized to a particular family of instances. In the
international SAT competition series, these parameters are ignored: solvers are
run using a single default parameter setting (supplied by the authors) for all
benchmark instances in a given track. While this competition format rewards
solvers with robust default settings, it does not reflect the situation faced
by a practitioner who only cares about performance on one particular
application and can invest some time into tuning solver parameters for this
application. The new Configurable SAT Solver Competition (CSSC) compares
solvers in this latter setting, scoring each solver by the performance it
achieved after a fully automated configuration step. This article describes the
CSSC in more detail, and reports the results obtained in its two instantiations
so far, CSSC 2013 and 2014.",2015-05-05T23:39:24Z,"Frank Hutter, Marius Lindauer, Adrian Balint, Sam Bayless, Holger Hoos, Kevin Leyton-Brown"
1505.01419v2,Fast Differentially Private Matrix Factorization,"Differentially private collaborative filtering is a challenging task, both in
terms of accuracy and speed. We present a simple algorithm that is provably
differentially private, while offering good performance, using a novel
connection of differential privacy to Bayesian posterior sampling via
Stochastic Gradient Langevin Dynamics. Due to its simplicity the algorithm
lends itself to efficient implementation. By careful systems design and by
exploiting the power law behavior of the data to maximize CPU cache bandwidth
we are able to generate 1024 dimensional models at a rate of 8.5 million
recommendations per second on a single PC.",2015-05-06T16:18:06Z,"Ziqi Liu, Yu-Xiang Wang, Alexander J. Smola"
1505.05451v3,Fuzzy Least Squares Twin Support Vector Machines,"Least Squares Twin Support Vector Machine (LST-SVM) has been shown to be an
efficient and fast algorithm for binary classification. It combines the
operating principles of Least Squares SVM (LS-SVM) and Twin SVM (T-SVM); it
constructs two non-parallel hyperplanes (as in T-SVM) by solving two systems of
linear equations (as in LS-SVM). Despite its efficiency, LST-SVM is still
unable to cope with two features of real-world problems. First, in many
real-world applications, labels of samples are not deterministic; they come
naturally with their associated membership degrees. Second, samples in
real-world applications may not be equally important and their importance
degrees affect the classification. In this paper, we propose Fuzzy LST-SVM
(FLST-SVM) to deal with these two characteristics of real-world data. Two
models are introduced for FLST-SVM: the first model builds up crisp hyperplanes
using training samples and their corresponding membership degrees. The second
model, on the other hand, constructs fuzzy hyperplanes using training samples
and their membership degrees. Numerical evaluation of the proposed method with
synthetic and real datasets demonstrate significant improvement in the
classification accuracy of FLST-SVM when compared to well-known existing
versions of SVM.",2015-05-20T16:57:02Z,"Javad Salimi Sartakhti, Homayun Afrabandpey, Nasser Ghadiri"
1505.05723v1,On the relation between accuracy and fairness in binary classification,"Our study revisits the problem of accuracy-fairness tradeoff in binary
classification. We argue that comparison of non-discriminatory classifiers
needs to account for different rates of positive predictions, otherwise
conclusions about performance may be misleading, because accuracy and
discrimination of naive baselines on the same dataset vary with different rates
of positive predictions. We provide methodological recommendations for sound
comparison of non-discriminatory classifiers, and present a brief theoretical
and empirical analysis of tradeoffs between accuracy and non-discrimination.",2015-05-21T13:20:06Z,Indre Zliobaite
1506.02113v1,"Selective Greedy Equivalence Search: Finding Optimal Bayesian Networks
  Using a Polynomial Number of Score Evaluations","We introduce Selective Greedy Equivalence Search (SGES), a restricted version
of Greedy Equivalence Search (GES). SGES retains the asymptotic correctness of
GES but, unlike GES, has polynomial performance guarantees. In particular, we
show that when data are sampled independently from a distribution that is
perfect with respect to a DAG ${\cal G}$ defined over the observable variables
then, in the limit of large data, SGES will identify ${\cal G}$'s equivalence
class after a number of score evaluations that is (1) polynomial in the number
of nodes and (2) exponential in various complexity measures including
maximum-number-of-parents, maximum-clique-size, and a new measure called {\em
v-width} that is at least as small as---and potentially much smaller than---the
other two. More generally, we show that for any hereditary and
equivalence-invariant property $\Pi$ known to hold in ${\cal G}$, we retain the
large-sample optimality guarantees of GES even if we ignore any GES deletion
operator during the backward phase that results in a state for which $\Pi$ does
not hold in the common-descendants subgraph.",2015-06-06T03:56:44Z,"David Maxwell Chickering, Christopher Meek"
1506.02465v3,ASlib: A Benchmark Library for Algorithm Selection,"The task of algorithm selection involves choosing an algorithm from a set of
algorithms on a per-instance basis in order to exploit the varying performance
of algorithms over a set of instances. The algorithm selection problem is
attracting increasing attention from researchers and practitioners in AI. Years
of fruitful applications in a number of domains have resulted in a large amount
of data, but the community lacks a standard format or repository for this data.
This situation makes it difficult to share and compare different approaches
effectively, as is done in other, more established fields. It also
unnecessarily hinders new researchers who want to work in this area. To address
this problem, we introduce a standardized format for representing algorithm
selection scenarios and a repository that contains a growing number of data
sets from the literature. Our format has been designed to be able to express a
wide variety of different scenarios. Demonstrating the breadth and power of our
platform, we describe a set of example experiments that build and evaluate
algorithm selection models through a common interface. The results display the
potential of algorithm selection to achieve significant performance
improvements across a broad range of problems and algorithms.",2015-06-08T12:35:04Z,"Bernd Bischl, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Frechette, Holger Hoos, Frank Hutter, Kevin Leyton-Brown, Kevin Tierney, Joaquin Vanschoren"
1506.03379v2,"The Online Coupon-Collector Problem and Its Application to Lifelong
  Reinforcement Learning","Transferring knowledge across a sequence of related tasks is an important
challenge in reinforcement learning (RL). Despite much encouraging empirical
evidence, there has been little theoretical analysis. In this paper, we study a
class of lifelong RL problems: the agent solves a sequence of tasks modeled as
finite Markov decision processes (MDPs), each of which is from a finite set of
MDPs with the same state/action sets and different transition/reward functions.
Motivated by the need for cross-task exploration in lifelong learning, we
formulate a novel online coupon-collector problem and give an optimal
algorithm. This allows us to develop a new lifelong RL algorithm, whose overall
sample complexity in a sequence of tasks is much smaller than single-task
learning, even if the sequence of tasks is generated by an adversary. Benefits
of the algorithm are demonstrated in simulated problems, including a recently
introduced human-robot interaction problem.",2015-06-10T16:23:29Z,"Emma Brunskill, Lihong Li"
1506.03425v1,Fast Online Clustering with Randomized Skeleton Sets,"We present a new fast online clustering algorithm that reliably recovers
arbitrary-shaped data clusters in high throughout data streams. Unlike the
existing state-of-the-art online clustering methods based on k-means or
k-medoid, it does not make any restrictive generative assumptions. In addition,
in contrast to existing nonparametric clustering techniques such as DBScan or
DenStream, it gives provable theoretical guarantees. To achieve fast
clustering, we propose to represent each cluster by a skeleton set which is
updated continuously as new data is seen. A skeleton set consists of weighted
samples from the data where weights encode local densities. The size of each
skeleton set is adapted according to the cluster geometry. The proposed
technique automatically detects the number of clusters and is robust to
outliers. The algorithm works for the infinite data stream where more than one
pass over the data is not feasible. We provide theoretical guarantees on the
quality of the clustering and also demonstrate its advantage over the existing
state-of-the-art on several datasets.",2015-06-10T18:41:55Z,"Krzysztof Choromanski, Sanjiv Kumar, Xiaofeng Liu"
1507.00436v2,Online Transfer Learning in Reinforcement Learning Domains,"This paper proposes an online transfer framework to capture the interaction
among agents and shows that current transfer learning in reinforcement learning
is a special case of online transfer. Furthermore, this paper re-characterizes
existing agents-teaching-agents methods as online transfer and analyze one such
teaching method in three ways. First, the convergence of Q-learning and Sarsa
with tabular representation with a finite budget is proven. Second, the
convergence of Q-learning and Sarsa with linear function approximation is
established. Third, the we show the asymptotic performance cannot be hurt
through teaching. Additionally, all theoretical results are empirically
validated.",2015-07-02T06:05:44Z,"Yusen Zhan, Matthew E. Taylor"
1507.01569v1,Emphatic Temporal-Difference Learning,"Emphatic algorithms are temporal-difference learning algorithms that change
their effective state distribution by selectively emphasizing and
de-emphasizing their updates on different time steps. Recent works by Sutton,
Mahmood and White (2015), and Yu (2015) show that by varying the emphasis in a
particular way, these algorithms become stable and convergent under off-policy
training with linear function approximation. This paper serves as a unified
summary of the available results from both works. In addition, we demonstrate
the empirical benefits from the flexibility of emphatic algorithms, including
state-dependent discounting, state-dependent bootstrapping, and the
user-specified allocation of function approximation resources.",2015-07-06T19:28:36Z,"A. Rupam Mahmood, Huizhen Yu, Martha White, Richard S. Sutton"
1507.04124v1,On the Computability of Solomonoff Induction and Knowledge-Seeking,"Solomonoff induction is held as a gold standard for learning, but it is known
to be incomputable. We quantify its incomputability by placing various flavors
of Solomonoff's prior M in the arithmetical hierarchy. We also derive
computability bounds for knowledge-seeking agents, and give a limit-computable
weakly asymptotically optimal reinforcement learning agent.",2015-07-15T08:46:06Z,"Jan Leike, Marcus Hutter"
1508.00507v1,"A Weakly Supervised Learning Approach based on Spectral Graph-Theoretic
  Grouping","In this study, a spectral graph-theoretic grouping strategy for weakly
supervised classification is introduced, where a limited number of labelled
samples and a larger set of unlabelled samples are used to construct a larger
annotated training set composed of strongly labelled and weakly labelled
samples. The inherent relationship between the set of strongly labelled samples
and the set of unlabelled samples is established via spectral grouping, with
the unlabelled samples subsequently weakly annotated based on the strongly
labelled samples within the associated spectral groups. A number of similarity
graph models for spectral grouping, including two new similarity graph models
introduced in this study, are explored to investigate their performance in the
context of weakly supervised classification in handling different types of
data. Experimental results using benchmark datasets as well as real EMG
datasets demonstrate that the proposed approach to weakly supervised
classification can provide noticeable improvements in classification
performance, and that the proposed similarity graph models can lead to ultimate
learning results that are either better than or on a par with existing
similarity graph models in the context of spectral grouping for weakly
supervised classification.",2015-08-03T18:08:04Z,"Tameem Adel, Alexander Wong, Daniel Stashuk"
1508.00509v2,"Maintaining prediction quality under the condition of a growing
  knowledge space","Intelligence can be understood as an agent's ability to predict its
environment's dynamic by a level of precision which allows it to effectively
foresee opportunities and threats. Under the assumption that such intelligence
relies on a knowledge space any effective reasoning would benefit from a
maximum portion of useful and a minimum portion of misleading knowledge
fragments. It begs the question of how the quality of such knowledge space can
be kept high as the amount of knowledge keeps growing. This article proposes a
mathematical model to describe general principles of how quality of a growing
knowledge space evolves depending on error rate, error propagation and
countermeasures. There is also shown to which extend the quality of a knowledge
space collapses as removal of low quality knowledge fragments occurs too slowly
for a given knowledge space's growth rate.",2015-08-03T18:19:41Z,Christoph Jahnz
1508.02103v2,"Lifted Representation of Relational Causal Models Revisited:
  Implications for Reasoning and Structure Learning","Maier et al. (2010) introduced the relational causal model (RCM) for
representing and inferring causal relationships in relational data. A lifted
representation, called abstract ground graph (AGG), plays a central role in
reasoning with and learning of RCM. The correctness of the algorithm proposed
by Maier et al. (2013a) for learning RCM from data relies on the soundness and
completeness of AGG for relational d-separation to reduce the learning of an
RCM to learning of an AGG. We revisit the definition of AGG and show that AGG,
as defined in Maier et al. (2013b), does not correctly abstract all ground
graphs. We revise the definition of AGG to ensure that it correctly abstracts
all ground graphs. We further show that AGG representation is not complete for
relational d-separation, that is, there can exist conditional independence
relations in an RCM that are not entailed by AGG. A careful examination of the
relationship between the lack of completeness of AGG for relational
d-separation and faithfulness conditions suggests that weaker notions of
completeness, namely adjacency faithfulness and orientation faithfulness
between an RCM and its AGG, can be used to learn an RCM from data.",2015-08-10T00:52:14Z,"Sanghack Lee, Vasant Honavar"
1508.02593v2,Type-Constrained Representation Learning in Knowledge Graphs,"Large knowledge graphs increasingly add value to various applications that
require machines to recognize and understand queries and their semantics, as in
search or question answering systems. Latent variable models have increasingly
gained attention for the statistical modeling of knowledge graphs, showing
promising results in tasks related to knowledge graph completion and cleaning.
Besides storing facts about the world, schema-based knowledge graphs are backed
by rich semantic descriptions of entities and relation-types that allow
machines to understand the notion of things and their semantic relationships.
In this work, we study how type-constraints can generally support the
statistical modeling with latent variable models. More precisely, we integrated
prior knowledge in form of type-constraints in various state of the art latent
variable approaches. Our experimental results show that prior knowledge on
relation-types significantly improves these models up to 77% in link-prediction
tasks. The achieved improvements are especially prominent when a low model
complexity is enforced, a crucial requirement when these models are applied to
very large datasets. Unfortunately, type-constraints are neither always
available nor always complete e.g., they can become fuzzy when entities lack
proper typing. We show that in these cases, it can be beneficial to apply a
local closed-world assumption that approximates the semantics of relation-types
based on observations made in the data.",2015-08-11T13:49:07Z,"Denis Krompa, Stephan Baier, Volker Tresp"
1508.02681v1,"Artificial Prediction Markets for Online Prediction of Continuous
  Variables-A Preliminary Report","We propose the Artificial Continuous Prediction Market (ACPM) as a means to
predict a continuous real value, by integrating a range of data sources and
aggregating the results of different machine learning (ML) algorithms. ACPM
adapts the concept of the (physical) prediction market to address the
prediction of real values instead of discrete events. Each ACPM participant has
a data source, a ML algorithm and a local decision-making procedure that
determines what to bid on what value. The contributions of ACPM are: (i)
adaptation to changes in data quality by the use of learning in: (a) the
market, which weights each market participant to adjust the influence of each
on the market prediction and (b) the participants, which use a Q-learning based
trading strategy to incorporate the market prediction into their subsequent
predictions, (ii) resilience to a changing population of low- and
high-performing participants. We demonstrate the effectiveness of ACPM by
application to an influenza-like illnesses data set, showing ACPM out-performs
a range of well-known regression models and is resilient to variation in data
source quality.",2015-08-11T18:37:29Z,"Fatemeh Jahedpari, Marina De Vos, Sattar Hashemi, Benjamin Hirsch, Julian Padget"
1510.02879v6,"Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive
  Transfer from multiple sources in the same domain","Transferring knowledge from prior source tasks in solving a new target task
can be useful in several learning applications. The application of transfer
poses two serious challenges which have not been adequately addressed. First,
the agent should be able to avoid negative transfer, which happens when the
transfer hampers or slows down the learning instead of helping it. Second, the
agent should be able to selectively transfer, which is the ability to select
and transfer from different and multiple source tasks for different parts of
the state space of the target task. We propose A2T (Attend, Adapt and
Transfer), an attentive deep architecture which adapts and transfers from these
source tasks. Our model is generic enough to effect transfer of either policies
or value functions. Empirical evaluations on different learning algorithms show
that A2T is an effective architecture for transfer by being able to avoid
negative transfer while transferring selectively from multiple source tasks in
the same domain.",2015-10-10T05:32:24Z,"Janarthanan Rajendran, Aravind Srinivas, Mitesh M. Khapra, P Prasanna, Balaraman Ravindran"
1510.03317v1,The Inductive Constraint Programming Loop,"Constraint programming is used for a variety of real-world optimisation
problems, such as planning, scheduling and resource allocation problems. At the
same time, one continuously gathers vast amounts of data about these problems.
Current constraint programming software does not exploit such data to update
schedules, resources and plans. We propose a new framework, that we call the
Inductive Constraint Programming loop. In this approach data is gathered and
analyzed systematically, in order to dynamically revise and adapt constraints
and optimization criteria. Inductive Constraint Programming aims at bridging
the gap between the areas of data mining and machine learning on the one hand,
and constraint programming on the other hand.",2015-10-12T14:51:03Z,"Christian Bessiere, Luc De Raedt, Tias Guns, Lars Kotthoff, Mirco Nanni, Siegfried Nijssen, Barry O'Sullivan, Anastasia Paparrizou, Dino Pedreschi, Helmut Simonis"
1510.03336v4,"Evaluating Real-time Anomaly Detection Algorithms - the Numenta Anomaly
  Benchmark","Much of the world's data is streaming, time-series data, where anomalies give
significant information in critical situations; examples abound in domains such
as finance, IT, security, medical, and energy. Yet detecting anomalies in
streaming data is a difficult task, requiring detectors to process data in
real-time, not batches, and learn while simultaneously making predictions.
There are no benchmarks to adequately test and score the efficacy of real-time
anomaly detectors. Here we propose the Numenta Anomaly Benchmark (NAB), which
attempts to provide a controlled and repeatable environment of open-source
tools to test and measure anomaly detection algorithms on streaming data. The
perfect detector would detect all anomalies as soon as possible, trigger no
false alarms, work with real-world time-series data across a variety of
domains, and automatically adapt to changing statistics. Rewarding these
characteristics is formalized in NAB, using a scoring algorithm designed for
streaming data. NAB evaluates detectors on a benchmark dataset with labeled,
real-world time-series data. We present these components, and give results and
analyses for several open source, commercially-used algorithms. The goal for
NAB is to provide a standard, open source framework with which the research
community can compare and evaluate different algorithms for detecting anomalies
in streaming data.",2015-10-12T15:30:34Z,"Alexander Lavin, Subutai Ahmad"
1510.03370v1,Asymptotic Logical Uncertainty and The Benford Test,"We give an algorithm A which assigns probabilities to logical sentences. For
any simple infinite sequence of sentences whose truth-values appear
indistinguishable from a biased coin that outputs ""true"" with probability p, we
have that the sequence of probabilities that A assigns to these sentences
converges to p.",2015-10-12T17:14:44Z,"Scott Garrabrant, Siddharth Bhaskar, Abram Demski, Joanna Garrabrant, George Koleszarik, Evan Lloyd"
1510.04931v1,Bad Universal Priors and Notions of Optimality,"A big open question of algorithmic information theory is the choice of the
universal Turing machine (UTM). For Kolmogorov complexity and Solomonoff
induction we have invariance theorems: the choice of the UTM changes bounds
only by a constant. For the universally intelligent agent AIXI (Hutter, 2005)
no invariance theorem is known. Our results are entirely negative: we discuss
cases in which unlucky or adversarial choices of the UTM cause AIXI to
misbehave drastically. We show that Legg-Hutter intelligence and thus balanced
Pareto optimality is entirely subjective, and that every policy is Pareto
optimal in the class of all computable environments. This undermines all
existing optimality properties for AIXI. While it may still serve as a gold
standard for AI, our results imply that AIXI is a relative theory, dependent on
the choice of the UTM.",2015-10-16T16:22:23Z,"Jan Leike, Marcus Hutter"
1510.06143v4,High Performance Latent Variable Models,"Latent variable models have accumulated a considerable amount of interest
from the industry and academia for their versatility in a wide range of
applications. A large amount of effort has been made to develop systems that is
able to extend the systems to a large scale, in the hope to make use of them on
industry scale data. In this paper, we describe a system that operates at a
scale orders of magnitude higher than previous works, and an order of magnitude
faster than state-of-the-art system at the same scale, at the same time showing
more robustness and more accurate results.
  Our system uses a number of advances in distributed inference: high
performance in synchronization of sufficient statistics with relaxed
consistency model; fast sampling, using the Metropolis-Hastings-Walker method
to overcome dense generative models; statistical modeling, moving beyond Latent
Dirichlet Allocation (LDA) to Pitman-Yor distributions (PDP) and Hierarchical
Dirichlet Process (HDP) models; sophisticated parameter projection schemes, to
resolve the conflicts within the constraint between parameters arising from the
relaxed consistency model.
  This work significantly extends the domain of applicability of what is
commonly known as the Parameter Server. We obtain results with up to hundreds
billion oftokens, thousands of topics, and a vocabulary of a few million
token-types, using up to 60,000 processor cores operating on a production
cluster of a large Internet company. This demonstrates the feasibility to scale
to problems orders of magnitude larger than any previously published work.",2015-10-21T06:23:55Z,"Aaron Q. Li, Amr Ahmed, Mu Li, Vanja Josifovski"
1510.06335v2,"Time-Sensitive Bayesian Information Aggregation for Crowdsourcing
  Systems","Crowdsourcing systems commonly face the problem of aggregating multiple
judgments provided by potentially unreliable workers. In addition, several
aspects of the design of efficient crowdsourcing processes, such as defining
worker's bonuses, fair prices and time limits of the tasks, involve knowledge
of the likely duration of the task at hand. Bringing this together, in this
work we introduce a new time--sensitive Bayesian aggregation method that
simultaneously estimates a task's duration and obtains reliable aggregations of
crowdsourced judgments. Our method, called BCCTime, builds on the key insight
that the time taken by a worker to perform a task is an important indicator of
the likely quality of the produced judgment. To capture this, BCCTime uses
latent variables to represent the uncertainty about the workers' completion
time, the tasks' duration and the workers' accuracy. To relate the quality of a
judgment to the time a worker spends on a task, our model assumes that each
task is completed within a latent time window within which all workers with a
propensity to genuinely attempt the labelling task (i.e., no spammers) are
expected to submit their judgments. In contrast, workers with a lower
propensity to valid labeling, such as spammers, bots or lazy labelers, are
assumed to perform tasks considerably faster or slower than the time required
by normal workers. Specifically, we use efficient message-passing Bayesian
inference to learn approximate posterior probabilities of (i) the confusion
matrix of each worker, (ii) the propensity to valid labeling of each worker,
(iii) the unbiased duration of each task and (iv) the true label of each task.
Using two real-world public datasets for entity linking tasks, we show that
BCCTime produces up to 11% more accurate classifications and up to 100% more
informative estimates of a task's duration compared to state-of-the-art
methods.",2015-10-21T16:42:55Z,"Matteo Venanzi, John Guiver, Pushmeet Kohli, Nick Jennings"
1512.00165v1,Learning Using 1-Local Membership Queries,"Classic machine learning algorithms learn from labelled examples. For
example, to design a machine translation system, a typical training set will
consist of English sentences and their translation. There is a stronger model,
in which the algorithm can also query for labels of new examples it creates.
E.g, in the translation task, the algorithm can create a new English sentence,
and request its translation from the user during training. This combination of
examples and queries has been widely studied. Yet, despite many theoretical
results, query algorithms are almost never used. One of the main causes for
this is a report (Baum and Lang, 1992) on very disappointing empirical
performance of a query algorithm. These poor results were mainly attributed to
the fact that the algorithm queried for labels of examples that are artificial,
and impossible to interpret by humans.
  In this work we study a new model of local membership queries (Awasthi et
al., 2012), which tries to resolve the problem of artificial queries. In this
model, the algorithm is only allowed to query the labels of examples which are
close to examples from the training set. E.g., in translation, the algorithm
can change individual words in a sentence it has already seen, and then ask for
the translation. In this model, the examples queried by the algorithm will be
close to natural examples and hence, hopefully, will not appear as artificial
or random. We focus on 1-local queries (i.e., queries of distance 1 from an
example in the training sample). We show that 1-local membership queries are
already stronger than the standard learning model. We also present an
experiment on a well known NLP task of sentiment analysis. In this experiment,
the users were asked to provide more information than merely indicating the
label. We present results that illustrate that this extra information is
beneficial in practice.",2015-12-01T07:40:49Z,Galit Bary
1512.00355v1,Taxonomy grounded aggregation of classifiers with different label sets,"We describe the problem of aggregating the label predictions of diverse
classifiers using a class taxonomy. Such a taxonomy may not have been available
or referenced when the individual classifiers were designed and trained, yet
mapping the output labels into the taxonomy is desirable to integrate the
effort spent in training the constituent classifiers. A hierarchical taxonomy
representing some domain knowledge may be different from, but partially
mappable to, the label sets of the individual classifiers. We present a
heuristic approach and a principled graphical model to aggregate the label
predictions by grounding them into the available taxonomy. Our model aggregates
the labels using the taxonomy structure as constraints to find the most likely
hierarchically consistent class. We experimentally validate our proposed method
on image and text classification tasks.",2015-12-01T17:32:16Z,"Amrita Saha, Sathish Indurthi, Shantanu Godbole, Subendhu Rongali, Vikas C. Raykar"
1512.01752v2,"Large Scale Distributed Semi-Supervised Learning Using Streaming
  Approximation","Traditional graph-based semi-supervised learning (SSL) approaches, even
though widely applied, are not suited for massive data and large label
scenarios since they scale linearly with the number of edges $|E|$ and distinct
labels $m$. To deal with the large label size problem, recent works propose
sketch-based methods to approximate the distribution on labels per node thereby
achieving a space reduction from $O(m)$ to $O(\log m)$, under certain
conditions. In this paper, we present a novel streaming graph-based SSL
approximation that captures the sparsity of the label distribution and ensures
the algorithm propagates labels accurately, and further reduces the space
complexity per node to $O(1)$. We also provide a distributed version of the
algorithm that scales well to large data sizes. Experiments on real-world
datasets demonstrate that the new method achieves better performance than
existing state-of-the-art algorithms with significant reduction in memory
footprint. We also study different graph construction mechanisms for natural
language applications and propose a robust graph augmentation strategy trained
using state-of-the-art unsupervised deep learning architectures that yields
further significant quality gains.",2015-12-06T06:58:57Z,"Sujith Ravi, Qiming Diao"
1512.02011v2,"How to Discount Deep Reinforcement Learning: Towards New Dynamic
  Strategies","Using deep neural nets as function approximator for reinforcement learning
tasks have recently been shown to be very powerful for solving problems
approaching real-world complexity. Using these results as a benchmark, we
discuss the role that the discount factor may play in the quality of the
learning process of a deep Q-network (DQN). When the discount factor
progressively increases up to its final value, we empirically show that it is
possible to significantly reduce the number of learning steps. When used in
conjunction with a varying learning rate, we empirically show that it
outperforms original DQN on several experiments. We relate this phenomenon with
the instabilities of neural networks when they are used in an approximate
Dynamic Programming setting. We also describe the possibility to fall within a
local optimum during the learning process, thus connecting our discussion with
the exploration/exploitation dilemma.",2015-12-07T12:25:18Z,"Vincent Franois-Lavet, Raphael Fonteneau, Damien Ernst"
1512.02406v3,Learning Discrete Bayesian Networks from Continuous Data,"Learning Bayesian networks from raw data can help provide insights into the
relationships between variables. While real data often contains a mixture of
discrete and continuous-valued variables, many Bayesian network structure
learning algorithms assume all random variables are discrete. Thus, continuous
variables are often discretized when learning a Bayesian network. However, the
choice of discretization policy has significant impact on the accuracy, speed,
and interpretability of the resulting models. This paper introduces a
principled Bayesian discretization method for continuous variables in Bayesian
networks with quadratic complexity instead of the cubic complexity of other
standard techniques. Empirical demonstrations show that the proposed method is
superior to the established minimum description length algorithm. In addition,
this paper shows how to incorporate existing methods into the structure
learning process to discretize all continuous variables and simultaneously
learn Bayesian network structures.",2015-12-08T11:12:04Z,"Yi-Chun Chen, Tim Allan Wheeler, Mykel John Kochenderfer"
1512.03375v1,Convolutional Monte Carlo Rollouts in Go,"In this work, we present a MCTS-based Go-playing program which uses
convolutional networks in all parts. Our method performs MCTS in batches,
explores the Monte Carlo search tree using Thompson sampling and a
convolutional network, and evaluates convnet-based rollouts on the GPU. We
achieve strong win rates against open source Go programs and attain competitive
results against state of the art convolutional net-based Go-playing programs.",2015-12-10T19:32:48Z,"Peter H. Jin, Kurt Keutzer"
1512.04087v2,True Online Temporal-Difference Learning,"The temporal-difference methods TD($\lambda$) and Sarsa($\lambda$) form a
core part of modern reinforcement learning. Their appeal comes from their good
performance, low computational cost, and their simple interpretation, given by
their forward view. Recently, new versions of these methods were introduced,
called true online TD($\lambda$) and true online Sarsa($\lambda$), respectively
(van Seijen & Sutton, 2014). These new versions maintain an exact equivalence
with the forward view at all times, whereas the traditional versions only
approximate it for small step-sizes. We hypothesize that these true online
methods not only have better theoretical properties, but also dominate the
regular methods empirically. In this article, we put this hypothesis to the
test by performing an extensive empirical comparison. Specifically, we compare
the performance of true online TD($\lambda$)/Sarsa($\lambda$) with regular
TD($\lambda$)/Sarsa($\lambda$) on random MRPs, a real-world myoelectric
prosthetic arm, and a domain from the Arcade Learning Environment. We use
linear function approximation with tabular, binary, and non-binary features.
Our results suggest that the true online methods indeed dominate the regular
methods. Across all domains/representations the learning speed of the true
online methods are often better, but never worse than that of the regular
methods. An additional advantage is that no choice between traces has to be
made for the true online methods. Besides the empirical results, we provide an
in-depth analysis of the theory behind true online temporal-difference
learning. In addition, we show that new true online temporal-difference methods
can be derived by making changes to the online forward view and then rewriting
the update equations.",2015-12-13T17:13:33Z,"Harm van Seijen, A. Rupam Mahmood, Patrick M. Pilarski, Marlos C. Machado, Richard S. Sutton"
1512.04105v1,Policy Gradient Methods for Off-policy Control,"Off-policy learning refers to the problem of learning the value function of a
way of behaving, or policy, while following a different policy. Gradient-based
off-policy learning algorithms, such as GTD and TDC/GQ, converge even when
using function approximation and incremental updates. However, they have been
developed for the case of a fixed behavior policy. In control problems, one
would like to adapt the behavior policy over time to become more greedy with
respect to the existing value function. In this paper, we present the first
gradient-based learning algorithms for this problem, which rely on the
framework of policy gradient in order to modify the behavior policy. We present
derivations of the algorithms, a convergence theorem, and empirical evidence
showing that they compare favorably to existing approaches.",2015-12-13T19:20:14Z,"Lucas Lehnert, Doina Precup"
1512.04792v5,"From One Point to A Manifold: Knowledge Graph Embedding For Precise Link
  Prediction","Knowledge graph embedding aims at offering a numerical knowledge
representation paradigm by transforming the entities and relations into
continuous vector space. However, existing methods could not characterize the
knowledge graph in a fine degree to make a precise prediction. There are two
reasons: being an ill-posed algebraic system and applying an overstrict
geometric form. As precise prediction is critical, we propose an manifold-based
embedding principle (\textbf{ManifoldE}) which could be treated as a well-posed
algebraic system that expands the position of golden triples from one point in
current models to a manifold in ours. Extensive experiments show that the
proposed models achieve substantial improvements against the state-of-the-art
baselines especially for the precise prediction task, and yet maintain high
efficiency.",2015-12-15T14:24:44Z,"Han Xiao, Minlie Huang, Xiaoyan Zhu"
1512.04860v1,Increasing the Action Gap: New Operators for Reinforcement Learning,"This paper introduces new optimality-preserving operators on Q-functions. We
first describe an operator for tabular representations, the consistent Bellman
operator, which incorporates a notion of local policy consistency. We show that
this local consistency leads to an increase in the action gap at each state;
increasing this gap, we argue, mitigates the undesirable effects of
approximation and estimation errors on the induced greedy policies. This
operator can also be applied to discretized continuous space and time problems,
and we provide empirical results evidencing superior performance in this
context. Extending the idea of a locally consistent operator, we then derive
sufficient conditions for an operator to preserve optimality, leading to a
family of operators which includes our consistent Bellman operator. As
corollaries we provide a proof of optimality for Baird's advantage learning
algorithm and derive other gap-increasing operators with interesting
properties. We conclude with an empirical study on 60 Atari 2600 games
illustrating the strong potential of these new operators.",2015-12-15T17:13:49Z,"Marc G. Bellemare, Georg Ostrovski, Arthur Guez, Philip S. Thomas, Rmi Munos"
1512.05467v1,"Unsupervised Feature Construction for Improving Data Representation and
  Semantics","Feature-based format is the main data representation format used by machine
learning algorithms. When the features do not properly describe the initial
data, performance starts to degrade. Some algorithms address this problem by
internally changing the representation space, but the newly-constructed
features are rarely comprehensible. We seek to construct, in an unsupervised
way, new features that are more appropriate for describing a given dataset and,
at the same time, comprehensible for a human user. We propose two algorithms
that construct the new features as conjunctions of the initial primitive
features or their negations. The generated feature sets have reduced
correlations between features and succeed in catching some of the hidden
relations between individuals in a dataset. For example, a feature like $sky
\wedge \neg building \wedge panorama$ would be true for non-urban images and is
more informative than simple features expressing the presence or the absence of
an object. The notion of Pareto optimality is used to evaluate feature sets and
to obtain a balance between total correlation and the complexity of the
resulted feature set. Statistical hypothesis testing is used in order to
automatically determine the values of the parameters used for constructing a
data-dependent feature set. We experimentally show that our approaches achieve
the construction of informative feature sets for multiple datasets.",2015-12-17T05:18:05Z,"Marian-Andrei Rizoiu, Julien Velcin, Stphane Lallich"
1512.08120v2,"Regularized Orthogonal Tensor Decompositions for Multi-Relational
  Learning","Multi-relational learning has received lots of attention from researchers in
various research communities. Most existing methods either suffer from
superlinear per-iteration cost, or are sensitive to the given ranks. To address
both issues, we propose a scalable core tensor trace norm Regularized
Orthogonal Iteration Decomposition (ROID) method for full or incomplete tensor
analytics, which can be generalized as a graph Laplacian regularized version by
using auxiliary information or a sparse higher-order orthogonal iteration
(SHOOI) version. We first induce the equivalence relation of the Schatten
p-norm (0<p<\infty) of a low multi-linear rank tensor and its core tensor. Then
we achieve a much smaller matrix trace norm minimization problem. Finally, we
develop two efficient augmented Lagrange multiplier algorithms to solve our
problems with convergence guarantees. Extensive experiments using both real and
synthetic datasets, even though with only a few observations, verified both the
efficiency and effectiveness of our methods.",2015-12-26T15:26:05Z,"Fanhua Shang, James Cheng, Hong Cheng"
1601.00318v4,A Unified Approach for Learning the Parameters of Sum-Product Networks,"We present a unified approach for learning the parameters of Sum-Product
networks (SPNs). We prove that any complete and decomposable SPN is equivalent
to a mixture of trees where each tree corresponds to a product of univariate
distributions. Based on the mixture model perspective, we characterize the
objective function when learning SPNs based on the maximum likelihood
estimation (MLE) principle and show that the optimization problem can be
formulated as a signomial program. We construct two parameter learning
algorithms for SPNs by using sequential monomial approximations (SMA) and the
concave-convex procedure (CCCP), respectively. The two proposed methods
naturally admit multiplicative updates, hence effectively avoiding the
projection operation. With the help of the unified framework, we also show
that, in the case of SPNs, CCCP leads to the same algorithm as Expectation
Maximization (EM) despite the fact that they are different in general.",2016-01-03T18:11:14Z,"Han Zhao, Pascal Poupart, Geoff Gordon"
1601.01297v2,Angrier Birds: Bayesian reinforcement learning,"We train a reinforcement learner to play a simplified version of the game
Angry Birds. The learner is provided with a game state in a manner similar to
the output that could be produced by computer vision algorithms. We improve on
the efficiency of regular {\epsilon}-greedy Q-Learning with linear function
approximation through more systematic exploration in Randomized Least Squares
Value Iteration (RLSVI), an algorithm that samples its policy from a posterior
distribution on optimal policies. With larger state-action spaces, efficient
exploration becomes increasingly important, as evidenced by the faster learning
in RLSVI.",2016-01-06T20:22:22Z,"Imanol Arrieta Ibarra, Bernardo Ramos, Lars Roemheld"
1601.01675v1,Ensemble Methods of Classification for Power Systems Security Assessment,"One of the most promising approaches for complex technical systems analysis
employs ensemble methods of classification. Ensemble methods enable to build a
reliable decision rules for feature space classification in the presence of
many possible states of the system. In this paper, novel techniques based on
decision trees are used for evaluation of the reliability of the regime of
electric power systems. We proposed hybrid approach based on random forests
models and boosting models. Such techniques can be applied to predict the
interaction of increasing renewable power, storage devices and swiching of
smart loads from intelligent domestic appliances, heaters and air-conditioning
units and electric vehicles with grid for enhanced decision making. The
ensemble classification methods were tested on the modified 118-bus IEEE power
system showing that proposed technique can be employed to examine whether the
power system is secured under steady-state operating conditions.",2016-01-07T13:31:41Z,"Alexei Zhukov, Victor Kurbatsky, Nikita Tomin, Denis Sidorov, Daniil Panasetsky, Aoife Foley"
1601.04574v1,SimpleDS: A Simple Deep Reinforcement Learning Dialogue System,"This paper presents 'SimpleDS', a simple and publicly available dialogue
system trained with deep reinforcement learning. In contrast to previous
reinforcement learning dialogue systems, this system avoids manual feature
engineering by performing action selection directly from raw text of the last
system and (noisy) user responses. Our initial results, in the restaurant
domain, show that it is indeed possible to induce reasonable dialogue behaviour
with an approach that aims for high levels of automation in dialogue control
for intelligent interactive agents.",2016-01-18T15:37:22Z,Heriberto Cuayhuitl
1601.06180v2,On the Latent Variable Interpretation in Sum-Product Networks,"One of the central themes in Sum-Product networks (SPNs) is the
interpretation of sum nodes as marginalized latent variables (LVs). This
interpretation yields an increased syntactic or semantic structure, allows the
application of the EM algorithm and to efficiently perform MPE inference. In
literature, the LV interpretation was justified by explicitly introducing the
indicator variables corresponding to the LVs' states. However, as pointed out
in this paper, this approach is in conflict with the completeness condition in
SPNs and does not fully specify the probabilistic model. We propose a remedy
for this problem by modifying the original approach for introducing the LVs,
which we call SPN augmentation. We discuss conditional independencies in
augmented SPNs, formally establish the probabilistic interpretation of the
sum-weights and give an interpretation of augmented SPNs as Bayesian networks.
Based on these results, we find a sound derivation of the EM algorithm for
SPNs. Furthermore, the Viterbi-style algorithm for MPE proposed in literature
was never proven to be correct. We show that this is indeed a correct
algorithm, when applied to selective SPNs, and in particular when applied to
augmented SPNs. Our theoretical results are confirmed in experiments on
synthetic data and 103 real-world datasets.",2016-01-22T21:40:33Z,"Robert Peharz, Robert Gens, Franz Pernkopf, Pedro Domingos"
1601.06602v3,"Expected Similarity Estimation for Large-Scale Batch and Streaming
  Anomaly Detection","We present a novel algorithm for anomaly detection on very large datasets and
data streams. The method, named EXPected Similarity Estimation (EXPoSE), is
kernel-based and able to efficiently compute the similarity between new data
points and the distribution of regular data. The estimator is formulated as an
inner product with a reproducing kernel Hilbert space embedding and makes no
assumption about the type or shape of the underlying data distribution. We show
that offline (batch) learning with EXPoSE can be done in linear time and online
(incremental) learning takes constant time per instance and model update.
Furthermore, EXPoSE can make predictions in constant time, while it requires
only constant memory. In addition, we propose different methodologies for
concept drift adaptation on evolving data streams. On several real datasets we
demonstrate that our approach can compete with state of the art algorithms for
anomaly detection while being an order of magnitude faster than most other
approaches.",2016-01-25T13:56:59Z,"Markus Schneider, Wolfgang Ertel, Fabio Ramos"
1602.02672v1,"Learning to Communicate to Solve Riddles with Deep Distributed Recurrent
  Q-Networks","We propose deep distributed recurrent Q-networks (DDRQN), which enable teams
of agents to learn to solve communication-based coordination tasks. In these
tasks, the agents are not given any pre-designed communication protocol.
Therefore, in order to successfully communicate, they must first automatically
develop and agree upon their own communication protocol. We present empirical
results on two multi-agent learning problems based on well-known riddles,
demonstrating that DDRQN can successfully solve such tasks and discover elegant
communication protocols to do so. To our knowledge, this is the first time deep
reinforcement learning has succeeded in learning communication protocols. In
addition, we present ablation experiments that confirm that each of the main
components of the DDRQN architecture are critical to its success.",2016-02-08T18:01:35Z,"Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson"
1602.02706v2,Decoy Bandits Dueling on a Poset,"We adress the problem of dueling bandits defined on partially ordered sets,
or posets. In this setting, arms may not be comparable, and there may be
several (incomparable) optimal arms. We propose an algorithm, UnchainedBandits,
that efficiently finds the set of optimal arms of any poset even when pairs of
comparable arms cannot be distinguished from pairs of incomparable arms, with a
set of minimal assumptions. This algorithm relies on the concept of decoys,
which stems from social psychology. For the easier case where the
incomparability information may be accessible, we propose a second algorithm,
SlicingBandits, which takes advantage of this information and achieves a very
significant gain of performance compared to UnchainedBandits. We provide
theoretical guarantees and experimental evaluation for both algorithms.",2016-02-08T19:32:18Z,"Julien Audiffren, Ralaivola Liva"
1602.03348v2,Iterative Hierarchical Optimization for Misspecified Problems (IHOMP),"For complex, high-dimensional Markov Decision Processes (MDPs), it may be
necessary to represent the policy with function approximation. A problem is
misspecified whenever, the representation cannot express any policy with
acceptable performance. We introduce IHOMP : an approach for solving
misspecified problems. IHOMP iteratively learns a set of context specialized
options and combines these options to solve an otherwise misspecified problem.
Our main contribution is proving that IHOMP enjoys theoretical convergence
guarantees. In addition, we extend IHOMP to exploit Option Interruption (OI)
enabling it to decide where the learned options can be reused. Our experiments
demonstrate that IHOMP can find near-optimal solutions to otherwise
misspecified problems and that OI can further improve the solutions.",2016-02-10T12:27:04Z,"Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor"
1602.04889v3,Unsupervised Domain Adaptation Using Approximate Label Matching,"Domain adaptation addresses the problem created when training data is
generated by a so-called source distribution, but test data is generated by a
significantly different target distribution. In this work, we present
approximate label matching (ALM), a new unsupervised domain adaptation
technique that creates and leverages a rough labeling on the test samples, then
uses these noisy labels to learn a transformation that aligns the source and
target samples. We show that the transformation estimated by ALM has favorable
properties compared to transformations estimated by other methods, which do not
use any kind of target labeling. Our model is regularized by requiring that a
classifier trained to discriminate source from transformed target samples
cannot distinguish between the two. We experiment with ALM on simulated and
real data, and show that it outperforms techniques commonly used in the field.",2016-02-16T02:38:25Z,"Jordan T. Ash, Robert E. Schapire, Barbara E. Engelhardt"
1602.06539v1,"Determining the best attributes for surveillance video keywords
  generation","Automatic video keyword generation is one of the key ingredients in reducing
the burden of security officers in analyzing surveillance videos. Keywords or
attributes are generally chosen manually based on expert knowledge of
surveillance. Most existing works primarily aim at either supervised learning
approaches relying on extensive manual labelling or hierarchical probabilistic
models that assume the features are extracted using the bag-of-words approach;
thus limiting the utilization of the other features. To address this, we turn
our attention to automatic attribute discovery approaches. However, it is not
clear which automatic discovery approach can discover the most meaningful
attributes. Furthermore, little research has been done on how to compare and
choose the best automatic attribute discovery methods. In this paper, we
propose a novel approach, based on the shared structure exhibited amongst
meaningful attributes, that enables us to compare between different automatic
attribute discovery approaches.We then validate our approach by comparing
various attribute discovery methods such as PiCoDeS on two attribute datasets.
The evaluation shows that our approach is able to select the automatic
discovery approach that discovers the most meaningful attributes. We then
employ the best discovery approach to generate keywords for videos recorded
from a surveillance system. This work shows it is possible to massively reduce
the amount of manual work in generating video keywords without limiting
ourselves to a particular video feature descriptor.",2016-02-21T15:08:51Z,"Liangchen Liu, Arnold Wiliem, Shaokang Chen, Kun Zhao, Brian C. Lovell"
1602.07857v4,"Modeling cumulative biological phenomena with Suppes-Bayes Causal
  Networks","Several diseases related to cell proliferation are characterized by the
accumulation of somatic DNA changes, with respect to wildtype conditions.
Cancer and HIV are two common examples of such diseases, where the mutational
load in the cancerous/viral population increases over time. In these cases,
selective pressures are often observed along with competition, cooperation and
parasitism among distinct cellular clones. Recently, we presented a
mathematical framework to model these phenomena, based on a combination of
Bayesian inference and Suppes' theory of probabilistic causation, depicted in
graphical structures dubbed Suppes-Bayes Causal Networks (SBCNs). SBCNs are
generative probabilistic graphical models that recapitulate the potential
ordering of accumulation of such DNA changes during the progression of the
disease. Such models can be inferred from data by exploiting likelihood-based
model-selection strategies with regularization. In this paper we discuss the
theoretical foundations of our approach and we investigate in depth the
influence on the model-selection task of: (i) the poset based on Suppes' theory
and (ii) different regularization strategies. Furthermore, we provide an
example of application of our framework to HIV genetic data highlighting the
valuable insights provided by the inferred.",2016-02-25T09:23:58Z,"Daniele Ramazzotti, Alex Graudenzi, Giulio Caravagna, Marco Antoniotti"
1602.08350v2,Large-Scale Detection of Non-Technical Losses in Imbalanced Data Sets,"Non-technical losses (NTL) such as electricity theft cause significant harm
to our economies, as in some countries they may range up to 40% of the total
electricity distributed. Detecting NTLs requires costly on-site inspections.
Accurate prediction of NTLs for customers using machine learning is therefore
crucial. To date, related research largely ignore that the two classes of
regular and non-regular customers are highly imbalanced, that NTL proportions
may change and mostly consider small data sets, often not allowing to deploy
the results in production. In this paper, we present a comprehensive approach
to assess three NTL detection models for different NTL proportions in large
real world data sets of 100Ks of customers: Boolean rules, fuzzy logic and
Support Vector Machine. This work has resulted in appreciable results that are
about to be deployed in a leading industry solution. We believe that the
considerations and observations made in this contribution are necessary for
future smart meter research in order to report their effectiveness on
imbalanced and large real world data sets.",2016-02-26T14:49:29Z,"Patrick O. Glauner, Andre Boechat, Lautaro Dolberg, Radu State, Franck Bettinger, Yves Rangoni, Diogo Duarte"
1604.00923v1,Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning,"In this paper we present a new way of predicting the performance of a
reinforcement learning policy given historical data that may have been
generated by a different policy. The ability to evaluate a policy from
historical data is important for applications where the deployment of a bad
policy can be dangerous or costly. We show empirically that our algorithm
produces estimates that often have orders of magnitude lower mean squared error
than existing methods---it makes more efficient use of the available data. Our
new estimator is based on two advances: an extension of the doubly robust
estimator (Jiang and Li, 2015), and a new way to mix between model based
estimates and importance sampling based estimates.",2016-04-04T15:56:52Z,"Philip S. Thomas, Emma Brunskill"
1604.01350v1,Bounded Optimal Exploration in MDP,"Within the framework of probably approximately correct Markov decision
processes (PAC-MDP), much theoretical work has focused on methods to attain
near optimality after a relatively long period of learning and exploration.
However, practical concerns require the attainment of satisfactory behavior
within a short period of time. In this paper, we relax the PAC-MDP conditions
to reconcile theoretically driven exploration methods and practical needs. We
propose simple algorithms for discrete and continuous state spaces, and
illustrate the benefits of our proposed relaxation via theoretical analyses and
numerical examples. Our algorithms also maintain anytime error bounds and
average loss bounds. Our approach accommodates both Bayesian and non-Bayesian
methods.",2016-04-05T18:00:02Z,Kenji Kawaguchi
1604.02336v2,"Back to the Basics: Bayesian extensions of IRT outperform neural
  networks for proficiency estimation","Estimating student proficiency is an important task for computer based
learning systems. We compare a family of IRT-based proficiency estimation
methods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural
network model with promising initial results. We evaluate how well each model
predicts a student's future response given previous responses using two
publicly available and one proprietary data set. We find that IRT-based methods
consistently matched or outperformed DKT across all data sets at the finest
level of content granularity that was tractable for them to be trained on. A
hierarchical extension of IRT that captured item grouping structure performed
best overall. When data sets included non-trivial autocorrelations in student
response patterns, a temporal extension of IRT improved performance over
standard IRT while the RNN-based method did not. We conclude that IRT-based
models provide a simpler, better-performing alternative to existing RNN-based
models of student interaction data while also affording more interpretability
and guarantees due to their formulation as Bayesian probabilistic models.",2016-04-08T12:54:18Z,"Kevin H. Wilson, Yan Karklin, Bojian Han, Chaitanya Ekanadham"
1604.03099v1,Symbolic Knowledge Extraction using ukasiewicz Logics,"This work describes a methodology that combines logic-based systems and
connectionist systems. Our approach uses finite truth-valued {\L}ukasiewicz
logic, wherein every connective can be defined by a neuron in an artificial
network. This allowed the injection of first-order formulas into a network
architecture, and also simplified symbolic rule extraction. For that we trained
a neural networks using the Levenderg-Marquardt algorithm, where we restricted
the knowledge dissemination in the network structure. This procedure reduces
neural network plasticity without drastically damaging the learning
performance, thus making the descriptive power of produced neural networks
similar to the descriptive power of {\L}ukasiewicz logic language and
simplifying the translation between symbolic and connectionist structures. We
used this method for reverse engineering truth table and in extraction of
formulas from real data sets.",2016-04-11T05:17:09Z,Carlos Leandro
1604.03200v1,Efficient Classification of Multi-Labelled Text Streams by Clashing,"We present a method for the classification of multi-labelled text documents
explicitly designed for data stream applications that require to process a
virtually infinite sequence of data using constant memory and constant
processing time. Our method is composed of an online procedure used to
efficiently map text into a low-dimensional feature space and a partition of
this space into a set of regions for which the system extracts and keeps
statistics used to predict multi-label text annotations. Documents are fed into
the system as a sequence of words, mapped to a region of the partition, and
annotated using the statistics computed from the labelled instances colliding
in the same region. This approach is referred to as clashing. We illustrate the
method in real-world text data, comparing the results with those obtained using
other text classifiers. In addition, we provide an analysis about the effect of
the representation space dimensionality on the predictive performance of the
system. Our results show that the online embedding indeed approximates the
geometry of the full corpus-wise TF and TF-IDF space. The model obtains
competitive F measures with respect to the most accurate methods, using
significantly fewer computational resources. In addition, the method achieves a
higher macro-averaged F measure than methods with similar running time.
Furthermore, the system is able to learn faster than the other methods from
partially labelled streams.",2016-04-12T01:52:38Z,"Ricardo anculef, Ilias Flaounas, Nello Cristianini"
1604.05024v1,"Empirical study of PROXTONE and PROXTONE$^+$ for Fast Learning of Large
  Scale Sparse Models","PROXTONE is a novel and fast method for optimization of large scale
non-smooth convex problem \cite{shi2015large}. In this work, we try to use
PROXTONE method in solving large scale \emph{non-smooth non-convex} problems,
for example training of sparse deep neural network (sparse DNN) or sparse
convolutional neural network (sparse CNN) for embedded or mobile device.
PROXTONE converges much faster than first order methods, while first order
method is easy in deriving and controlling the sparseness of the solutions.
Thus in some applications, in order to train sparse models fast, we propose to
combine the merits of both methods, that is we use PROXTONE in the first
several epochs to reach the neighborhood of an optimal solution, and then use
the first order method to explore the possibility of sparsity in the following
training. We call such method PROXTONE plus (PROXTONE$^+$). Both PROXTONE and
PROXTONE$^+$ are tested in our experiments, and which demonstrate both methods
improved convergence speed twice as fast at least on diverse sparse model
learning problems, and at the same time reduce the size to 0.5\% for DNN
models. The source of all the algorithms is available upon request.",2016-04-18T08:01:02Z,"Ziqiang Shi, Rujie Liu"
1604.05085v3,"Mastering 2048 with Delayed Temporal Coherence Learning, Multi-Stage
  Weight Promotion, Redundant Encoding and Carousel Shaping","2048 is an engaging single-player, nondeterministic video puzzle game, which,
thanks to the simple rules and hard-to-master gameplay, has gained massive
popularity in recent years. As 2048 can be conveniently embedded into the
discrete-state Markov decision processes framework, we treat it as a testbed
for evaluating existing and new methods in reinforcement learning. With the aim
to develop a strong 2048 playing program, we employ temporal difference
learning with systematic n-tuple networks. We show that this basic method can
be significantly improved with temporal coherence learning, multi-stage
function approximator with weight promotion, carousel shaping, and redundant
encoding. In addition, we demonstrate how to take advantage of the
characteristics of the n-tuple network, to improve the algorithmic
effectiveness of the learning process by i) delaying the (decayed) update and
applying lock-free optimistic parallelism to effortlessly make advantage of
multiple CPU cores. This way, we were able to develop the best known 2048
playing program to date, which confirms the effectiveness of the introduced
methods for discrete-state Markov decision problems.",2016-04-18T11:06:32Z,Wojciech Jakowski
1604.05753v1,Sketching and Neural Networks,"High-dimensional sparse data present computational and statistical challenges
for supervised learning. We propose compact linear sketches for reducing the
dimensionality of the input, followed by a single layer neural network. We show
that any sparse polynomial function can be computed, on nearly all sparse
binary vectors, by a single layer neural network that takes a compact sketch of
the vector as input. Consequently, when a set of sparse binary vectors is
approximately separable using a sparse polynomial, there exists a single-layer
neural network that takes a short sketch as input and correctly classifies
nearly all the points. Previous work has proposed using sketches to reduce
dimensionality while preserving the hypothesis class. However, the sketch size
has an exponential dependence on the degree in the case of polynomial
classifiers. In stark contrast, our approach of using improper learning, using
a larger hypothesis class allows the sketch size to have a logarithmic
dependence on the degree. Even in the linear case, our approach allows us to
improve on the pesky $O({1}/{{\gamma}^2})$ dependence of random projections, on
the margin $\gamma$. We empirically show that our approach leads to more
compact neural networks than related methods such as feature hashing at equal
or better performance.",2016-04-19T21:22:29Z,"Amit Daniely, Nevena Lazic, Yoram Singer, Kunal Talwar"
1604.06743v1,"Latent Contextual Bandits and their Application to Personalized
  Recommendations for New Users","Personalized recommendations for new users, also known as the cold-start
problem, can be formulated as a contextual bandit problem. Existing contextual
bandit algorithms generally rely on features alone to capture user variability.
Such methods are inefficient in learning new users' interests. In this paper we
propose Latent Contextual Bandits. We consider both the benefit of leveraging a
set of learned latent user classes for new users, and how we can learn such
latent classes from prior users. We show that our approach achieves a better
regret bound than existing algorithms. We also demonstrate the benefit of our
approach using a large real world dataset and a preliminary user study.",2016-04-22T16:47:04Z,"Li Zhou, Emma Brunskill"
1604.06849v1,"A Computational Model for Situated Task Learning with Interactive
  Instruction","Learning novel tasks is a complex cognitive activity requiring the learner to
acquire diverse declarative and procedural knowledge. Prior ACT-R models of
acquiring task knowledge from instruction focused on learning procedural
knowledge from declarative instructions encoded in semantic memory. In this
paper, we identify the requirements for designing compu- tational models that
learn task knowledge from situated task- oriented interactions with an expert
and then describe and evaluate a model of learning from situated interactive
instruc- tion that is implemented in the Soar cognitive architecture.",2016-04-23T02:23:14Z,"Shiwali Mohan, James Kirk, John Laird"
1604.07255v3,A Deep Hierarchical Approach to Lifelong Learning in Minecraft,"We propose a lifelong learning system that has the ability to reuse and
transfer knowledge from one task to another while efficiently retaining the
previously learned knowledge-base. Knowledge is transferred by learning
reusable skills to solve tasks in Minecraft, a popular video game which is an
unsolved and high-dimensional lifelong learning problem. These reusable skills,
which we refer to as Deep Skill Networks, are then incorporated into our novel
Hierarchical Deep Reinforcement Learning Network (H-DRLN) architecture using
two techniques: (1) a deep skill array and (2) skill distillation, our novel
variation of policy distillation (Rusu et. al. 2015) for learning skills. Skill
distillation enables the HDRLN to efficiently retain knowledge and therefore
scale in lifelong learning, by accumulating knowledge and encapsulating
multiple reusable skills into a single distilled network. The H-DRLN exhibits
superior performance and lower learning sample complexity compared to the
regular Deep Q Network (Mnih et. al. 2015) in sub-domains of Minecraft.",2016-04-25T13:45:50Z,"Chen Tessler, Shahar Givony, Tom Zahavy, Daniel J. Mankowitz, Shie Mannor"
1604.08642v1,"On the representation and embedding of knowledge bases beyond binary
  relations","The models developed to date for knowledge base embedding are all based on
the assumption that the relations contained in knowledge bases are binary. For
the training and testing of these embedding models, multi-fold (or n-ary)
relational data are converted to triples (e.g., in FB15K dataset) and
interpreted as instances of binary relations. This paper presents a canonical
representation of knowledge bases containing multi-fold relations. We show that
the existing embedding models on the popular FB15K datasets correspond to a
sub-optimal modelling framework, resulting in a loss of structural information.
We advocate a novel modelling framework, which models multi-fold relations
directly using this canonical representation. Using this framework, the
existing TransH model is generalized to a new model, m-TransH. We demonstrate
experimentally that m-TransH outperforms TransH by a large margin, thereby
establishing a new state of the art.",2016-04-28T22:42:38Z,"Jianfeng Wen, Jianxin Li, Yongyi Mao, Shini Chen, Richong Zhang"
1605.00241v1,"Common-Description Learning: A Framework for Learning Algorithms and
  Generating Subproblems from Few Examples","Current learning algorithms face many difficulties in learning simple
patterns and using them to learn more complex ones. They also require more
examples than humans do to learn the same pattern, assuming no prior knowledge.
In this paper, a new learning framework is introduced that is called
common-description learning (CDL). This framework has been tested on 32 small
multi-task datasets, and the results show that it was able to learn complex
algorithms from a few number of examples. The final model is perfectly
interpretable and its depth depends on the question. What is meant by depth
here is that whenever needed, the model learns to break down the problem into
simpler subproblems and solves them using previously learned models. Finally,
we explain the capabilities of our framework in discovering complex relations
in data and how it can help in improving language understanding in machines.",2016-05-01T11:56:01Z,Basem G. El-Barashy
1605.00788v2,Online Learning of Commission Avoidant Portfolio Ensembles,"We present a novel online ensemble learning strategy for portfolio selection.
The new strategy controls and exploits any set of commission-oblivious
portfolio selection algorithms. The strategy handles transaction costs using a
novel commission avoidance mechanism. We prove a logarithmic regret bound for
our strategy with respect to optimal mixtures of the base algorithms. Numerical
examples validate the viability of our method and show significant improvement
over the state-of-the-art.",2016-05-03T08:38:34Z,"Guy Uziel, Ran El-Yaniv"
1605.01335v1,Learning from the memory of Atari 2600,"We train a number of neural networks to play games Bowling, Breakout and
Seaquest using information stored in the memory of a video game console Atari
2600. We consider four models of neural networks which differ in size and
architecture: two networks which use only information contained in the RAM and
two mixed networks which use both information in the RAM and information from
the screen. As the benchmark we used the convolutional model proposed in NIPS
and received comparable results in all considered games. Quite surprisingly, in
the case of Seaquest we were able to train RAM-only agents which behave better
than the benchmark screen-only agent. Mixing screen and RAM did not lead to an
improved performance comparing to screen-only and RAM-only agents.",2016-05-04T16:23:34Z,"Jakub Sygnowski, Henryk Michalewski"
1605.04056v2,Causal Discovery for Manufacturing Domains,"Yield and quality improvement is of paramount importance to any manufacturing
company. One of the ways of improving yield is through discovery of the root
causal factors affecting yield. We propose the use of data-driven interpretable
causal models to identify key factors affecting yield. We focus on factors that
are measured in different stages of production and testing in the manufacturing
cycle of a product. We apply causal structure learning techniques on real data
collected from this line. Specifically, the goal of this work is to learn
interpretable causal models from observational data produced by manufacturing
lines.
  Emphasis has been given to the interpretability of the models to make them
actionable in the field of manufacturing. We highlight the challenges presented
by assembly line data and propose ways to alleviate them.We also identify
unique characteristics of data originating from assembly lines and how to
leverage them in order to improve causal discovery. Standard evaluation
techniques for causal structure learning shows that the learned causal models
seem to closely represent the underlying latent causal relationship between
different factors in the production process. These results were also validated
by manufacturing domain experts who found them promising. This work
demonstrates how data mining and knowledge discovery can be used for root cause
analysis in the domain of manufacturing and connected industry.",2016-05-13T06:17:54Z,"Katerina Marazopoulou, Rumi Ghosh, Prasanth Lade, David Jensen"
1605.06377v1,"Towards Automation of Knowledge Understanding: An Approach for
  Probabilistic Generative Classifiers","After data selection, pre-processing, transformation, and feature extraction,
knowledge extraction is not the final step in a data mining process. It is then
necessary to understand this knowledge in order to apply it efficiently and
effectively. Up to now, there is a lack of appropriate techniques that support
this significant step. This is partly due to the fact that the assessment of
knowledge is often highly subjective, e.g., regarding aspects such as novelty
or usefulness. These aspects depend on the specific knowledge and requirements
of the data miner. There are, however, a number of aspects that are objective
and for which it is possible to provide appropriate measures. In this article
we focus on classification problems and use probabilistic generative
classifiers based on mixture density models that are quite common in data
mining applications. We define objective measures to assess the
informativeness, uniqueness, importance, discrimination, representativity,
uncertainty, and distinguishability of rules contained in these classifiers
numerically. These measures not only support a data miner in evaluating results
of a data mining process based on such classifiers. As we will see in
illustrative case studies, they may also be used to improve the data mining
process itself or to support the later application of the extracted knowledge.",2016-05-20T14:34:49Z,"Dominik Fisch, Christian Gruhl, Edgar Kalkowski, Bernhard Sick, Seppo J. Ovaska"
1605.07148v4,Backprop KF: Learning Discriminative Deterministic State Estimators,"Generative state estimators based on probabilistic filters and smoothers are
one of the most popular classes of state estimators for robots and autonomous
vehicles. However, generative models have limited capacity to handle rich
sensory observations, such as camera images, since they must model the entire
distribution over sensor readings. Discriminative models do not suffer from
this limitation, but are typically more complex to train as latent variable
models for state estimation. We present an alternative approach where the
parameters of the latent state distribution are directly optimized as a
deterministic computation graph, resulting in a simple and effective gradient
descent algorithm for training discriminative state estimators. We show that
this procedure can be used to train state estimators that use complex input,
such as raw camera images, which must be processed using expressive nonlinear
function approximators such as convolutional neural networks. Our model can be
viewed as a type of recurrent neural network, and the connection to
probabilistic filtering allows us to design a network architecture that is
particularly well suited for state estimation. We evaluate our approach on
synthetic tracking task with raw image inputs and on the visual odometry task
in the KITTI dataset. The results show significant improvement over both
standard generative approaches and regular recurrent neural networks.",2016-05-23T19:28:21Z,"Tuomas Haarnoja, Anurag Ajay, Sergey Levine, Pieter Abbeel"
1605.07334v2,Near-optimal Bayesian Active Learning with Correlated and Noisy Tests,"We consider the Bayesian active learning and experimental design problem,
where the goal is to learn the value of some unknown target variable through a
sequence of informative, noisy tests. In contrast to prior work, we focus on
the challenging, yet practically relevant setting where test outcomes can be
conditionally dependent given the hidden target variable. Under such
assumptions, common heuristics, such as greedily performing tests that maximize
the reduction in uncertainty of the target, often perform poorly. In this
paper, we propose ECED, a novel, computationally efficient active learning
algorithm, and prove strong theoretical guarantees that hold with correlated,
noisy tests. Rather than directly optimizing the prediction error, at each
step, ECED picks the test that maximizes the gain in a surrogate objective,
which takes into account the dependencies between tests. Our analysis relies on
an information-theoretic auxiliary function to track the progress of ECED, and
utilizes adaptive submodularity to attain the near-optimal bound. We
demonstrate strong empirical performance of ECED on two problem instances,
including a Bayesian experimental design task intended to distinguish among
economic theories of how people make risky decisions, and an active preference
learning task via pairwise comparisons.",2016-05-24T08:25:27Z,"Yuxin Chen, S. Hamed Hassani, Andreas Krause"
1605.07700v1,Learning Purposeful Behaviour in the Absence of Rewards,"Artificial intelligence is commonly defined as the ability to achieve goals
in the world. In the reinforcement learning framework, goals are encoded as
reward functions that guide agent behaviour, and the sum of observed rewards
provide a notion of progress. However, some domains have no such reward signal,
or have a reward signal so sparse as to appear absent. Without reward feedback,
agent behaviour is typically random, often dithering aimlessly and lacking
intentionality. In this paper we present an algorithm capable of learning
purposeful behaviour in the absence of rewards. The algorithm proceeds by
constructing temporally extended actions (options), through the identification
of purposes that are ""just out of reach"" of the agent's current behaviour.
These purposes establish intrinsic goals for the agent to learn, ultimately
resulting in a suite of behaviours that encourage the agent to visit different
parts of the state space. Moreover, the approach is particularly suited for
settings where rewards are very sparse, and such behaviours can help in the
exploration of the environment until reward is observed.",2016-05-25T01:33:34Z,"Marlos C. Machado, Michael Bowling"
1605.07736v2,Learning Multiagent Communication with Backpropagation,"Many tasks in AI require the collaboration of multiple agents. Typically, the
communication protocol between agents is manually specified and not altered
during training. In this paper we explore a simple neural model, called
CommNet, that uses continuous communication for fully cooperative tasks. The
model consists of multiple agents and the communication between them is learned
alongside their policy. We apply this model to a diverse set of tasks,
demonstrating the ability of the agents to learn to communicate amongst
themselves, yielding improved performance over non-communicative agents and
baselines. In some cases, it is possible to interpret the language devised by
the agents, revealing simple but effective strategies for solving the task at
hand.",2016-05-25T05:33:21Z,"Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus"
1605.07969v2,Adaptive Neural Compilation,"This paper proposes an adaptive neural-compilation framework to address the
problem of efficient program learning. Traditional code optimisation strategies
used in compilers are based on applying pre-specified set of transformations
that make the code faster to execute without changing its semantics. In
contrast, our work involves adapting programs to make them more efficient while
considering correctness only on a target input distribution. Our approach is
inspired by the recent works on differentiable representations of programs. We
show that it is possible to compile programs written in a low-level language to
a differentiable representation. We also show how programs in this
representation can be optimised to make them efficient on a target distribution
of inputs. Experimental results demonstrate that our approach enables learning
specifically-tuned algorithms for given data distributions with a high success
rate.",2016-05-25T17:17:21Z,"Rudy Bunel, Alban Desmaison, Pushmeet Kohli, Philip H. S. Torr, M. Pawan Kumar"
1605.08478v1,Model-Free Imitation Learning with Policy Optimization,"In imitation learning, an agent learns how to behave in an environment with
an unknown cost function by mimicking expert demonstrations. Existing imitation
learning algorithms typically involve solving a sequence of planning or
reinforcement learning problems. Such algorithms are therefore not directly
applicable to large, high-dimensional environments, and their performance can
significantly degrade if the planning problems are not solved to optimality.
Under the apprenticeship learning formalism, we develop alternative model-free
algorithms for finding a parameterized stochastic policy that performs at least
as well as an expert policy on an unknown cost function, based on sample
trajectories from the expert. Our approach, based on policy gradients, scales
to large continuous environments with guaranteed convergence to local minima.",2016-05-26T23:43:32Z,"Jonathan Ho, Jayesh K. Gupta, Stefano Ermon"
1606.00917v1,Towards a Job Title Classification System,"Document classification for text, images and other applicable entities has
long been a focus of research in academia and also finds application in many
industrial settings. Amidst a plethora of approaches to solve such problems,
machine-learning techniques have found success in a variety of scenarios. In
this paper we discuss the design of a machine learning-based semi-supervised
job title classification system for the online job recruitment domain currently
in production at CareerBuilder.com and propose enhancements to it. The system
leverages a varied collection of classification as well clustering algorithms.
These algorithms are encompassed in an architecture that facilitates leveraging
existing off-the-shelf machine learning tools and techniques while keeping into
consideration the challenges of constructing a scalable classification system
for a large taxonomy of categories. As a continuously evolving system that is
still under development we first discuss the existing semi-supervised
classification system which is composed of both clustering and classification
components in a proximity-based classifier setup and results of which are
already used across numerous products at CareerBuilder. We then elucidate our
long-term goals for job title classification and propose enhancements to the
existing system in the form of a two-stage coarse and fine level classifier
augmentation to construct a cascade of hierarchical vertical classifiers.
Preliminary results are presented using experimental evaluation on real world
industrial data.",2016-06-02T22:01:50Z,"Faizan Javed, Matt McNair, Ferosh Jacob, Meng Zhao"
1606.01540v1,OpenAI Gym,"OpenAI Gym is a toolkit for reinforcement learning research. It includes a
growing collection of benchmark problems that expose a common interface, and a
website where people can share their results and compare the performance of
algorithms. This whitepaper discusses the components of OpenAI Gym and the
design decisions that went into the software.",2016-06-05T17:54:48Z,"Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, Wojciech Zaremba"
1606.02854v1,"e-Commerce product classification: our participation at cDiscount 2015
  challenge","This report describes our participation in the cDiscount 2015 challenge where
the goal was to classify product items in a predefined taxonomy of products.
Our best submission yielded an accuracy score of 64.20\% in the private part of
the leaderboard and we were ranked 10th out of 175 participating teams. We
followed a text classification approach employing mainly linear models. The
final solution was a weighted voting system which combined a variety of trained
models.",2016-06-09T08:06:00Z,"Ioannis Partalas, Georgios Balikas"
1606.03476v1,Generative Adversarial Imitation Learning,"Consider learning a policy from example expert behavior, without interaction
with the expert or access to reinforcement signal. One approach is to recover
the expert's cost function with inverse reinforcement learning, then extract a
policy from that cost function with reinforcement learning. This approach is
indirect and can be slow. We propose a new general framework for directly
extracting a policy from data, as if it were obtained by reinforcement learning
following inverse reinforcement learning. We show that a certain instantiation
of our framework draws an analogy between imitation learning and generative
adversarial networks, from which we derive a model-free imitation learning
algorithm that obtains significant performance gains over existing model-free
methods in imitating complex behaviors in large, high-dimensional environments.",2016-06-10T20:51:29Z,"Jonathan Ho, Stefano Ermon"
1606.04695v1,Strategic Attentive Writer for Learning Macro-Actions,"We present a novel deep recurrent neural network architecture that learns to
build implicit plans in an end-to-end manner by purely interacting with an
environment in reinforcement learning setting. The network builds an internal
plan, which is continuously updated upon observation of the next input from the
environment. It can also partition this internal representation into contiguous
sub- sequences by learning for how long the plan can be committed to - i.e.
followed without re-planing. Combining these properties, the proposed model,
dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally
abstracted macro- actions of varying lengths that are solely learnt from data
without any prior information. These macro-actions enable both structured
exploration and economic computation. We experimentally demonstrate that STRAW
delivers strong improvements on several ATARI games by employing temporally
extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same
time a general algorithm that can be applied on any sequence data. To that end,
we also show that when trained on text prediction task, STRAW naturally
predicts frequent n-grams (instead of macro-actions), demonstrating the
generality of the approach.",2016-06-15T09:28:52Z," Alexander,  Vezhnevets, Volodymyr Mnih, John Agapiou, Simon Osindero, Alex Graves, Oriol Vinyals, Koray Kavukcuoglu"
1606.06565v2,Concrete Problems in AI Safety,"Rapid progress in machine learning and artificial intelligence (AI) has
brought increasing attention to the potential impacts of AI technologies on
society. In this paper we discuss one such potential impact: the problem of
accidents in machine learning systems, defined as unintended and harmful
behavior that may emerge from poor design of real-world AI systems. We present
a list of five practical research problems related to accident risk,
categorized according to whether the problem originates from having the wrong
objective function (""avoiding side effects"" and ""avoiding reward hacking""), an
objective function that is too expensive to evaluate frequently (""scalable
supervision""), or undesirable behavior during the learning process (""safe
exploration"" and ""distributional shift""). We review previous work in these
areas as well as suggesting research directions with a focus on relevance to
cutting-edge AI systems. Finally, we consider the high-level question of how to
think most productively about the safety of forward-looking applications of AI.",2016-06-21T13:37:05Z,"Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, Dan Man"
1606.08808v2,Adaptive Training of Random Mapping for Data Quantization,"Data quantization learns encoding results of data with certain requirements,
and provides a broad perspective of many real-world applications to data
handling. Nevertheless, the results of encoder is usually limited to
multivariate inputs with the random mapping, and side information of binary
codes are hardly to mostly depict the original data patterns as possible. In
the literature, cosine based random quantization has attracted much attentions
due to its intrinsic bounded results. Nevertheless, it usually suffers from the
uncertain outputs, and information of original data fails to be fully preserved
in the reduced codes. In this work, a novel binary embedding method, termed
adaptive training quantization (ATQ), is proposed to learn the ideal transform
of random encoder, where the limitation of cosine random mapping is tackled. As
an adaptive learning idea, the reduced mapping is adaptively calculated with
idea of data group, while the bias of random transform is to be improved to
hold most matching information. Experimental results show that the proposed
method is able to obtain outstanding performance compared with other random
quantization methods.",2016-06-28T18:15:32Z,"Miao Cheng, Ah Chung Tsoi"
1607.00872v2,"Neighborhood Features Help Detecting Non-Technical Losses in Big Data
  Sets","Electricity theft is a major problem around the world in both developed and
developing countries and may range up to 40% of the total electricity
distributed. More generally, electricity theft belongs to non-technical losses
(NTL), which are losses that occur during the distribution of electricity in
power grids. In this paper, we build features from the neighborhood of
customers. We first split the area in which the customers are located into
grids of different sizes. For each grid cell we then compute the proportion of
inspected customers and the proportion of NTL found among the inspected
customers. We then analyze the distributions of features generated and show why
they are useful to predict NTL. In addition, we compute features from the
consumption time series of customers. We also use master data features of
customers, such as their customer class and voltage of their connection. We
compute these features for a Big Data base of 31M meter readings, 700K
customers and 400K inspection results. We then use these features to train four
machine learning algorithms that are particularly suitable for Big Data sets
because of their parallelizable structure: logistic regression, k-nearest
neighbors, linear support vector machine and random forest. Using the
neighborhood features instead of only analyzing the time series has resulted in
appreciable results for Big Data sets for varying NTL proportions of 1%-90%.
This work can therefore be deployed to a wide range of different regions around
the world.",2016-07-04T13:08:19Z,"Patrick Glauner, Jorge Meira, Lautaro Dolberg, Radu State, Franck Bettinger, Yves Rangoni, Diogo Duarte"
1607.01690v1,"A New Hierarchical Redundancy Eliminated Tree Augmented Naive Bayes
  Classifier for Coping with Gene Ontology-based Features","The Tree Augmented Naive Bayes classifier is a type of probabilistic
graphical model that can represent some feature dependencies. In this work, we
propose a Hierarchical Redundancy Eliminated Tree Augmented Naive Bayes
(HRE-TAN) algorithm, which considers removing the hierarchical redundancy
during the classifier learning process, when coping with data containing
hierarchically structured features. The experiments showed that HRE-TAN obtains
significantly better predictive performance than the conventional Tree
Augmented Naive Bayes classifier, and enhanced the robustness against
imbalanced class distributions, in aging-related gene datasets with Gene
Ontology terms used as features.",2016-07-06T16:00:43Z,"Cen Wan, Alex A. Freitas"
1607.03611v2,Characterizing Driving Styles with Deep Learning,"Characterizing driving styles of human drivers using vehicle sensor data,
e.g., GPS, is an interesting research problem and an important real-world
requirement from automotive industries. A good representation of driving
features can be highly valuable for autonomous driving, auto insurance, and
many other application scenarios. However, traditional methods mainly rely on
handcrafted features, which limit machine learning algorithms to achieve a
better performance. In this paper, we propose a novel deep learning solution to
this problem, which could be the first attempt of extending deep learning to
driving behavior analysis based on GPS data. The proposed approach can
effectively extract high level and interpretable features describing complex
driving patterns. It also requires significantly less human experience and
work. The power of the learned driving style representations are validated
through the driver identification problem using a large real dataset.",2016-07-13T07:15:30Z,"Weishan Dong, Jian Li, Renjie Yao, Changsheng Li, Ting Yuan, Lanjun Wang"
1607.03705v1,"Possibilistic Networks: Parameters Learning from Imprecise Data and
  Evaluation strategy","There has been an ever-increasing interest in multidisciplinary research on
representing and reasoning with imperfect data. Possibilistic networks present
one of the powerful frameworks of interest for representing uncertain and
imprecise information. This paper covers the problem of their parameters
learning from imprecise datasets, i.e., containing multi-valued data. We
propose in the rst part of this paper a possibilistic networks sampling
process. In the second part, we propose a likelihood function which explores
the link between random sets theory and possibility theory. This function is
then deployed to parametrize possibilistic networks.",2016-07-13T12:45:53Z,"Maroua Haddad, Philippe Leray, Nahla Ben Amor"
1608.00100v1,Online Learning of Event Definitions,"Systems for symbolic event recognition infer occurrences of events in time
using a set of event definitions in the form of first-order rules. The Event
Calculus is a temporal logic that has been used as a basis in event recognition
applications, providing among others, direct connections to machine learning,
via Inductive Logic Programming (ILP). We present an ILP system for online
learning of Event Calculus theories. To allow for a single-pass learning
strategy, we use the Hoeffding bound for evaluating clauses on a subset of the
input stream. We employ a decoupling scheme of the Event Calculus axioms during
the learning process, that allows to learn each clause in isolation. Moreover,
we use abductive-inductive logic programming techniques to handle unobserved
target predicates. We evaluate our approach on an activity recognition
application and compare it to a number of batch learning techniques. We obtain
results of comparable predicative accuracy with significant speed-ups in
training time. We also outperform hand-crafted rules and match the performance
of a sound incremental learner that can only operate on noise-free datasets.
This paper is under consideration for acceptance in TPLP.",2016-07-30T10:44:58Z,"Nikos Katzouris, Alexander Artikis, Georgios Paliouras"
1608.00667v1,Can Active Learning Experience Be Transferred?,"Active learning is an important machine learning problem in reducing the
human labeling effort. Current active learning strategies are designed from
human knowledge, and are applied on each dataset in an immutable manner. In
other words, experience about the usefulness of strategies cannot be updated
and transferred to improve active learning on other datasets. This paper
initiates a pioneering study on whether active learning experience can be
transferred. We first propose a novel active learning model that linearly
aggregates existing strategies. The linear weights can then be used to
represent the active learning experience. We equip the model with the popular
linear upper- confidence-bound (LinUCB) algorithm for contextual bandit to
update the weights. Finally, we extend our model to transfer the experience
across datasets with the technique of biased regularization. Empirical studies
demonstrate that the learned experience not only is competitive with existing
strategies on most single datasets, but also can be transferred across datasets
to improve the performance on future learning tasks.",2016-08-02T01:30:25Z,"Hong-Min Chu, Hsuan-Tien Lin"
1608.06154v1,"Multi-Sensor Prognostics using an Unsupervised Health Index based on
  LSTM Encoder-Decoder","Many approaches for estimation of Remaining Useful Life (RUL) of a machine,
using its operational sensor data, make assumptions about how a system degrades
or a fault evolves, e.g., exponential degradation. However, in many domains
degradation may not follow a pattern. We propose a Long Short Term Memory based
Encoder-Decoder (LSTM-ED) scheme to obtain an unsupervised health index (HI)
for a system using multi-sensor time-series data. LSTM-ED is trained to
reconstruct the time-series corresponding to healthy state of a system. The
reconstruction error is used to compute HI which is then used for RUL
estimation. We evaluate our approach on publicly available Turbofan Engine and
Milling Machine datasets. We also present results on a real-world industry
dataset from a pulverizer mill where we find significant correlation between
LSTM-ED based HI and maintenance costs.",2016-08-22T12:59:31Z,"Pankaj Malhotra, Vishnu TV, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, Gautam Shroff"
1608.07685v8,"KSR: A Semantic Representation of Knowledge Graph within a Novel
  Unsupervised Paradigm","Knowledge representation is a long-history topic in AI, which is very
important. A variety of models have been proposed for knowledge graph
embedding, which projects symbolic entities and relations into continuous
vector space. However, most related methods merely focus on the data-fitting of
knowledge graph, and ignore the interpretable semantic expression. Thus,
traditional embedding methods are not friendly for applications that require
semantic analysis, such as question answering and entity retrieval. To this
end, this paper proposes a semantic representation method for knowledge graph
\textbf{(KSR)}, which imposes a two-level hierarchical generative process that
globally extracts many aspects and then locally assigns a specific category in
each aspect for every triple. Since both aspects and categories are
semantics-relevant, the collection of categories in each aspect is treated as
the semantic representation of this triple. Extensive experiments show that our
model outperforms other state-of-the-art baselines substantially.",2016-08-27T09:53:38Z,"Han Xiao, Minlie Huang, Xiaoyan Zhu"
1609.02976v1,An Integrated Classification Model for Financial Data Mining,"Nowadays, financial data analysis is becoming increasingly important in the
business market. As companies collect more and more data from daily operations,
they expect to extract useful knowledge from existing collected data to help
make reasonable decisions for new customer requests, e.g. user credit category,
churn analysis, real estate analysis, etc. Financial institutes have applied
different data mining techniques to enhance their business performance.
However, simple ap-proach of these techniques could raise a performance issue.
Besides, there are very few general models for both understanding and
forecasting different finan-cial fields. We present in this paper a new
classification model for analyzing fi-nancial data. We also evaluate this model
with different real-world data to show its performance.",2016-09-09T23:45:19Z,"Fan Cai, Nhien-An Le-Khac, M-T. Kechadi"
1609.02993v3,"Episodic Exploration for Deep Deterministic Policies: An Application to
  StarCraft Micromanagement Tasks","We consider scenarios from the real-time strategy game StarCraft as new
benchmarks for reinforcement learning algorithms. We propose micromanagement
tasks, which present the problem of the short-term, low-level control of army
members during a battle. From a reinforcement learning point of view, these
scenarios are challenging because the state-action space is very large, and
because there is no obvious feature representation for the state-action
evaluation function. We describe our approach to tackle the micromanagement
scenarios with deep neural network controllers from raw state features given by
the game engine. In addition, we present a heuristic reinforcement learning
algorithm which combines direct exploration in the policy space and
backpropagation. This algorithm allows for the collection of traces for
learning using deterministic policies, which appears much more efficient than,
for example, {\epsilon}-greedy exploration. Experiments show that with this
algorithm, we successfully learn non-trivial strategies for scenarios with
armies of up to 15 agents, where both Q-learning and REINFORCE struggle.",2016-09-10T02:13:02Z,"Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, Soumith Chintala"
1609.04994v3,Exploration Potential,"We introduce exploration potential, a quantity that measures how much a
reinforcement learning agent has explored its environment class. In contrast to
information gain, exploration potential takes the problem's reward structure
into account. This leads to an exploration criterion that is both necessary and
sufficient for asymptotic optimality (learning to act optimally across the
entire environment class). Our experiments in multi-armed bandits use
exploration potential to illustrate how different algorithms make the tradeoff
between exploration and exploitation.",2016-09-16T10:55:27Z,Jan Leike
1609.05473v6,SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient,"As a new way of training generative models, Generative Adversarial Nets (GAN)
that uses a discriminative model to guide the training of the generative model
has enjoyed considerable success in generating real-valued data. However, it
has limitations when the goal is for generating sequences of discrete tokens. A
major reason lies in that the discrete outputs from the generative model make
it difficult to pass the gradient update from the discriminative model to the
generative model. Also, the discriminative model can only assess a complete
sequence, while for a partially generated sequence, it is non-trivial to
balance its current score and the future one once the entire sequence has been
generated. In this paper, we propose a sequence generation framework, called
SeqGAN, to solve the problems. Modeling the data generator as a stochastic
policy in reinforcement learning (RL), SeqGAN bypasses the generator
differentiation problem by directly performing gradient policy update. The RL
reward signal comes from the GAN discriminator judged on a complete sequence,
and is passed back to the intermediate state-action steps using Monte Carlo
search. Extensive experiments on synthetic data and real-world tasks
demonstrate significant improvements over strong baselines.",2016-09-18T11:42:23Z,"Lantao Yu, Weinan Zhang, Jun Wang, Yong Yu"
1609.05518v2,Towards Deep Symbolic Reinforcement Learning,"Deep reinforcement learning (DRL) brings the power of deep neural networks to
bear on the generic task of trial-and-error learning, and its effectiveness has
been convincingly demonstrated on tasks such as Atari video games and the game
of Go. However, contemporary DRL systems inherit a number of shortcomings from
the current generation of deep learning techniques. For example, they require
very large datasets to work effectively, entailing that they are slow to learn
even when such datasets are available. Moreover, they lack the ability to
reason on an abstract level, which makes it difficult to implement high-level
cognitive functions such as transfer learning, analogical reasoning, and
hypothesis-based reasoning. Finally, their operation is largely opaque to
humans, rendering them unsuitable for domains in which verifiability is
important. In this paper, we propose an end-to-end reinforcement learning
architecture comprising a neural back end and a symbolic front end with the
potential to overcome each of these shortcomings. As proof-of-concept, we
present a preliminary implementation of the architecture and apply it to
several variants of a simple video game. We show that the resulting system --
though just a prototype -- learns effectively, and, by acquiring a set of
symbolic rules that are easily comprehensible to humans, dramatically
outperforms a conventional, fully neural DRL system on a stochastic variant of
the game.",2016-09-18T17:28:22Z,"Marta Garnelo, Kai Arulkumaran, Murray Shanahan"
1609.05521v2,Playing FPS Games with Deep Reinforcement Learning,"Advances in deep reinforcement learning have allowed autonomous agents to
perform well on Atari games, often outperforming humans, using only raw pixels
to make their decisions. However, most of these games take place in 2D
environments that are fully observable to the agent. In this paper, we present
the first architecture to tackle 3D environments in first-person shooter games,
that involve partially observable states. Typically, deep reinforcement
learning methods only utilize visual input for training. We present a method to
augment these models to exploit game feature information such as the presence
of enemies or items, during the training phase. Our model is trained to
simultaneously learn these features along with minimizing a Q-learning
objective, which is shown to dramatically improve the training speed and
performance of our agent. Our architecture is also modularized to allow
different models to be independently trained for different phases of the game.
We show that the proposed architecture substantially outperforms built-in AI
agents of the game as well as humans in deathmatch scenarios.",2016-09-18T17:52:28Z,"Guillaume Lample, Devendra Singh Chaplot"
1611.00175v1,Robust Spectral Inference for Joint Stochastic Matrix Factorization,"Spectral inference provides fast algorithms and provable optimality for
latent topic analysis. But for real data these algorithms require additional
ad-hoc heuristics, and even then often produce unusable results. We explain
this poor performance by casting the problem of topic inference in the
framework of Joint Stochastic Matrix Factorization (JSMF) and showing that
previous methods violate the theoretical conditions necessary for a good
solution to exist. We then propose a novel rectification method that learns
high quality topics and their interactions even on small, noisy data. This
method achieves results comparable to probabilistic techniques in several
domains while maintaining scalability and provable optimality.",2016-11-01T10:06:57Z,"Moontae Lee, David Bindel, David Mimno"
1611.00625v2,"TorchCraft: a Library for Machine Learning Research on Real-Time
  Strategy Games","We present TorchCraft, a library that enables deep learning research on
Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it
easier to control these games from a machine learning framework, here Torch.
This white paper argues for using RTS games as a benchmark for AI research, and
describes the design and components of TorchCraft.",2016-11-01T05:01:24Z,"Gabriel Synnaeve, Nantas Nardelli, Alex Auvolat, Soumith Chintala, Timothe Lacroix, Zeming Lin, Florian Richoux, Nicolas Usunier"
1611.00862v1,Quantile Reinforcement Learning,"In reinforcement learning, the standard criterion to evaluate policies in a
state is the expectation of (discounted) sum of rewards. However, this
criterion may not always be suitable, we consider an alternative criterion
based on the notion of quantiles. In the case of episodic reinforcement
learning problems, we propose an algorithm based on stochastic approximation
with two timescales. We evaluate our proposition on a simple model of the TV
show, Who wants to be a millionaire.",2016-11-03T02:28:53Z,"Hugo Gilbert, Paul Weng"
1611.00873v1,"Extracting Actionability from Machine Learning Models by Sub-optimal
  Deterministic Planning","A main focus of machine learning research has been improving the
generalization accuracy and efficiency of prediction models. Many models such
as SVM, random forest, and deep neural nets have been proposed and achieved
great success. However, what emerges as missing in many applications is
actionability, i.e., the ability to turn prediction results into actions. For
example, in applications such as customer relationship management, clinical
prediction, and advertisement, the users need not only accurate prediction, but
also actionable instructions which can transfer an input to a desirable goal
(e.g., higher profit repays, lower morbidity rates, higher ads hit rates).
Existing effort in deriving such actionable knowledge is few and limited to
simple action models which restricted to only change one attribute for each
action. The dilemma is that in many real applications those action models are
often more complex and harder to extract an optimal solution.
  In this paper, we propose a novel approach that achieves actionability by
combining learning with planning, two core areas of AI. In particular, we
propose a framework to extract actionable knowledge from random forest, one of
the most widely used and best off-the-shelf classifiers. We formulate the
actionability problem to a sub-optimal action planning (SOAP) problem, which is
to find a plan to alter certain features of a given input so that the random
forest would yield a desirable output, while minimizing the total costs of
actions. Technically, the SOAP problem is formulated in the SAS+ planning
formalism, and solved using a Max-SAT based approach. Our experimental results
demonstrate the effectiveness and efficiency of the proposed approach on a
personal credit dataset and other benchmarks. Our work represents a new
application of automated planning on an emerging and challenging machine
learning paradigm.",2016-11-03T03:53:41Z,"Qiang Lyu, Yixin Chen, Zhaorong Li, Zhicheng Cui, Ling Chen, Xing Zhang, Haihua Shen"
1611.01423v2,Learning Continuous Semantic Representations of Symbolic Expressions,"Combining abstract, symbolic reasoning with continuous neural reasoning is a
grand challenge of representation learning. As a step in this direction, we
propose a new architecture, called neural equivalence networks, for the problem
of learning continuous semantic representations of algebraic and logical
expressions. These networks are trained to represent semantic equivalence, even
of expressions that are syntactically very different. The challenge is that
semantic representations must be computed in a syntax-directed manner, because
semantics is compositional, but at the same time, small changes in syntax can
lead to very large changes in semantics, which can be difficult for continuous
neural architectures. We perform an exhaustive evaluation on the task of
checking equivalence on a highly diverse class of symbolic algebraic and
boolean expression types, showing that our model significantly outperforms
existing architectures.",2016-11-04T15:30:43Z,"Miltiadis Allamanis, Pankajan Chanthirasegaran, Pushmeet Kohli, Charles Sutton"
1611.02205v2,Playing SNES in the Retro Learning Environment,"Mastering a video game requires skill, tactics and strategy. While these
attributes may be acquired naturally by human players, teaching them to a
computer program is a far more challenging task. In recent years, extensive
research was carried out in the field of reinforcement learning and numerous
algorithms were introduced, aiming to learn how to perform human tasks such as
playing video games. As a result, the Arcade Learning Environment (ALE)
(Bellemare et al., 2013) has become a commonly used benchmark environment
allowing algorithms to train on various Atari 2600 games. In many games the
state-of-the-art algorithms outperform humans. In this paper we introduce a new
learning environment, the Retro Learning Environment --- RLE, that can run
games on the Super Nintendo Entertainment System (SNES), Sega Genesis and
several other gaming consoles. The environment is expandable, allowing for more
video games and consoles to be easily added to the environment, while
maintaining the same interface as ALE. Moreover, RLE is compatible with Python
and Torch. SNES games pose a significant challenge to current algorithms due to
their higher level of complexity and versatility.",2016-11-07T18:33:38Z,"Nadav Bhonker, Shai Rozenberg, Itay Hubara"
1611.02796v9,"Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models
  with KL-control","This paper proposes a general method for improving the structure and quality
of sequences generated by a recurrent neural network (RNN), while maintaining
information originally learned from data, as well as sample diversity. An RNN
is first pre-trained on data using maximum likelihood estimation (MLE), and the
probability distribution over the next token in the sequence learned by this
model is treated as a prior policy. Another RNN is then trained using
reinforcement learning (RL) to generate higher-quality outputs that account for
domain-specific incentives while retaining proximity to the prior policy of the
MLE RNN. To formalize this objective, we derive novel off-policy RL methods for
RNNs from KL-control. The effectiveness of the approach is demonstrated on two
applications; 1) generating novel musical melodies, and 2) computational
molecular generation. For both problems, we show that the proposed method
improves the desired properties and structure of the generated sequences, while
maintaining information learned from data.",2016-11-09T01:46:32Z,"Natasha Jaques, Shixiang Gu, Dzmitry Bahdanau, Jos Miguel Hernndez-Lobato, Richard E. Turner, Douglas Eck"
1611.03553v1,The Sum-Product Theorem: A Foundation for Learning Tractable Models,"Inference in expressive probabilistic models is generally intractable, which
makes them difficult to learn and limits their applicability. Sum-product
networks are a class of deep models where, surprisingly, inference remains
tractable even when an arbitrary number of hidden layers are present. In this
paper, we generalize this result to a much broader set of learning problems:
all those where inference consists of summing a function over a semiring. This
includes satisfiability, constraint satisfaction, optimization, integration,
and others. In any semiring, for summation to be tractable it suffices that the
factors of every product have disjoint scopes. This unifies and extends many
previous results in the literature. Enforcing this condition at learning time
thus ensures that the learned models are tractable. We illustrate the power and
generality of this approach by applying it to a new type of structured
prediction problem: learning a nonconvex function that can be globally
optimized in polynomial time. We show empirically that this greatly outperforms
the standard approach of learning without regard to the cost of optimization.",2016-11-11T00:46:33Z,"Abram L. Friesen, Pedro Domingos"
1611.03852v3,"A Connection between Generative Adversarial Networks, Inverse
  Reinforcement Learning, and Energy-Based Models","Generative adversarial networks (GANs) are a recently proposed class of
generative models in which a generator is trained to optimize a cost function
that is being simultaneously learned by a discriminator. While the idea of
learning cost functions is relatively new to the field of generative modeling,
learning costs has long been studied in control and reinforcement learning (RL)
domains, typically for imitation learning from demonstrations. In these fields,
learning cost function underlying observed behavior is known as inverse
reinforcement learning (IRL) or inverse optimal control. While at first the
connection between cost learning in RL and cost learning in generative modeling
may appear to be a superficial one, we show in this paper that certain IRL
methods are in fact mathematically equivalent to GANs. In particular, we
demonstrate an equivalence between a sample-based algorithm for maximum entropy
IRL and a GAN in which the generator's density can be evaluated and is provided
as an additional input to the discriminator. Interestingly, maximum entropy IRL
is a special case of an energy-based model. We discuss the interpretation of
GANs as an algorithm for training energy-based models, and relate this
interpretation to other recent work that seeks to connect GANs and EBMs. By
formally highlighting the connection between GANs, IRL, and EBMs, we hope that
researchers in all three communities can better identify and apply transferable
ideas from one domain to another, particularly for developing more stable and
scalable algorithms: a major challenge in all three domains.",2016-11-11T20:53:45Z,"Chelsea Finn, Paul Christiano, Pieter Abbeel, Sergey Levine"
1611.04717v3,"#Exploration: A Study of Count-Based Exploration for Deep Reinforcement
  Learning","Count-based exploration algorithms are known to perform near-optimally when
used in conjunction with tabular reinforcement learning (RL) methods for
solving small discrete Markov decision processes (MDPs). It is generally
thought that count-based methods cannot be applied in high-dimensional state
spaces, since most states will only occur once. Recent deep RL exploration
strategies are able to deal with high-dimensional continuous state spaces
through complex heuristics, often relying on optimism in the face of
uncertainty or intrinsic motivation. In this work, we describe a surprising
finding: a simple generalization of the classic count-based approach can reach
near state-of-the-art performance on various high-dimensional and/or continuous
deep RL benchmarks. States are mapped to hash codes, which allows to count
their occurrences with a hash table. These counts are then used to compute a
reward bonus according to the classic count-based exploration theory. We find
that simple hash functions can achieve surprisingly good results on many
challenging tasks. Furthermore, we show that a domain-dependent learned hash
code may further improve these results. Detailed analysis reveals important
aspects of a good hash function: 1) having appropriate granularity and 2)
encoding information relevant to solving the MDP. This exploration strategy
achieves near state-of-the-art performance on both continuous control tasks and
Atari 2600 games, hence providing a simple yet powerful baseline for solving
MDPs that require considerable exploration.",2016-11-15T06:42:24Z,"Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, Xi Chen, Yan Duan, John Schulman, Filip De Turck, Pieter Abbeel"
1611.05675v1,"Study on Feature Subspace of Archetypal Emotions for Speech Emotion
  Recognition","Feature subspace selection is an important part in speech emotion
recognition. Most of the studies are devoted to finding a feature subspace for
representing all emotions. However, some studies have indicated that the
features associated with different emotions are not exactly the same. Hence,
traditional methods may fail to distinguish some of the emotions with just one
global feature subspace. In this work, we propose a new divide and conquer idea
to solve the problem. First, the feature subspaces are constructed for all the
combinations of every two different emotions (emotion-pair). Bi-classifiers are
then trained on these feature subspaces respectively. The final emotion
recognition result is derived by the voting and competition method.
Experimental results demonstrate that the proposed method can get better
results than the traditional multi-classification method.",2016-11-17T13:32:59Z,"Xi Ma, Zhiyong Wu, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai"
1611.05950v1,Analysis of a Design Pattern for Teaching with Features and Labels,"We study the task of teaching a machine to classify objects using features
and labels. We introduce the Error-Driven-Featuring design pattern for teaching
using features and labels in which a teacher prefers to introduce features only
if they are needed. We analyze the potential risks and benefits of this
teaching pattern through the use of teaching protocols, illustrative examples,
and by providing bounds on the effort required for an optimal machine teacher
using a linear learning algorithm, the most commonly used type of learners in
interactive machine learning systems. Our analysis provides a deeper
understanding of potential trade-offs of using different learning algorithms
and between the effort required for featuring (creating new features) and
labeling (providing labels for objects).",2016-11-18T02:04:57Z,"Christopher Meek, Patrice Simard, Xiaojin Zhu"
1611.06824v3,Options Discovery with Budgeted Reinforcement Learning,"We consider the problem of learning hierarchical policies for Reinforcement
Learning able to discover options, an option corresponding to a sub-policy over
a set of primitive actions. Different models have been proposed during the last
decade that usually rely on a predefined set of options. We specifically
address the problem of automatically discovering options in decision processes.
We describe a new learning model called Budgeted Option Neural Network (BONN)
able to discover options based on a budgeted learning objective. The BONN model
is evaluated on different classical RL problems, demonstrating both
quantitative and qualitative interesting results.",2016-11-21T15:05:55Z,"Aurlia Lon, Ludovic Denoyer"
1611.06953v1,Associative Adversarial Networks,"We propose a higher-level associative memory for learning adversarial
networks. Generative adversarial network (GAN) framework has a discriminator
and a generator network. The generator (G) maps white noise (z) to data samples
while the discriminator (D) maps data samples to a single scalar. To do so, G
learns how to map from high-level representation space to data space, and D
learns to do the opposite. We argue that higher-level representation spaces
need not necessarily follow a uniform probability distribution. In this work,
we use Restricted Boltzmann Machines (RBMs) as a higher-level associative
memory and learn the probability distribution for the high-level features
generated by D. The associative memory samples its underlying probability
distribution and G learns how to map these samples to data space. The proposed
associative adversarial networks (AANs) are generative models in the
higher-levels of the learning, and use adversarial non-stochastic models D and
G for learning the mapping between data and higher-level representation spaces.
Experiments show the potential of the proposed networks.",2016-11-18T02:11:40Z,"Tarik Arici, Asli Celikyilmaz"
1611.07507v1,Variational Intrinsic Control,"In this paper we introduce a new unsupervised reinforcement learning method
for discovering the set of intrinsic options available to an agent. This set is
learned by maximizing the number of different states an agent can reliably
reach, as measured by the mutual information between the set of options and
option termination states. To this end, we instantiate two policy gradient
based algorithms, one that creates an explicit embedding space of options and
one that represents options implicitly. The algorithms also provide an explicit
measure of empowerment in a given state that can be used by an empowerment
maximizing agent. The algorithm scales well with function approximation and we
demonstrate the applicability of the algorithm on a range of tasks.",2016-11-22T20:44:39Z,"Karol Gregor, Danilo Jimenez Rezende, Daan Wierstra"
1611.08070v1,Multiscale Inverse Reinforcement Learning using Diffusion Wavelets,"This work presents a multiscale framework to solve an inverse reinforcement
learning (IRL) problem for continuous-time/state stochastic systems. We take
advantage of a diffusion wavelet representation of the associated Markov chain
to abstract the state space. This not only allows for effectively handling the
large (and geometrically complex) decision space but also provides more
interpretable representations of the demonstrated state trajectories and also
of the resulting policy of IRL. In the proposed framework, the problem is
divided into the global and local IRL, where the global approximation of the
optimal value functions are obtained using coarse features and the local
details are quantified using fine local features. An illustrative numerical
example on robot path control in a complex environment is presented to verify
the proposed method.",2016-11-24T05:20:52Z,"Jung-Su Ha, Han-Lim Choi"
1611.08108v2,Dynamic Key-Value Memory Networks for Knowledge Tracing,"Knowledge Tracing (KT) is a task of tracing evolving knowledge state of
students with respect to one or more concepts as they engage in a sequence of
learning activities. One important purpose of KT is to personalize the practice
sequence to help students learn knowledge concepts efficiently. However,
existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing
either model knowledge state for each predefined concept separately or fail to
pinpoint exactly which concepts a student is good at or unfamiliar with. To
solve these problems, this work introduces a new model called Dynamic Key-Value
Memory Networks (DKVMN) that can exploit the relationships between underlying
concepts and directly output a student's mastery level of each concept. Unlike
standard memory-augmented neural networks that facilitate a single memory
matrix or two static memory matrices, our model has one static matrix called
key, which stores the knowledge concepts and the other dynamic matrix called
value, which stores and updates the mastery levels of corresponding concepts.
Experiments show that our model consistently outperforms the state-of-the-art
model in a range of KT datasets. Moreover, the DKVMN model can automatically
discover underlying concepts of exercises typically performed by human
annotations and depict the changing knowledge state of a student.",2016-11-24T09:12:47Z,"Jiani Zhang, Xingjian Shi, Irwin King, Dit-Yan Yeung"
1611.09321v3,Improving Policy Gradient by Exploring Under-appreciated Rewards,"This paper presents a novel form of policy gradient for model-free
reinforcement learning (RL) with improved exploration properties. Current
policy-based methods use entropy regularization to encourage undirected
exploration of the reward landscape, which is ineffective in high dimensional
spaces with sparse rewards. We propose a more directed exploration strategy
that promotes exploration of under-appreciated reward regions. An action
sequence is considered under-appreciated if its log-probability under the
current policy under-estimates its resulting reward. The proposed exploration
strategy is easy to implement, requiring small modifications to an
implementation of the REINFORCE algorithm. We evaluate the approach on a set of
algorithmic tasks that have long challenged RL methods. Our approach reduces
hyper-parameter sensitivity and demonstrates significant improvements over
baseline methods. Our algorithm successfully solves a benchmark multi-digit
addition task and generalizes to long sequences. This is, to our knowledge, the
first time that a pure RL method has solved addition using only reward
feedback.",2016-11-28T20:15:55Z,"Ofir Nachum, Mohammad Norouzi, Dale Schuurmans"
1611.09904v1,"C-RNN-GAN: Continuous recurrent neural networks with adversarial
  training","Generative adversarial networks have been proposed as a way of efficiently
training deep generative neural networks. We propose a generative adversarial
model that works on continuous sequential data, and apply it by training it on
a collection of classical music. We conclude that it generates music that
sounds better and better as the model is trained, report statistics on
generated music, and let the reader judge the quality by downloading the
generated songs.",2016-11-29T21:53:09Z,Olof Mogren
1611.10215v3,Unit Commitment using Nearest Neighbor as a Short-Term Proxy,"We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as
a proxy for quickly approximating outcomes of short-term decisions, to make
tractable hierarchical long-term assessment and planning for large power
systems. Experimental results on updated versions of IEEE-RTS79 and IEEE-RTS96
show high accuracy measured on operational cost, achieved in runtimes that are
lower in several orders of magnitude than the traditional approach.",2016-11-30T15:24:55Z,"Gal Dalal, Elad Gilboa, Shie Mannor, Louis Wehenkel"
1611.10328v1,"The observer-assisted method for adjusting hyper-parameters in deep
  learning algorithms","This paper presents a concept of a novel method for adjusting
hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer
monitors a performance of a selected Deep Learning algorithm. The observer
learns to model the DL algorithm using a series of random experiments.
Consequently, it may be used for predicting a response of the DL algorithm in
terms of a selected quality measurement to a set of hyper-parameters. This
allows to construct an ensemble composed of a series of evaluators which
constitute an observer-assisted architecture. The architecture may be used to
gradually iterate towards to the best achievable quality score in tiny steps
governed by a unit of progress. The algorithm is stopped when the maximum
number of steps is reached or no further progress is made.",2016-11-30T19:37:48Z,Maciej Wielgosz
1612.00222v1,"Interaction Networks for Learning about Objects, Relations and Physics","Reasoning about objects, relations, and physics is central to human
intelligence, and a key goal of artificial intelligence. Here we introduce the
interaction network, a model which can reason about how objects in complex
systems interact, supporting dynamical predictions, as well as inferences about
the abstract properties of the system. Our model takes graphs as input,
performs object- and relation-centric reasoning in a way that is analogous to a
simulation, and is implemented using deep neural networks. We evaluate its
ability to reason about several challenging physical domains: n-body problems,
rigid-body collision, and non-rigid dynamics. Our results show it can be
trained to accurately simulate the physical trajectories of dozens of objects
over thousands of time steps, estimate abstract quantities such as energy, and
generalize automatically to systems with different numbers and configurations
of objects and relations. Our interaction network implementation is the first
general-purpose, learnable physics engine, and a powerful general framework for
reasoning about object and relations in a wide variety of complex real-world
domains.",2016-12-01T12:34:54Z,"Peter W. Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, Koray Kavukcuoglu"
1612.00341v2,A Compositional Object-Based Approach to Learning Physical Dynamics,"We present the Neural Physics Engine (NPE), a framework for learning
simulators of intuitive physics that naturally generalize across variable
object count and different scene configurations. We propose a factorization of
a physical scene into composable object-based representations and a neural
network architecture whose compositional structure factorizes object dynamics
into pairwise interactions. Like a symbolic physics engine, the NPE is endowed
with generic notions of objects and their interactions; realized as a neural
network, it can be trained via stochastic gradient descent to adapt to specific
object properties and dynamics of different worlds. We evaluate the efficacy of
our approach on simple rigid body dynamics in two-dimensional worlds. By
comparing to less structured architectures, we show that the NPE's
compositional representation of the structure in physical interactions improves
its ability to predict movement, generalize across variable object count and
different scene configurations, and infer latent properties of objects such as
mass.",2016-12-01T16:39:04Z,"Michael B. Chang, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum"
1612.02310v1,"Extend natural neighbor: a novel classification method with
  self-adaptive neighborhood parameters in different stages","Various kinds of k-nearest neighbor (KNN) based classification methods are
the bases of many well-established and high-performance pattern-recognition
techniques, but both of them are vulnerable to their parameter choice.
Essentially, the challenge is to detect the neighborhood of various data sets,
while utterly ignorant of the data characteristic. This article introduces a
new supervised classification method: the extend natural neighbor (ENaN)
method, and shows that it provides a better classification result without
choosing the neighborhood parameter artificially. Unlike the original KNN based
method which needs a prior k, the ENaNE method predicts different k in
different stages. Therefore, the ENaNE method is able to learn more from
flexible neighbor information both in training stage and testing stage, and
provide a better classification result.",2016-12-07T16:13:52Z,"Ji Feng, Qingsheng Zhu, Jinlong Huang, Lijun Yang"
1612.03780v1,"Online Reinforcement Learning for Real-Time Exploration in Continuous
  State and Action Markov Decision Processes","This paper presents a new method to learn online policies in continuous
state, continuous action, model-free Markov decision processes, with two
properties that are crucial for practical applications. First, the policies are
implementable with a very low computational cost: once the policy is computed,
the action corresponding to a given state is obtained in logarithmic time with
respect to the number of samples used. Second, our method is versatile: it does
not rely on any a priori knowledge of the structure of optimal policies. We
build upon the Fitted Q-iteration algorithm which represents the $Q$-value as
the average of several regression trees. Our algorithm, the Fitted Policy
Forest algorithm (FPF), computes a regression forest representing the Q-value
and transforms it into a single tree representing the policy, while keeping
control on the size of the policy using resampling and leaf merging. We
introduce an adaptation of Multi-Resolution Exploration (MRE) which is
particularly suited to FPF. We assess the performance of FPF on three classical
benchmarks for reinforcement learning: the ""Inverted Pendulum"", the ""Double
Integrator"" and ""Car on the Hill"" and show that FPF equals or outperforms other
algorithms, although these algorithms rely on the use of particular
representations of the policies, especially chosen in order to fit each of the
three problems. Finally, we exhibit that the combination of FPF and MRE allows
to find nearly optimal solutions in problems where $\epsilon$-greedy approaches
would fail.",2016-12-12T16:52:01Z,"Ludovic Hofer, Hugo Gimbert"
1612.04804v1,Anomaly Detection Using the Knowledge-based Temporal Abstraction Method,"The rapid growth in stored time-oriented data necessitates the development of
new methods for handling, processing, and interpreting large amounts of
temporal data. One important example of such processing is detecting anomalies
in time-oriented data. The Knowledge-Based Temporal Abstraction method was
previously proposed for intelligent interpretation of temporal data based on
predefined domain knowledge. In this study we propose a framework that
integrates the KBTA method with a temporal pattern mining process for anomaly
detection. According to the proposed method a temporal pattern mining process
is applied on a dataset of basic temporal abstraction database in order to
extract patterns representing normal behavior. These patterns are then analyzed
in order to identify abnormal time periods characterized by a significantly
small number of normal patterns. The proposed approach was demonstrated using a
dataset collected from a real server.",2016-12-14T20:50:48Z,Asaf Shabtai
1612.05159v2,Separation of Concerns in Reinforcement Learning,"In this paper, we propose a framework for solving a single-agent task by
using multiple agents, each focusing on different aspects of the task. This
approach has two main advantages: 1) it allows for training specialized agents
on different parts of the task, and 2) it provides a new way to transfer
knowledge, by transferring trained agents. Our framework generalizes the
traditional hierarchical decomposition, in which, at any moment in time, a
single agent has control until it has solved its particular subtask. We
illustrate our framework with empirical experiments on two domains.",2016-12-15T17:41:41Z,"Harm van Seijen, Mehdi Fatemi, Joshua Romoff, Romain Laroche"
1612.05299v1,A Survey of Inductive Biases for Factorial Representation-Learning,"With the resurgence of interest in neural networks, representation learning
has re-emerged as a central focus in artificial intelligence. Representation
learning refers to the discovery of useful encodings of data that make
domain-relevant information explicit. Factorial representations identify
underlying independent causal factors of variation in data. A factorial
representation is compact and faithful, makes the causal factors explicit, and
facilitates human interpretation of data. Factorial representations support a
variety of applications, including the generation of novel examples, indexing
and search, novelty detection, and transfer learning.
  This article surveys various constraints that encourage a learning algorithm
to discover factorial representations. I dichotomize the constraints in terms
of unsupervised and supervised inductive bias. Unsupervised inductive biases
exploit assumptions about the environment, such as the statistical distribution
of factor coefficients, assumptions about the perturbations a factor should be
invariant to (e.g. a representation of an object can be invariant to rotation,
translation or scaling), and assumptions about how factors are combined to
synthesize an observation. Supervised inductive biases are constraints on the
representations based on additional information connected to observations.
Supervisory labels come in variety of types, which vary in how strongly they
constrain the representation, how many factors are labeled, how many
observations are labeled, and whether or not we know the associations between
the constraints and the factors they are related to.
  This survey brings together a wide variety of models that all touch on the
problem of learning factorial representations and lays out a framework for
comparing these models based on the strengths of the underlying supervised and
unsupervised inductive biases.",2016-12-15T22:55:41Z,Karl Ridgeway
1612.05502v2,Defensive Player Classification in the National Basketball Association,"The National Basketball Association(NBA) has expanded their data gathering
and have heavily invested in new technologies to gather advanced performance
metrics on players. This expanded data set allows analysts to use unique
performance metrics in models to estimate and classify player performance.
Instead of grouping players together based on physical attributes and positions
played, analysts can group together players that play similar to each other
based on these tracked metrics. Existing methods for player classification have
typically used offensive metrics for clustering [1]. There have been attempts
to classify players using past defensive metrics, but the lack of quality
metrics has not produced promising results. The classifications presented in
the paper use newly introduced defensive metrics to find different defensive
positions for each player. Without knowing the number of categories that
players can be cast into, Gaussian Mixture Models (GMM) can be applied to find
the optimal number of clusters. In the model presented, five different
defensive player types can be identified.",2016-12-13T20:22:00Z,Neil Seward
1612.06018v2,Self-Correcting Models for Model-Based Reinforcement Learning,"When an agent cannot represent a perfectly accurate model of its
environment's dynamics, model-based reinforcement learning (MBRL) can fail
catastrophically. Planning involves composing the predictions of the model;
when flawed predictions are composed, even minor errors can compound and render
the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the
model to ""correct"" itself when it produces errors, substantially improving MBRL
with flawed models. This paper theoretically analyzes this approach,
illuminates settings in which it is likely to be effective or ineffective, and
presents a novel error bound, showing that a model's ability to self-correct is
more tightly related to MBRL performance than one-step prediction error. These
results inspire an MBRL algorithm for deterministic MDPs with performance
guarantees that are robust to model class limitations.",2016-12-19T01:09:23Z,Erik Talvitie
1612.06505v4,Parallelized Tensor Train Learning of Polynomial Classifiers,"In pattern classification, polynomial classifiers are well-studied methods as
they are capable of generating complex decision surfaces. Unfortunately, the
use of multivariate polynomials is limited to kernels as in support vector
machines, because polynomials quickly become impractical for high-dimensional
problems. In this paper, we effectively overcome the curse of dimensionality by
employing the tensor train format to represent a polynomial classifier. Based
on the structure of tensor trains, two learning algorithms are proposed which
involve solving different optimization problems of low computational
complexity. Furthermore, we show how both regularization to prevent overfitting
and parallelization, which enables the use of large training sets, are
incorporated into these methods. Both the efficiency and efficacy of our
tensor-based polynomial classifier are then demonstrated on the two popular
datasets USPS and MNIST.",2016-12-20T04:54:49Z,"Zhongming Chen, Kim Batselier, Johan A. K. Suykens, Ngai Wong"
1612.07896v1,A Base Camp for Scaling AI,"Modern statistical machine learning (SML) methods share a major limitation
with the early approaches to AI: there is no scalable way to adapt them to new
domains. Human learning solves this in part by leveraging a rich, shared,
updateable world model. Such scalability requires modularity: updating part of
the world model should not impact unrelated parts. We have argued that such
modularity will require both ""correctability"" (so that errors can be corrected
without introducing new errors) and ""interpretability"" (so that we can
understand what components need correcting).
  To achieve this, one could attempt to adapt state of the art SML systems to
be interpretable and correctable; or one could see how far the simplest
possible interpretable, correctable learning methods can take us, and try to
control the limitations of SML methods by applying them only where needed. Here
we focus on the latter approach and we investigate two main ideas: ""Teacher
Assisted Learning"", which leverages crowd sourcing to learn language; and
""Factored Dialog Learning"", which factors the process of application
development into roles where the language competencies needed are isolated,
enabling non-experts to quickly create new applications.
  We test these ideas in an ""Automated Personal Assistant"" (APA) setting, with
two scenarios: that of detecting user intent from a user-APA dialog; and that
of creating a class of event reminder applications, where a non-expert
""teacher"" can then create specific apps. For the intent detection task, we use
a dataset of a thousand labeled utterances from user dialogs with Cortana, and
we show that our approach matches state of the art SML methods, but in addition
provides full transparency: the whole (editable) model can be summarized on one
human-readable page. For the reminder app task, we ran small user studies to
verify the efficacy of the approach.",2016-12-23T08:03:20Z,"C. J. C. Burges, T. Hart, Z. Yang, S. Cucerzan, R. W. White, A. Pastusiak, J. Lewis"
1702.03584v3,Similarity Preserving Representation Learning for Time Series Clustering,"A considerable amount of clustering algorithms take instance-feature matrices
as their inputs. As such, they cannot directly analyze time series data due to
its temporal nature, usually unequal lengths, and complex properties. This is a
great pity since many of these algorithms are effective, robust, efficient, and
easy to use. In this paper, we bridge this gap by proposing an efficient
representation learning framework that is able to convert a set of time series
with various lengths to an instance-feature matrix. In particular, we guarantee
that the pairwise similarities between time series are well preserved after the
transformation, thus the learned feature representation is particularly
suitable for the time series clustering task. Given a set of $n$ time series,
we first construct an $n\times n$ partially-observed similarity matrix by
randomly sampling $\mathcal{O}(n \log n)$ pairs of time series and computing
their pairwise similarities. We then propose an efficient algorithm that solves
a non-convex and NP-hard problem to learn new features based on the
partially-observed similarity matrix. By conducting extensive empirical
studies, we show that the proposed framework is more effective, efficient, and
flexible, compared to other state-of-the-art time series clustering methods.",2017-02-12T22:38:42Z,"Qi Lei, Jinfeng Yi, Roman Vaculin, Lingfei Wu, Inderjit S. Dhillon"
1702.03767v2,Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?,"Non-technical losses (NTL) occur during the distribution of electricity in
power grids and include, but are not limited to, electricity theft and faulty
meters. In emerging countries, they may range up to 40% of the total
electricity distributed. In order to detect NTLs, machine learning methods are
used that learn irregular consumption patterns from customer data and
inspection results. The Big Data paradigm followed in modern machine learning
reflects the desire of deriving better conclusions from simply analyzing more
data, without the necessity of looking at theory and models. However, the
sample of inspected customers may be biased, i.e. it does not represent the
population of all customers. As a consequence, machine learning models trained
on these inspection results are biased as well and therefore lead to unreliable
predictions of whether customers cause NTL or not. In machine learning, this
issue is called covariate shift and has not been addressed in the literature on
NTL detection yet. In this work, we present a novel framework for quantifying
and visualizing covariate shift. We apply it to a commercial data set from
Brazil that consists of 3.6M customers and 820K inspection results. We show
that some features have a stronger covariate shift than others, making
predictions less reliable. In particular, previous inspections were focused on
certain neighborhoods or customer classes and that they were not sufficiently
spread among the population of customers. This framework is about to be
deployed in a commercial product for NTL detection.",2017-02-13T13:33:47Z,"Patrick Glauner, Angelo Migliosi, Jorge Meira, Petko Valtchev, Radu State, Franck Bettinger"
1702.04423v3,Efficient Multitask Feature and Relationship Learning,"We consider a multitask learning problem, in which several predictors are
learned jointly. Prior research has shown that learning the relations between
tasks, and between the input features, together with the predictor, can lead to
better generalization and interpretability, which proved to be useful for
applications in many domains. In this paper, we consider a formulation of
multitask learning that learns the relationships both between tasks and between
features, represented through a task covariance and a feature covariance
matrix, respectively. First, we demonstrate that existing methods proposed for
this problem present an issue that may lead to ill-posed optimization. We then
propose an alternative formulation, as well as an efficient algorithm to
optimize it. Using ideas from optimization and graph theory, we propose an
efficient coordinate-wise minimization algorithm that has a closed form
solution for each block subproblem. Our experiments show that the proposed
optimization method is orders of magnitude faster than its competitors. We also
provide a nonlinear extension that is able to achieve better generalization
than existing methods.",2017-02-14T23:43:32Z,"Han Zhao, Otilia Stretcu, Alex Smola, Geoff Gordon"
1702.04577v2,"On the Discrepancy Between Kleinberg's Clustering Axioms and $k$-Means
  Clustering Algorithm Behavior","This paper investigates the validity of Kleinberg's axioms for clustering
functions with respect to the quite popular clustering algorithm called
$k$-means. While Kleinberg's axioms have been discussed heavily in the past, we
concentrate here on the case predominantly relevant for $k$-means algorithm,
that is behavior embedded in Euclidean space. We point at some contradictions
and counter intuitiveness aspects of this axiomatic set within $\mathbb{R}^m$
that were evidently not discussed so far. Our results suggest that apparently
without defining clearly what kind of clusters we expect we will not be able to
construct a valid axiomatic system. In particular we look at the shape and the
gaps between the clusters. Finally we demonstrate that there exist several ways
to reconcile the formulation of the axioms with their intended meaning and that
under this reformulation the axioms stop to be contradictory and the real-world
$k$-means algorithm conforms to this axiomatic system.",2017-02-15T12:25:28Z,"Robert Kopotek, Mieczysaw Kopotek"
1702.04638v2,"A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale
  Learning","In modern machine learning, pattern recognition replaces realtime semantic
reasoning. The mapping from input to output is learned with fixed semantics by
training outcomes deliberately. This is an expensive and static approach which
depends heavily on the availability of a very particular kind of prior raining
data to make inferences in a single step. Conventional semantic network
approaches, on the other hand, base multi-step reasoning on modal logics and
handcrafted ontologies, which are ad hoc, expensive to construct, and fragile
to inconsistency. Both approaches may be enhanced by a hybrid approach, which
completely separates reasoning from pattern recognition. In this report, a
quasi-linguistic approach to knowledge representation is discussed, motivated
by spacetime structure. Tokenized patterns from diverse sources are integrated
to build a lightly constrained and approximately scale-free network. This is
then be parsed with very simple recursive algorithms to generate
`brainstorming' sets of reasoned knowledge.",2017-02-12T14:58:45Z,Mark Burgess
1702.04767v2,Linear Time Computation of Moments in Sum-Product Networks,"Bayesian online algorithms for Sum-Product Networks (SPNs) need to update
their posterior distribution after seeing one single additional instance. To do
so, they must compute moments of the model parameters under this distribution.
The best existing method for computing such moments scales quadratically in the
size of the SPN, although it scales linearly for trees. This unfortunate
scaling makes Bayesian online algorithms prohibitively expensive, except for
small or tree-structured SPNs. We propose an optimal linear-time algorithm that
works even when the SPN is a general directed acyclic graph (DAG), which
significantly broadens the applicability of Bayesian online algorithms for
SPNs. There are three key ingredients in the design and analysis of our
algorithm: 1). For each edge in the graph, we construct a linear time reduction
from the moment computation problem to a joint inference problem in SPNs. 2).
Using the property that each SPN computes a multilinear polynomial, we give an
efficient procedure for polynomial evaluation by differentiation without
expanding the network that may contain exponentially many monomials. 3). We
propose a dynamic programming method to further reduce the computation of the
moments of all the edges in the graph from quadratic to linear. We demonstrate
the usefulness of our linear time algorithm by applying it to develop a linear
time assume density filter (ADF) for SPNs.",2017-02-15T20:40:12Z,"Han Zhao, Geoff Gordon"
1702.06230v3,"Beating the World's Best at Super Smash Bros. with Deep Reinforcement
  Learning","There has been a recent explosion in the capabilities of game-playing
artificial intelligence. Many classes of RL tasks, from Atari games to motor
control to board games, are now solvable by fairly generic algorithms, based on
deep learning, that learn to play from experience with minimal knowledge of the
specific domain of interest. In this work, we will investigate the performance
of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting
game. The SSBM environment has complex dynamics and partial observability,
making it challenging for human and machine alike. The multi-player aspect
poses an additional challenge, as the vast majority of recent advances in RL
have focused on single-agent environments. Nonetheless, we will show that it is
possible to train agents that are competitive against and even surpass human
professionals, a new result for the multi-player video game setting.",2017-02-21T01:06:11Z,"Vlad Firoiu, William F. Whitney, Joshua B. Tenenbaum"
1702.06238v2,Sample Efficient Policy Search for Optimal Stopping Domains,"Optimal stopping problems consider the question of deciding when to stop an
observation-generating process in order to maximize a return. We examine the
problem of simultaneously learning and planning in such domains, when data is
collected directly from the environment. We propose GFSE, a simple and flexible
model-free policy search method that reuses data for sample efficiency by
leveraging problem structure. We bound the sample complexity of our approach to
guarantee uniform convergence of policy value estimates, tightening existing
PAC bounds to achieve logarithmic dependence on horizon length for our setting.
We also examine the benefit of our method against prevalent model-based and
model-free approaches on 3 domains taken from diverse fields.",2017-02-21T02:14:47Z,"Karan Goel, Christoph Dann, Emma Brunskill"
1702.06776v1,Causal Inference by Stochastic Complexity,"The algorithmic Markov condition states that the most likely causal direction
between two random variables X and Y can be identified as that direction with
the lowest Kolmogorov complexity. Due to the halting problem, however, this
notion is not computable.
  We hence propose to do causal inference by stochastic complexity. That is, we
propose to approximate Kolmogorov complexity via the Minimum Description Length
(MDL) principle, using a score that is mini-max optimal with regard to the
model class under consideration. This means that even in an adversarial
setting, such as when the true distribution is not in this class, we still
obtain the optimal encoding for the data relative to the class.
  We instantiate this framework, which we call CISC, for pairs of univariate
discrete variables, using the class of multinomial distributions. Experiments
show that CISC is highly accurate on synthetic, benchmark, as well as
real-world data, outperforming the state of the art by a margin, and scales
extremely well with regard to sample and domain sizes.",2017-02-22T12:36:21Z,"Kailash Budhathoki, Jilles Vreeken"
1702.08039v2,Criticality & Deep Learning I: Generally Weighted Nets,"Motivated by the idea that criticality and universality of phase transitions
might play a crucial role in achieving and sustaining learning and intelligent
behaviour in biological and artificial networks, we analyse a theoretical and a
pragmatic experimental set up for critical phenomena in deep learning. On the
theoretical side, we use results from statistical physics to carry out critical
point calculations in feed-forward/fully connected networks, while on the
experimental side we set out to find traces of criticality in deep neural
networks. This is our first step in a series of upcoming investigations to map
out the relationship between criticality and learning in deep networks.",2017-02-26T14:43:38Z,"Dan Oprisa, Peter Toth"
1702.08165v2,Reinforcement Learning with Deep Energy-Based Policies,"We propose a method for learning expressive energy-based policies for
continuous states and actions, which has been feasible only in tabular domains
before. We apply our method to learning maximum entropy policies, resulting
into a new algorithm, called soft Q-learning, that expresses the optimal policy
via a Boltzmann distribution. We use the recently proposed amortized Stein
variational gradient descent to learn a stochastic sampling network that
approximates samples from this distribution. The benefits of the proposed
algorithm include improved exploration and compositionality that allows
transferring skills between tasks, which we confirm in simulated experiments
with swimming and walking robots. We also draw a connection to actor-critic
methods, which can be viewed performing approximate inference on the
corresponding energy-based model.",2017-02-27T07:16:41Z,"Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, Sergey Levine"
1703.00512v1,"PMLB: A Large Benchmark Suite for Machine Learning Evaluation and
  Comparison","The selection, development, or comparison of machine learning methods in data
mining can be a difficult task based on the target problem and goals of a
particular study. Numerous publicly available real-world and simulated
benchmark datasets have emerged from different sources, but their organization
and adoption as standards have been inconsistent. As such, selecting and
curating specific benchmarks remains an unnecessary burden on machine learning
practitioners and data scientists. The present study introduces an accessible,
curated, and developing public benchmark resource to facilitate identification
of the strengths and weaknesses of different machine learning methodologies. We
compare meta-features among the current set of benchmark datasets in this
resource to characterize the diversity of available data. Finally, we apply a
number of established machine learning methods to the entire benchmark suite
and analyze how datasets and algorithms cluster in terms of performance. This
work is an important first step towards understanding the limitations of
popular benchmarking suites and developing a resource that connects existing
benchmarking standards to more diverse and efficient standards in the future.",2017-03-01T21:20:11Z,"Randal S. Olson, William La Cava, Patryk Orzechowski, Ryan J. Urbanowicz, Jason H. Moore"
1703.00956v2,A Laplacian Framework for Option Discovery in Reinforcement Learning,"Representation learning and option discovery are two of the biggest
challenges in reinforcement learning (RL). Proto-value functions (PVFs) are a
well-known approach for representation learning in MDPs. In this paper we
address the option discovery problem by showing how PVFs implicitly define
options. We do it by introducing eigenpurposes, intrinsic reward functions
derived from the learned representations. The options discovered from
eigenpurposes traverse the principal directions of the state space. They are
useful for multiple tasks because they are discovered without taking the
environment's rewards into consideration. Moreover, different options act at
different time scales, making them helpful for exploration. We demonstrate
features of eigenpurposes in traditional tabular domains as well as in Atari
2600 games.",2017-03-02T21:31:29Z,"Marlos C. Machado, Marc G. Bellemare, Michael Bowling"
1703.01203v3,Stochastic Separation Theorems,"The problem of non-iterative one-shot and non-destructive correction of
unavoidable mistakes arises in all Artificial Intelligence applications in the
real world. Its solution requires robust separation of samples with errors from
samples where the system works properly. We demonstrate that in (moderately)
high dimension this separation could be achieved with probability close to one
by linear discriminants. Surprisingly, separation of a new image from a very
large set of known images is almost always possible even in moderately high
dimensions by linear functionals, and coefficients of these functionals can be
found explicitly. Based on fundamental properties of measure concentration, we
show that for $M<a\exp(b{n})$ random $M$-element sets in $\mathbb{R}^n$ are
linearly separable with probability $p$, $p>1-\vartheta$, where $1>\vartheta>0$
is a given small constant. Exact values of $a,b>0$ depend on the probability
distribution that determines how the random $M$-element sets are drawn, and on
the constant $\vartheta$. These {\em stochastic separation theorems} provide a
new instrument for the development, analysis, and assessment of machine
learning methods and algorithms in high dimension. Theoretical statements are
illustrated with numerical examples.",2017-03-03T15:27:38Z,"A. N. Gorban, I. Y. Tyukin"
1703.01327v2,Multi-step Reinforcement Learning: A Unifying Algorithm,"Unifying seemingly disparate algorithmic ideas to produce better performing
algorithms has been a longstanding goal in reinforcement learning. As a primary
example, TD($\lambda$) elegantly unifies one-step TD prediction with Monte
Carlo methods through the use of eligibility traces and the trace-decay
parameter $\lambda$. Currently, there are a multitude of algorithms that can be
used to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa.
These methods are often studied in the one-step case, but they can be extended
across multiple time steps to achieve better performance. Each of these
algorithms is seemingly distinct, and no one dominates the others for all
problems. In this paper, we study a new multi-step action-value algorithm
called $Q(\sigma)$ which unifies and generalizes these existing algorithms,
while subsuming them as special cases. A new parameter, $\sigma$, is introduced
to allow the degree of sampling performed by the algorithm at each step during
its backup to be continuously varied, with Sarsa existing at one extreme (full
sampling), and Expected Sarsa existing at the other (pure expectation).
$Q(\sigma)$ is generally applicable to both on- and off-policy learning, but in
this work we focus on experiments in the on-policy case. Our results show that
an intermediate value of $\sigma$, which results in a mixture of the existing
algorithms, performs better than either extreme. The mixture can also be varied
dynamically which can result in even greater performance.",2017-03-03T20:19:08Z,"Kristopher De Asis, J. Fernando Hernandez-Garcia, G. Zacharias Holland, Richard S. Sutton"
1703.02883v1,"Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data
  Clustering","Cluster analysis plays an important role in decision making process for many
knowledge-based systems. There exist a wide variety of different approaches for
clustering applications including the heuristic techniques, probabilistic
models, and traditional hierarchical algorithms. In this paper, a novel
heuristic approach based on big bang-big crunch algorithm is proposed for
clustering problems. The proposed method not only takes advantage of heuristic
nature to alleviate typical clustering algorithms such as k-means, but it also
benefits from the memory based scheme as compared to its similar heuristic
techniques. Furthermore, the performance of the proposed algorithm is
investigated based on several benchmark test functions as well as on the
well-known datasets. The experimental results show the significant superiority
of the proposed method over the similar algorithms.",2017-03-08T15:50:35Z,"Kayvan Bijari, Hadi Zare, Hadi Veisi, Hossein Bobarshad"
1703.03041v1,"Combining Bayesian Approaches and Evolutionary Techniques for the
  Inference of Breast Cancer Networks","Gene and protein networks are very important to model complex large-scale
systems in molecular biology. Inferring or reverseengineering such networks can
be defined as the process of identifying gene/protein interactions from
experimental data through computational analysis. However, this task is
typically complicated by the enormously large scale of the unknowns in a rather
small sample size. Furthermore, when the goal is to study causal relationships
within the network, tools capable of overcoming the limitations of correlation
networks are required. In this work, we make use of Bayesian Graphical Models
to attach this problem and, specifically, we perform a comparative study of
different state-of-the-art heuristics, analyzing their performance in inferring
the structure of the Bayesian Network from breast cancer data.",2017-03-08T21:36:01Z,"Stefano Beretta, Mauro Castelli, Ivo Goncalves, Ivan Merelli, Daniele Ramazzotti"
1703.03074v4,"Efficient computational strategies to learn the structure of
  probabilistic graphical models of cumulative phenomena","Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is
further complicated by many theoretical issues, such as the I-equivalence among
different structures. In this work, we focus on a specific subclass of BNs,
named Suppes-Bayes Causal Networks (SBCNs), which include specific structural
constraints based on Suppes' probabilistic causation to efficiently model
cumulative phenomena. Here we compare the performance, via extensive
simulations, of various state-of-the-art search strategies, such as local
search techniques and Genetic Algorithms, as well as of distinct regularization
methods. The assessment is performed on a large number of simulated datasets
from topologies with distinct levels of complexity, various sample size and
different rates of errors in the data. Among the main results, we show that the
introduction of Suppes' constraints dramatically improve the inference
accuracy, by reducing the solution space and providing a temporal ordering on
the variables. We also report on trade-offs among different search techniques
that can be efficiently employed in distinct experimental settings. This
manuscript is an extended version of the paper ""Structural Learning of
Probabilistic Graphical Models of Cumulative Phenomena"" presented at the 2018
International Conference on Computational Science.",2017-03-08T23:50:19Z,"Daniele Ramazzotti, Marco S. Nobile, Marco Antoniotti, Alex Graudenzi"
1703.03633v3,Learning Gradient Descent: Better Generalization and Longer Horizons,"Training deep neural networks is a highly nontrivial task, involving
carefully selecting appropriate training algorithms, scheduling step sizes and
tuning other hyperparameters. Trying different combinations can be quite
labor-intensive and time consuming. Recently, researchers have tried to use
deep learning algorithms to exploit the landscape of the loss function of the
training problem of interest, and learn how to optimize over it in an automatic
way. In this paper, we propose a new learning-to-learn model and some useful
and practical tricks. Our optimizer outperforms generic, hand-crafted
optimization algorithms and state-of-the-art learning-to-learn optimizers by
DeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a
number of tasks, including deep MLPs, CNNs, and simple LSTMs.",2017-03-10T11:30:03Z,"Kaifeng Lv, Shunhua Jiang, Jian Li"
1703.04529v4,Task-based End-to-end Model Learning in Stochastic Optimization,"With the increasing popularity of machine learning techniques, it has become
common to see prediction algorithms operating within some larger process.
However, the criteria by which we train these algorithms often differ from the
ultimate criteria on which we evaluate them. This paper proposes an end-to-end
approach for learning probabilistic machine learning models in a manner that
directly captures the ultimate task-based objective for which they will be
used, within the context of stochastic programming. We present three
experimental evaluations of the proposed approach: a classical inventory stock
problem, a real-world electrical grid scheduling task, and a real-world energy
storage arbitrage task. We show that the proposed approach can outperform both
traditional modeling and purely black-box policy optimization approaches in
these applications.",2017-03-13T17:58:36Z,"Priya L. Donti, Brandon Amos, J. Zico Kolter"
1703.05820v1,Particle Value Functions,"The policy gradients of the expected return objective can react slowly to
rare rewards. Yet, in some cases agents may wish to emphasize the low or high
returns regardless of their probability. Borrowing from the economics and
control literature, we review the risk-sensitive value function that arises
from an exponential utility and illustrate its effects on an example. This
risk-sensitive value function is not always applicable to reinforcement
learning problems, so we introduce the particle value function defined by a
particle filter over the distributions of an agent's experience, which bounds
the risk-sensitive one. We illustrate the benefit of the policy gradients of
this objective in Cliffworld.",2017-03-16T21:08:31Z,"Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess, Arnaud Doucet, Andriy Mnih, Yee Whye Teh"
1703.08475v3,Overcoming Catastrophic Forgetting by Incremental Moment Matching,"Catastrophic forgetting is a problem of neural networks that loses the
information of the first task after training the second task. Here, we propose
a method, i.e. incremental moment matching (IMM), to resolve this problem. IMM
incrementally matches the moment of the posterior distribution of the neural
network which is trained on the first and the second task, respectively. To
make the search space of posterior parameter smooth, the IMM procedure is
complemented by various transfer learning techniques including weight transfer,
L2-norm of the old and the new parameter, and a variant of dropout with the old
parameter. We analyze our approach on a variety of datasets including the
MNIST, CIFAR-10, Caltech-UCSD-Birds, and Lifelog datasets. The experimental
results show that IMM achieves state-of-the-art performance by balancing the
information between an old and a new network.",2017-03-24T15:43:39Z,"Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, Byoung-Tak Zhang"
1703.10069v4,"Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level
  Coordination in Learning to Play StarCraft Combat Games","Many artificial intelligence (AI) applications often require multiple
intelligent agents to work in a collaborative effort. Efficient learning for
intra-agent communication and coordination is an indispensable step towards
general AI. In this paper, we take StarCraft combat game as a case study, where
the task is to coordinate multiple agents as a team to defeat their enemies. To
maintain a scalable yet effective communication protocol, we introduce a
Multiagent Bidirectionally-Coordinated Network (BiCNet ['bIknet]) with a
vectorised extension of actor-critic formulation. We show that BiCNet can
handle different types of combats with arbitrary numbers of AI agents for both
sides. Our analysis demonstrates that without any supervisions such as human
demonstrations or labelled data, BiCNet could learn various types of advanced
coordination strategies that have been commonly used by experienced game
players. In our experiments, we evaluate our approach against multiple
baselines under different scenarios; it shows state-of-the-art performance, and
possesses potential values for large-scale real-world applications.",2017-03-29T14:37:25Z,"Peng Peng, Ying Wen, Yaodong Yang, Quan Yuan, Zhenkun Tang, Haitao Long, Jun Wang"
1703.10284v2,"Enter the Matrix: Safely Interruptible Autonomous Systems via
  Virtualization","Autonomous systems that operate around humans will likely always rely on kill
switches that stop their execution and allow them to be remote-controlled for
the safety of humans or to prevent damage to the system. It is theoretically
possible for an autonomous system with sufficient sensor and effector
capability that learn online using reinforcement learning to discover that the
kill switch deprives it of long-term reward and thus learn to disable the
switch or otherwise prevent a human operator from using the switch. This is
referred to as the big red button problem. We present a technique that prevents
a reinforcement learning agent from learning to disable the kill switch. We
introduce an interruption process in which the agent's sensors and effectors
are redirected to a virtual simulation where it continues to believe it is
receiving reward. We illustrate our technique in a simple grid world
environment.",2017-03-30T01:35:01Z,"Mark O. Riedl, Brent Harrison"
1704.01415v1,Multi-Label Learning with Global and Local Label Correlation,"It is well-known that exploiting label correlations is important to
multi-label learning. Existing approaches either assume that the label
correlations are global and shared by all instances; or that the label
correlations are local and shared only by a data subset. In fact, in the
real-world applications, both cases may occur that some label correlations are
globally applicable and some are shared only in a local group of instances.
Moreover, it is also a usual case that only partial labels are observed, which
makes the exploitation of the label correlations much more difficult. That is,
it is hard to estimate the label correlations when many labels are absent. In
this paper, we propose a new multi-label approach GLOCAL dealing with both the
full-label and the missing-label cases, exploiting global and local label
correlations simultaneously, through learning a latent label representation and
optimizing label manifolds. The extensive experimental studies validate the
effectiveness of our approach on both full-label and missing-label data.",2017-04-04T12:50:25Z,"Yue Zhu, James T. Kwok, Zhi-Hua Zhou"
1704.03732v4,Deep Q-learning from Demonstrations,"Deep reinforcement learning (RL) has achieved several high profile successes
in difficult decision-making problems. However, these algorithms typically
require a huge amount of data before they reach reasonable performance. In
fact, their performance during learning can be extremely poor. This may be
acceptable for a simulator, but it severely limits the applicability of deep RL
to many real-world tasks, where the agent must learn in the real environment.
In this paper we study a setting where the agent may access data from previous
control of the system. We present an algorithm, Deep Q-learning from
Demonstrations (DQfD), that leverages small sets of demonstration data to
massively accelerate the learning process even from relatively small amounts of
demonstration data and is able to automatically assess the necessary ratio of
demonstration data while learning thanks to a prioritized replay mechanism.
DQfD works by combining temporal difference updates with supervised
classification of the demonstrator's actions. We show that DQfD has better
initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN)
as it starts with better scores on the first million steps on 41 of 42 games
and on average it takes PDD DQN 83 million steps to catch up to DQfD's
performance. DQfD learns to out-perform the best demonstration given in 14 of
42 games. In addition, DQfD leverages human demonstrations to achieve
state-of-the-art results for 11 games. Finally, we show that DQfD performs
better than three related algorithms for incorporating demonstration data into
DQN.",2017-04-12T12:44:37Z,"Todd Hester, Matej Vecerik, Olivier Pietquin, Marc Lanctot, Tom Schaul, Bilal Piot, Dan Horgan, John Quan, Andrew Sendonaris, Gabriel Dulac-Arnold, Ian Osband, John Agapiou, Joel Z. Leibo, Audrunas Gruslys"
1704.04327v1,Deep API Programmer: Learning to Program with APIs,"We present DAPIP, a Programming-By-Example system that learns to program with
APIs to perform data transformation tasks. We design a domain-specific language
(DSL) that allows for arbitrary concatenations of API outputs and constant
strings. The DSL consists of three family of APIs: regular expression-based
APIs, lookup APIs, and transformation APIs. We then present a novel neural
synthesis algorithm to search for programs in the DSL that are consistent with
a given set of examples. The search algorithm uses recently introduced neural
architectures to encode input-output examples and to model the program search
in the DSL. We show that synthesis algorithm outperforms baseline methods for
synthesizing programs on both synthetic and real-world benchmarks.",2017-04-14T02:04:06Z,"Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, Pushmeet Kohli"
1704.04866v3,"Effective Warm Start for the Online Actor-Critic Reinforcement Learning
  based mHealth Intervention","Online reinforcement learning (RL) is increasingly popular for the
personalized mobile health (mHealth) intervention. It is able to personalize
the type and dose of interventions according to user's ongoing statuses and
changing needs. However, at the beginning of online learning, there are usually
too few samples to support the RL updating, which leads to poor performances. A
delay in good performance of the online learning algorithms can be especially
detrimental in the mHealth, where users tend to quickly disengage with the
mHealth app. To address this problem, we propose a new online RL methodology
that focuses on an effective warm start. The main idea is to make full use of
the data accumulated and the decision rule achieved in a former study. As a
result, we can greatly enrich the data size at the beginning of online learning
in our method. Such case accelerates the online learning process for new users
to achieve good performances not only at the beginning of online learning but
also through the whole online learning process. Besides, we use the decision
rules achieved in a previous study to initialize the parameter in our online RL
model for new users. It provides a good initialization for the proposed online
RL algorithm. Experiment results show that promising improvements have been
achieved by our method compared with the state-of-the-art method.",2017-04-17T04:43:05Z,"Feiyun Zhu, Peng Liao"
1704.05495v1,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,"Eligibility traces in reinforcement learning are used as a bias-variance
trade-off and can often speed up training time by propagating knowledge back
over time-steps in a single update. We investigate the use of eligibility
traces in combination with recurrent networks in the Atari domain. We
illustrate the benefits of both recurrent nets and eligibility traces in some
Atari games, and highlight also the importance of the optimization used in the
training.",2017-04-18T18:46:12Z,"Jean Harb, Doina Precup"
1704.06498v3,Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces,"Graph models are relevant in many fields, such as distributed computing,
intelligent tutoring systems or social network analysis. In many cases, such
models need to take changes in the graph structure into account, i.e. a varying
number of nodes or edges. Predicting such changes within graphs can be expected
to yield important insight with respect to the underlying dynamics, e.g. with
respect to user behaviour. However, predictive techniques in the past have
almost exclusively focused on single edges or nodes. In this contribution, we
attempt to predict the future state of a graph as a whole. We propose to phrase
time series prediction as a regression problem and apply dissimilarity- or
kernel-based regression techniques, such as 1-nearest neighbor, kernel
regression and Gaussian process regression, which can be applied to graphs via
graph kernels. The output of the regression is a point embedded in a
pseudo-Euclidean space, which can be analyzed using subsequent dissimilarity-
or kernel-based processing methods. We discuss strategies to speed up Gaussian
Processes regression from cubic to linear time and evaluate our approach on two
well-established theoretical models of graph evolution as well as two real data
sets from the domain of intelligent tutoring systems. We find that simple
regression methods, such as kernel regression, are sufficient to capture the
dynamics in the theoretical models, but that Gaussian process regression
significantly improves the prediction error for real-world data.",2017-04-21T12:08:30Z,"Benjamin Paaen, Christina Gpfert, Barbara Hammer"
1704.07498v3,"Leveraging Patient Similarity and Time Series Data in Healthcare
  Predictive Models","Patient time series classification faces challenges in high degrees of
dimensionality and missingness. In light of patient similarity theory, this
study explores effective temporal feature engineering and reduction, missing
value imputation, and change point detection methods that can afford
similarity-based classification models with desirable accuracy enhancement. We
select a piecewise aggregation approximation method to extract fine-grain
temporal features and propose a minimalist method to impute missing values in
temporal features. For dimensionality reduction, we adopt a gradient descent
search method for feature weight assignment. We propose new patient status and
directional change definitions based on medical knowledge or clinical
guidelines about the value ranges for different patient status levels, and
develop a method to detect change points indicating positive or negative
patient status changes. We evaluate the effectiveness of the proposed methods
in the context of early Intensive Care Unit mortality prediction. The
evaluation results show that the k-Nearest Neighbor algorithm that incorporates
methods we select and propose significantly outperform the relevant benchmarks
for early ICU mortality prediction. This study makes contributions to time
series classification and early ICU mortality prediction via identifying and
enhancing temporal feature engineering and reduction methods for
similarity-based time series classification.",2017-04-25T00:25:06Z,"Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman"
1704.07499v1,"PPMF: A Patient-based Predictive Modeling Framework for Early ICU
  Mortality Prediction","To date, developing a good model for early intensive care unit (ICU)
mortality prediction is still challenging. This paper presents a patient based
predictive modeling framework (PPMF) to improve the performance of ICU
mortality prediction using data collected during the first 48 hours of ICU
admission. PPMF consists of three main components verifying three related
research hypotheses. The first component captures dynamic changes of patients
status in the ICU using their time series data (e.g., vital signs and
laboratory tests). The second component is a local approximation algorithm that
classifies patients based on their similarities. The third component is a
Gradient Decent wrapper that updates feature weights according to the
classification feedback. Experiments using data from MIMICIII show that PPMF
significantly outperforms: (1) the severity score systems, namely SASP III,
APACHE IV, and MPM0III, (2) the aggregation based classifiers that utilize
summarized time series, and (3) baseline feature selection methods.",2017-04-25T00:27:00Z,"Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman"
1705.00597v1,"Towards well-specified semi-supervised model-based classifiers via
  structural adaptation","Semi-supervised learning plays an important role in large-scale machine
learning. Properly using additional unlabeled data (largely available nowadays)
often can improve the machine learning accuracy. However, if the machine
learning model is misspecified for the underlying true data distribution, the
model performance could be seriously jeopardized. This issue is known as model
misspecification. To address this issue, we focus on generative models and
propose a criterion to detect the onset of model misspecification by measuring
the performance difference between models obtained using supervised and
semi-supervised learning. Then, we propose to automatically modify the
generative models during model training to achieve an unbiased generative
model. Rigorous experiments were carried out to evaluate the proposed method
using two image classification data sets PASCAL VOC'07 and MIR Flickr. Our
proposed method has been demonstrated to outperform a number of
state-of-the-art semi-supervised learning approaches for the classification
task.",2017-05-01T17:26:53Z,"Zhaocai Sun, William K. Cheung, Xiaofeng Zhang, Jun Yang"
1705.01197v1,"Analyzing Knowledge Transfer in Deep Q-Networks for Autonomously
  Handling Multiple Intersections","We analyze how the knowledge to autonomously handle one type of intersection,
represented as a Deep Q-Network, translates to other types of intersections
(tasks). We view intersection handling as a deep reinforcement learning
problem, which approximates the state action Q function as a deep neural
network. Using a traffic simulator, we show that directly copying a network
trained for one type of intersection to another type of intersection decreases
the success rate. We also show that when a network that is pre-trained on Task
A and then is fine-tuned on a Task B, the resulting network not only performs
better on the Task B than an network exclusively trained on Task A, but also
retained knowledge on the Task A. Finally, we examine a lifelong learning
setting, where we train a single network on five different types of
intersections sequentially and show that the resulting network exhibited
catastrophic forgetting of knowledge on previous tasks. This result suggests a
need for a long-term memory component to preserve knowledge.",2017-05-02T23:05:56Z,"David Isele, Akansel Cosgun, Kikuo Fujimura"
1705.01209v2,Lifelong Metric Learning,"The state-of-the-art online learning approaches are only capable of learning
the metric for predefined tasks. In this paper, we consider lifelong learning
problem to mimic ""human learning"", i.e., endowing a new capability to the
learned metric for a new task from new online samples and incorporating
previous experiences and knowledge. Therefore, we propose a new metric learning
framework: lifelong metric learning (LML), which only utilizes the data of the
new task to train the metric model while preserving the original capabilities.
More specifically, the proposed LML maintains a common subspace for all learned
metrics, named lifelong dictionary, transfers knowledge from the common
subspace to each new metric task with task-specific idiosyncrasy, and redefines
the common subspace over time to maximize performance across all metric tasks.
For model optimization, we apply online passive aggressive optimization
algorithm to solve the proposed LML framework, where the lifelong dictionary
and task-specific partition are optimized alternatively and consecutively.
Finally, we evaluate our approach by analyzing several multi-task metric
learning datasets. Extensive experimental results demonstrate effectiveness and
efficiency of the proposed framework.",2017-05-03T00:31:55Z,"Gan Sun, Yang Cong, Ji Liu, Xiaowei Xu"
1705.02670v1,Metacontrol for Adaptive Imagination-Based Optimization,"Many machine learning systems are built to solve the hardest examples of a
particular task, which often makes them large and expensive to run---especially
with respect to the easier examples, which might require much less computation.
For an agent with a limited computational budget, this ""one-size-fits-all""
approach may result in the agent wasting valuable computation on easy examples,
while not spending enough on hard examples. Rather than learning a single,
fixed policy for solving all instances of a task, we introduce a metacontroller
which learns to optimize a sequence of ""imagined"" internal simulations over
predictive models of the world in order to construct a more informed, and more
economical, solution. The metacontroller component is a model-free
reinforcement learning agent, which decides both how many iterations of the
optimization procedure to run, as well as which model to consult on each
iteration. The models (which we call ""experts"") can be state transition models,
action-value functions, or any other mechanism that provides information useful
for solving the task, and can be learned on-policy or off-policy in parallel
with the metacontroller. When the metacontroller, controller, and experts were
trained with ""interaction networks"" (Battaglia et al., 2016) as expert models,
our approach was able to solve a challenging decision-making problem under
complex non-linear dynamics. The metacontroller learned to adapt the amount of
computation it performed to the difficulty of the task, and learned how to
choose which experts to consult by factoring in both their reliability and
individual computational resource costs. This allowed the metacontroller to
achieve a lower overall cost (task loss plus computational cost) than more
traditional fixed policy approaches. These results demonstrate that our
approach is a powerful framework for using rich forward models for efficient
model-based reinforcement learning.",2017-05-07T17:48:14Z,"Jessica B. Hamrick, Andrew J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, Peter W. Battaglia"
1705.04185v2,A First Empirical Study of Emphatic Temporal Difference Learning,"In this paper we present the first empirical study of the emphatic
temporal-difference learning algorithm (ETD), comparing it with conventional
temporal-difference learning, in particular, with linear TD(0), on on-policy
and off-policy variations of the Mountain Car problem. The initial motivation
for developing ETD was that it has good convergence properties under off-policy
training (Sutton, Mahmood and White 2016), but it is also a new algorithm for
the on-policy case. In both our on-policy and off-policy experiments, we found
that each method converged to a characteristic asymptotic level of error, with
ETD better than TD(0). TD(0) achieved a still lower error level temporarily
before falling back to its higher asymptote, whereas ETD never showed this kind
of ""bounce"". In the off-policy case (in which TD(0) is not guaranteed to
converge), ETD was significantly slower.",2017-05-11T13:52:52Z,"Sina Ghiassian, Banafsheh Rafiee, Richard S. Sutton"
1705.05427v3,Repeated Inverse Reinforcement Learning,"We introduce a novel repeated Inverse Reinforcement Learning problem: the
agent has to act on behalf of a human in a sequence of tasks and wishes to
minimize the number of tasks that it surprises the human by acting suboptimally
with respect to how the human would have acted. Each time the human is
surprised, the agent is provided a demonstration of the desired behavior by the
human. We formalize this problem, including how the sequence of tasks is
chosen, in a few different ways and provide some foundational results.",2017-05-15T20:06:35Z,"Kareem Amin, Nan Jiang, Satinder Singh"
1705.06460v2,Evolving Ensemble Fuzzy Classifier,"The concept of ensemble learning offers a promising avenue in learning from
data streams under complex environments because it addresses the bias and
variance dilemma better than its single model counterpart and features a
reconfigurable structure, which is well suited to the given context. While
various extensions of ensemble learning for mining non-stationary data streams
can be found in the literature, most of them are crafted under a static base
classifier and revisits preceding samples in the sliding window for a
retraining step. This feature causes computationally prohibitive complexity and
is not flexible enough to cope with rapidly changing environments. Their
complexities are often demanding because it involves a large collection of
offline classifiers due to the absence of structural complexities reduction
mechanisms and lack of an online feature selection mechanism. A novel evolving
ensemble classifier, namely Parsimonious Ensemble pENsemble, is proposed in
this paper. pENsemble differs from existing architectures in the fact that it
is built upon an evolving classifier from data streams, termed Parsimonious
Classifier pClass. pENsemble is equipped by an ensemble pruning mechanism,
which estimates a localized generalization error of a base classifier. A
dynamic online feature selection scenario is integrated into the pENsemble.
This method allows for dynamic selection and deselection of input features on
the fly. pENsemble adopts a dynamic ensemble structure to output a final
classification decision where it features a novel drift detection scenario to
grow the ensemble structure. The efficacy of the pENsemble has been numerically
demonstrated through rigorous numerical studies with dynamic and evolving data
streams where it delivers the most encouraging performance in attaining a
tradeoff between accuracy and complexity.",2017-05-18T08:19:41Z,"Mahardhika Pratama, Witold Pedrycz, Edwin Lughofer"
1705.06573v1,"Online learnability of Statistical Relational Learning in anomaly
  detection","Statistical Relational Learning (SRL) methods for anomaly detection are
introduced via a security-related application. Operational requirements for
online learning stability are outlined and compared to mathematical definitions
as applied to the learning process of a representative SRL method - Bayesian
Logic Programs (BLP). Since a formal proof of online stability appears to be
impossible, tentative common sense requirements are formulated and tested by
theoretical and experimental analysis of a simple and analytically tractable
BLP model. It is found that learning algorithms in initial stages of online
learning can lock on unstable false predictors that nevertheless comply with
our tentative stability requirements and thus masquerade as bona fide
solutions. The very expressiveness of SRL seems to cause significant stability
issues in settings with many variables and scarce data. We conclude that
reliable anomaly detection with SRL-methods requires monitoring by an
overarching framework that may involve a comprehensive context knowledge base
or human supervision.",2017-05-18T13:14:43Z,"Magnus Jndel, Pontus Svenson, Niclas Wadstrmer"
1705.06769v2,"Feature Control as Intrinsic Motivation for Hierarchical Reinforcement
  Learning","The problem of sparse rewards is one of the hardest challenges in
contemporary reinforcement learning. Hierarchical reinforcement learning (HRL)
tackles this problem by using a set of temporally-extended actions, or options,
each of which has its own subgoal. These subgoals are normally handcrafted for
specific tasks. Here, though, we introduce a generic class of subgoals with
broad applicability in the visual domain. Underlying our approach (in common
with work using ""auxiliary tasks"") is the hypothesis that the ability to
control aspects of the environment is an inherently useful skill to have. We
incorporate such subgoals in an end-to-end hierarchical reinforcement learning
system and test two variants of our algorithm on a number of games from the
Atari suite. We highlight the advantage of our approach in one of the hardest
games -- Montezuma's revenge -- for which the ability to handle sparse rewards
is key. Our agent learns several times faster than the current state-of-the-art
HRL agent in this game, reaching a similar level of performance. UPDATE
22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e.
extrinsic reward + feature control intrinsic reward, has comparable performance
to our agent in Montezuma Revenge. In light of the new experiments performed,
the advantage of our HRL approach can be attributed more to its ability to
learn useful features from intrinsic rewards rather than its ability to explore
and reuse abstracted skills with hierarchical components. This has led us to a
new conclusion about the result.",2017-05-18T19:00:43Z,"Nat Dilokthanakul, Christos Kaplanis, Nick Pawlowski, Murray Shanahan"
1705.07269v1,"Learning to Factor Policies and Action-Value Functions: Factored Action
  Space Representations for Deep Reinforcement learning","Deep Reinforcement Learning (DRL) methods have performed well in an
increasing numbering of high-dimensional visual decision making domains. Among
all such visual decision making problems, those with discrete action spaces
often tend to have underlying compositional structure in the said action space.
Such action spaces often contain actions such as go left, go up as well as go
diagonally up and left (which is a composition of the former two actions). The
representations of control policies in such domains have traditionally been
modeled without exploiting this inherent compositional structure in the action
spaces. We propose a new learning paradigm, Factored Action space
Representations (FAR) wherein we decompose a control policy learned using a
Deep Reinforcement Learning Algorithm into independent components, analogous to
decomposing a vector in terms of some orthogonal basis vectors. This
architectural modification of the control policy representation allows the
agent to learn about multiple actions simultaneously, while executing only one
of them. We demonstrate that FAR yields considerable improvements on top of two
DRL algorithms in Atari 2600: FARA3C outperforms A3C (Asynchronous Advantage
Actor Critic) in 9 out of 14 tasks and FARAQL outperforms AQL (Asynchronous
n-step Q-Learning) in 9 out of 13 tasks.",2017-05-20T07:18:40Z,"Sahil Sharma, Aravind Suresh, Rahul Ramesh, Balaraman Ravindran"
1705.07445v2,"Learning to Mix n-Step Returns: Generalizing lambda-Returns for Deep
  Reinforcement Learning","Reinforcement Learning (RL) can model complex behavior policies for
goal-directed sequential decision making tasks. A hallmark of RL algorithms is
Temporal Difference (TD) learning: value function for the current state is
moved towards a bootstrapped target that is estimated using next state's value
function. $\lambda$-returns generalize beyond 1-step returns and strike a
balance between Monte Carlo and TD learning methods. While lambda-returns have
been extensively studied in RL, they haven't been explored a lot in Deep RL.
This paper's first contribution is an exhaustive benchmarking of
lambda-returns. Although mathematically tractable, the use of exponentially
decaying weighting of n-step returns based targets in lambda-returns is a
rather ad-hoc design choice. Our second major contribution is that we propose a
generalization of lambda-returns called Confidence-based Autodidactic Returns
(CAR), wherein the RL agent learns the weighting of the n-step returns in an
end-to-end manner. This allows the agent to learn to decide how much it wants
to weigh the n-step returns based targets. In contrast, lambda-returns restrict
RL agents to use an exponentially decaying weighting scheme. Autodidactic
returns can be used for improving any RL algorithm which uses TD learning. We
empirically demonstrate that using sophisticated weighted mixtures of
multi-step returns (like CAR and lambda-returns) considerably outperforms the
use of n-step returns. We perform our experiments on the Asynchronous Advantage
Actor Critic (A3C) algorithm in the Atari 2600 domain.",2017-05-21T12:47:37Z,"Sahil Sharma, Girish Raguvir J, Srivatsan Ramesh, Balaraman Ravindran"
1705.08439v4,Thinking Fast and Slow with Deep Learning and Tree Search,"Sequential decision making problems, such as structured prediction, robotic
control, and game playing, require a combination of planning policies and
generalisation of those plans. In this paper, we present Expert Iteration
(ExIt), a novel reinforcement learning algorithm which decomposes the problem
into separate planning and generalisation tasks. Planning new policies is
performed by tree search, while a deep neural network generalises those plans.
Subsequently, tree search is improved by using the neural network policy to
guide search, increasing the strength of new plans. In contrast, standard deep
Reinforcement Learning algorithms rely on a neural network not only to
generalise plans, but to discover them too. We show that ExIt outperforms
REINFORCE for training a neural network to play the board game Hex, and our
final tree search agent, trained tabula rasa, defeats MoHex 1.0, the most
recent Olympiad Champion player to be publicly released.",2017-05-23T17:48:51Z,"Thomas Anthony, Zheng Tian, David Barber"
1705.08500v2,Selective Classification for Deep Neural Networks,"Selective classification techniques (also known as reject option) have not
yet been considered in the context of deep neural networks (DNNs). These
techniques can potentially significantly improve DNNs prediction performance by
trading-off coverage. In this paper we propose a method to construct a
selective classifier given a trained neural network. Our method allows a user
to set a desired risk level. At test time, the classifier rejects instances as
needed, to grant the desired risk (with high probability). Empirical results
over CIFAR and ImageNet convincingly demonstrate the viability of our method,
which opens up possibilities to operate DNNs in mission-critical applications.
For example, using our method an unprecedented 2% error in top-5 ImageNet
classification can be guaranteed with probability 99.9%, and almost 60% test
coverage.",2017-05-23T19:43:56Z,"Yonatan Geifman, Ran El-Yaniv"
1705.09011v2,Principled Hybrids of Generative and Discriminative Domain Adaptation,"We propose a probabilistic framework for domain adaptation that blends both
generative and discriminative modeling in a principled way. Under this
framework, generative and discriminative models correspond to specific choices
of the prior over parameters. This provides us a very general way to
interpolate between generative and discriminative extremes through different
choices of priors. By maximizing both the marginal and the conditional
log-likelihoods, models derived from this framework can use both labeled
instances from the source domain as well as unlabeled instances from both
source and target domains. Under this framework, we show that the popular
reconstruction loss of autoencoder corresponds to an upper bound of the
negative marginal log-likelihoods of unlabeled instances, where marginal
distributions are given by proper kernel density estimations. This provides a
way to interpret the empirical success of autoencoders in domain adaptation and
semi-supervised learning. We instantiate our framework using neural networks,
and build a concrete model, DAuto. Empirically, we demonstrate the
effectiveness of DAuto on text, image and speech datasets, showing that it
outperforms related competitors when domain adaptation is possible.",2017-05-25T01:02:16Z,"Han Zhao, Zhenyao Zhu, Junjie Hu, Adam Coates, Geoff Gordon"
1705.09436v1,Human Trajectory Prediction using Spatially aware Deep Attention Models,"Trajectory Prediction of dynamic objects is a widely studied topic in the
field of artificial intelligence. Thanks to a large number of applications like
predicting abnormal events, navigation system for the blind, etc. there have
been many approaches to attempt learning patterns of motion directly from data
using a wide variety of techniques ranging from hand-crafted features to
sophisticated deep learning models for unsupervised feature learning. All these
approaches have been limited by problems like inefficient features in the case
of hand crafted features, large error propagation across the predicted
trajectory and no information of static artefacts around the dynamic moving
objects. We propose an end to end deep learning model to learn the motion
patterns of humans using different navigational modes directly from data using
the much popular sequence to sequence model coupled with a soft attention
mechanism. We also propose a novel approach to model the static artefacts in a
scene and using these to predict the dynamic trajectories. The proposed method,
tested on trajectories of pedestrians, consistently outperforms previously
proposed state of the art approaches on a variety of large scale data sets. We
also show how our architecture can be naturally extended to handle multiple
modes of movement (say pedestrians, skaters, bikers and buses) simultaneously.",2017-05-26T05:37:36Z,"Daksh Varshneya, G. Srinivasaraghavan"
1705.09439v1,Taste or Addiction?: Using Play Logs to Infer Song Selection Motivation,"Online music services are increasing in popularity. They enable us to analyze
people's music listening behavior based on play logs. Although it is known that
people listen to music based on topic (e.g., rock or jazz), we assume that when
a user is addicted to an artist, s/he chooses the artist's songs regardless of
topic. Based on this assumption, in this paper, we propose a probabilistic
model to analyze people's music listening behavior. Our main contributions are
three-fold. First, to the best of our knowledge, this is the first study
modeling music listening behavior by taking into account the influence of
addiction to artists. Second, by using real-world datasets of play logs, we
showed the effectiveness of our proposed model. Third, we carried out
qualitative experiments and showed that taking addiction into account enables
us to analyze music listening behavior from a new viewpoint in terms of how
people listen to music according to the time of day, how an artist's songs are
listened to by people, etc. We also discuss the possibility of applying the
analysis results to applications such as artist similarity computation and song
recommendation.",2017-05-26T05:54:20Z,"Kosetsu Tsukuda, Masataka Goto"
1705.09783v3,Good Semi-supervised Learning that Requires a Bad GAN,"Semi-supervised learning methods based on generative adversarial networks
(GANs) obtained strong empirical results, but it is not clear 1) how the
discriminator benefits from joint training with a generator, and 2) why good
semi-supervised classification performance and a good generator cannot be
obtained at the same time. Theoretically, we show that given the discriminator
objective, good semisupervised learning indeed requires a bad generator, and
propose the definition of a preferred generator. Empirically, we derive a novel
formulation based on our analysis that substantially improves over feature
matching GANs, obtaining state-of-the-art results on multiple benchmark
datasets.",2017-05-27T07:53:53Z,"Zihang Dai, Zhilin Yang, Fan Yang, William W. Cohen, Ruslan Salakhutdinov"
1705.09922v1,"Bayesian Unification of Gradient and Bandit-based Learning for
  Accelerated Global Optimisation","Bandit based optimisation has a remarkable advantage over gradient based
approaches due to their global perspective, which eliminates the danger of
getting stuck at local optima. However, for continuous optimisation problems or
problems with a large number of actions, bandit based approaches can be
hindered by slow learning. Gradient based approaches, on the other hand,
navigate quickly in high-dimensional continuous spaces through local
optimisation, following the gradient in fine grained steps. Yet, apart from
being susceptible to local optima, these schemes are less suited for online
learning due to their reliance on extensive trial-and-error before the optimum
can be identified. In this paper, we propose a Bayesian approach that unifies
the above two paradigms in one single framework, with the aim of combining
their advantages. At the heart of our approach we find a stochastic linear
approximation of the function to be optimised, where both the gradient and
values of the function are explicitly captured. This allows us to learn from
both noisy function and gradient observations, and predict these properties
across the action space to support optimisation. We further propose an
accompanying bandit driven exploration scheme that uses Bayesian credible
bounds to trade off exploration against exploitation. Our empirical results
demonstrate that by unifying bandit and gradient based learning, one obtains
consistently improved performance across a wide spectrum of problem
environments. Furthermore, even when gradient feedback is unavailable, the
flexibility of our model, including gradient prediction, still allows us
outperform competing approaches, although with a smaller margin. Due to the
pervasiveness of bandit based optimisation, our scheme opens up for improved
performance both in meta-optimisation and in applications where gradient
related information is readily available.",2017-05-28T09:55:11Z,Ole-Christoffer Granmo
1705.10342v1,Deep Learning for Ontology Reasoning,"In this work, we present a novel approach to ontology reasoning that is based
on deep learning rather than logic-based formal reasoning. To this end, we
introduce a new model for statistical relational learning that is built upon
deep recursive neural networks, and give experimental evidence that it can
easily compete with, or even outperform, existing logic-based reasoners on the
task of ontology reasoning. More precisely, we compared our implemented system
with one of the best logic-based ontology reasoners at present, RDFox, on a
number of large standard benchmark datasets, and found that our system attained
high reasoning quality, while being up to two orders of magnitude faster.",2017-05-29T18:17:52Z,"Patrick Hohenecker, Thomas Lukasiewicz"
1705.10701v1,Multi-Labelled Value Networks for Computer Go,"This paper proposes a new approach to a novel value network architecture for
the game Go, called a multi-labelled (ML) value network. In the ML value
network, different values (win rates) are trained simultaneously for different
settings of komi, a compensation given to balance the initiative of playing
first. The ML value network has three advantages, (a) it outputs values for
different komi, (b) it supports dynamic komi, and (c) it lowers the mean
squared error (MSE). This paper also proposes a new dynamic komi method to
improve game-playing strength. This paper also performs experiments to
demonstrate the merits of the architecture. First, the MSE of the ML value
network is generally lower than the value network alone. Second, the program
based on the ML value network wins by a rate of 67.6% against the program based
on the value network alone. Third, the program with the proposed dynamic komi
method significantly improves the playing strength over the baseline that does
not use dynamic komi, especially for handicap games. To our knowledge, up to
date, no handicap games have been played openly by programs using value
networks. This paper provides these programs with a useful approach to playing
handicap games.",2017-05-30T15:23:32Z,"Ti-Rong Wu, I-Chen Wu, Guan-Wun Chen, Ting-han Wei, Tung-Yi Lai, Hung-Chun Wu, Li-Cheng Lan"
1705.10744v1,Knowledge Base Completion: Baselines Strike Back,"Many papers have been published on the knowledge base completion task in the
past few years. Most of these introduce novel architectures for relation
learning that are evaluated on standard datasets such as FB15k and WN18. This
paper shows that the accuracy of almost all models published on the FB15k can
be outperformed by an appropriately tuned baseline - our reimplementation of
the DistMult model. Our findings cast doubt on the claim that the performance
improvements of recent models are due to architectural changes as opposed to
hyper-parameter tuning or different training objectives. This should prompt
future research to re-consider how the performance of models is evaluated and
reported.",2017-05-30T16:54:19Z,"Rudolf Kadlec, Ondrej Bajgar, Jan Kleindienst"
1705.10786v1,Semi-Supervised Learning for Detecting Human Trafficking,"Human trafficking is one of the most atrocious crimes and among the
challenging problems facing law enforcement which demands attention of global
magnitude. In this study, we leverage textual data from the website ""Backpage""-
used for classified advertisement- to discern potential patterns of human
trafficking activities which manifest online and identify advertisements of
high interest to law enforcement. Due to the lack of ground truth, we rely on a
human analyst from law enforcement, for hand-labeling a small portion of the
crawled data. We extend the existing Laplacian SVM and present S3VM-R, by
adding a regularization term to exploit exogenous information embedded in our
feature space in favor of the task at hand. We train the proposed method using
labeled and unlabeled data and evaluate it on a fraction of the unlabeled data,
herein referred to as unseen data, with our expert's further verification.
Results from comparisons between our method and other semi-supervised and
supervised approaches on the labeled data demonstrate that our learner is
effective in identifying advertisements of high interest to law enforcement",2017-05-30T05:51:53Z,"Hamidreza Alvari, Paulo Shakarian, J. E. Kelly Snyder"
1706.02416v2,Generalized Value Iteration Networks: Life Beyond Lattices,"In this paper, we introduce a generalized value iteration network (GVIN),
which is an end-to-end neural network planning module. GVIN emulates the value
iteration algorithm by using a novel graph convolution operator, which enables
GVIN to learn and plan on irregular spatial graphs. We propose three novel
differentiable kernels as graph convolution operators and show that the
embedding based kernel achieves the best performance. We further propose
episodic Q-learning, an improvement upon traditional n-step Q-learning that
stabilizes training for networks that contain a planning module. Lastly, we
evaluate GVIN on planning problems in 2D mazes, irregular graphs, and
real-world street networks, showing that GVIN generalizes well for both
arbitrary graphs and unseen graphs of larger scale and outperforms a naive
generalization of VIN (discretizing a spatial graph into a 2D image).",2017-06-08T00:04:05Z,"Sufeng Niu, Siheng Chen, Hanyu Guo, Colin Targonski, Melissa C. Smith, Jelena Kovaevi"
1706.02780v1,"Setting Players' Behaviors in World of Warcraft through Semi-Supervised
  Learning","Digital games are one of the major and most important fields on the
entertainment domain, which also involves cinema and music. Numerous attempts
have been done to improve the quality of the games including more realistic
artistic production and computer science. Assessing the player's behavior, a
task known as player modeling, is currently the need of the hour which leads to
possible improvements in terms of: (i) better game interaction experience, (ii)
better exploitation of the relationship between players, and (iii)
increasing/maintaining the number of players interested in the game. In this
paper we model players using the basic four behaviors proposed in
\cite{BartleArtigo}, namely: achiever, explorer, socializer and killer. Our
analysis is carried out using data obtained from the game ""World of Warcraft""
over 3 years (2006 $-$ 2009). We employ a semi-supervised learning technique in
order to find out characteristics that possibly impact player's behavior.",2017-06-08T21:48:46Z,"Marcelo Souza Nery, Roque Anderson Teixeira, Victor do Nascimento Silva, Adriano Alonso Veloso"
1706.03235v3,"ACCNet: Actor-Coordinator-Critic Net for ""Learning-to-Communicate"" with
  Deep Multi-agent Reinforcement Learning","Communication is a critical factor for the big multi-agent world to stay
organized and productive. Typically, most previous multi-agent
""learning-to-communicate"" studies try to predefine the communication protocols
or use technologies such as tabular reinforcement learning and evolutionary
algorithm, which can not generalize to changing environment or large collection
of agents.
  In this paper, we propose an Actor-Coordinator-Critic Net (ACCNet) framework
for solving ""learning-to-communicate"" problem. The ACCNet naturally combines
the powerful actor-critic reinforcement learning technology with deep learning
technology. It can efficiently learn the communication protocols even from
scratch under partially observable environment. We demonstrate that the ACCNet
can achieve better results than several baselines under both continuous and
discrete action space environments. We also analyse the learned protocols and
discuss some design considerations.",2017-06-10T13:50:23Z,"Hangyu Mao, Zhibo Gong, Yan Ni, Zhen Xiao"
1706.04721v2,"Target Curricula via Selection of Minimum Feature Sets: a Case Study in
  Boolean Networks","We consider the effect of introducing a curriculum of targets when training
Boolean models on supervised Multi Label Classification (MLC) problems. In
particular, we consider how to order targets in the absence of prior knowledge,
and how such a curriculum may be enforced when using meta-heuristics to train
discrete non-linear models.
  We show that hierarchical dependencies between targets can be exploited by
enforcing an appropriate curriculum using hierarchical loss functions. On
several multi output circuit-inference problems with known target difficulties,
Feedforward Boolean Networks (FBNs) trained with such a loss function achieve
significantly lower out-of-sample error, up to $10\%$ in some cases. This
improvement increases as the loss places more emphasis on target order and is
strongly correlated with an easy-to-hard curricula. We also demonstrate the
same improvements on three real-world models and two Gene Regulatory Network
(GRN) inference problems.
  We posit a simple a-priori method for identifying an appropriate target order
and estimating the strength of target relationships in Boolean MLCs. These
methods use intrinsic dimension as a proxy for target difficulty, which is
estimated using optimal solutions to a combinatorial optimisation problem known
as the Minimum-Feature-Set (minFS) problem. We also demonstrate that the same
generalisation gains can be achieved without providing any knowledge of target
difficulty.",2017-06-15T02:08:54Z,"Shannon Fenn, Pablo Moscato"
1706.04972v2,Device Placement Optimization with Reinforcement Learning,"The past few years have witnessed a growth in size and computational
requirements for training and inference with neural networks. Currently, a
common approach to address these requirements is to use a heterogeneous
distributed environment with a mixture of hardware devices such as CPUs and
GPUs. Importantly, the decision of placing parts of the neural models on
devices is often made by human experts based on simple heuristics and
intuitions. In this paper, we propose a method which learns to optimize device
placement for TensorFlow computational graphs. Key to our method is the use of
a sequence-to-sequence model to predict which subsets of operations in a
TensorFlow graph should run on which of the available devices. The execution
time of the predicted placements is then used as the reward signal to optimize
the parameters of the sequence-to-sequence model. Our main result is that on
Inception-V3 for ImageNet classification, and on RNN LSTM, for language
modeling and neural machine translation, our model finds non-trivial device
placements that outperform hand-crafted heuristics and traditional algorithmic
methods.",2017-06-13T16:26:40Z,"Azalia Mirhoseini, Hieu Pham, Quoc V. Le, Benoit Steiner, Rasmus Larsen, Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, Jeff Dean"
1706.05064v2,"Zero-Shot Task Generalization with Multi-Task Deep Reinforcement
  Learning","As a step towards developing zero-shot task generalization capabilities in
reinforcement learning (RL), we introduce a new RL problem where the agent
should learn to execute sequences of instructions after learning useful skills
that solve subtasks. In this problem, we consider two types of generalizations:
to previously unseen instructions and to longer sequences of instructions. For
generalization over unseen instructions, we propose a new objective which
encourages learning correspondences between similar subtasks by making
analogies. For generalization over sequential instructions, we present a
hierarchical architecture where a meta controller learns to use the acquired
skills for executing the instructions. To deal with delayed reward, we propose
a new neural architecture in the meta controller that learns when to update the
subtask, which makes learning more efficient. Experimental results on a
stochastic 3D domain show that the proposed ideas are crucial for
generalization to longer instructions as well as unseen instructions.",2017-06-15T20:04:35Z,"Junhyuk Oh, Satinder Singh, Honglak Lee, Pushmeet Kohli"
1706.05198v2,Structured Best Arm Identification with Fixed Confidence,"We study the problem of identifying the best action among a set of possible
options when the value of each action is given by a mapping from a number of
noisy micro-observables in the so-called fixed confidence setting. Our main
motivation is the application to the minimax game search, which has been a
major topic of interest in artificial intelligence. In this paper we introduce
an abstract setting to clearly describe the essential properties of the
problem. While previous work only considered a two-move game tree search
problem, our abstract setting can be applied to the general minimax games where
the depth can be non-uniform and arbitrary, and transpositions are allowed. We
introduce a new algorithm (LUCB-micro) for the abstract setting, and give its
lower and upper sample complexity results. Our bounds recover some previous
results, which were only available in more limited settings, while they also
shed further light on how the structure of minimax problems influence sample
complexity.",2017-06-16T09:51:36Z,"Ruitong Huang, Mohammad M. Ajallooeian, Csaba Szepesvri, Martin Mller"
1706.05744v2,Learning Hierarchical Information Flow with Recurrent Neural Modules,"We propose ThalNet, a deep learning model inspired by neocortical
communication via the thalamus. Our model consists of recurrent neural modules
that send features through a routing center, endowing the modules with the
flexibility to share features over multiple time steps. We show that our model
learns to route information hierarchically, processing input data by a chain of
modules. We observe common architectures, such as feed forward neural networks
and skip connections, emerging as special cases of our architecture, while
novel connectivity patterns are learned for the text8 compression task. Our
model outperforms standard recurrent neural networks on several sequential
benchmarks.",2017-06-18T23:20:12Z,"Danijar Hafner, Alex Irpan, James Davidson, Nicolas Heess"
1706.06122v2,VAIN: Attentional Multi-agent Predictive Modeling,"Multi-agent predictive modeling is an essential step for understanding
physical, social and team-play systems. Recently, Interaction Networks (INs)
were proposed for the task of modeling multi-agent physical systems, INs scale
with the number of interactions in the system (typically quadratic or higher
order in the number of agents). In this paper we introduce VAIN, a novel
attentional architecture for multi-agent predictive modeling that scales
linearly with the number of agents. We show that VAIN is effective for
multi-agent predictive modeling. Our method is evaluated on tasks from
challenging multi-agent prediction domains: chess and soccer, and outperforms
competing multi-agent approaches.",2017-06-19T18:09:25Z,Yedid Hoshen
1706.06643v1,"Policy Gradient Methods for Reinforcement Learning with Function
  Approximation and Action-Dependent Baselines","We show how an action-dependent baseline can be used by the policy gradient
theorem using function approximation, originally presented with
action-independent baselines by (Sutton et al. 2000).",2017-06-20T19:47:44Z,"Philip S. Thomas, Emma Brunskill"
1706.08840v6,Gradient Episodic Memory for Continual Learning,"One major obstacle towards AI is the poor ability of models to solve new
problems quicker, and without forgetting previously acquired knowledge. To
better understand this issue, we study the problem of continual learning, where
the model observes, once and one by one, examples concerning a sequence of
tasks. First, we propose a set of metrics to evaluate models learning over a
continuum of data. These metrics characterize models not only by their test
accuracy, but also in terms of their ability to transfer knowledge across
tasks. Second, we propose a model for continual learning, called Gradient
Episodic Memory (GEM) that alleviates forgetting, while allowing beneficial
transfer of knowledge to previous tasks. Our experiments on variants of the
MNIST and CIFAR-100 datasets demonstrate the strong performance of GEM when
compared to the state-of-the-art.",2017-06-26T14:53:34Z,"David Lopez-Paz, Marc'Aurelio Ranzato"
1706.10036v1,"Providing Effective Real-time Feedback in Simulation-based Surgical
  Training","Virtual reality simulation is becoming popular as a training platform in
surgical education. However, one important aspect of simulation-based surgical
training that has not received much attention is the provision of automated
real-time performance feedback to support the learning process. Performance
feedback is actionable advice that improves novice behaviour. In simulation,
automated feedback is typically extracted from prediction models trained using
data mining techniques. Existing techniques suffer from either low
effectiveness or low efficiency resulting in their inability to be used in
real-time. In this paper, we propose a random forest based method that finds a
balance between effectiveness and efficiency. Experimental results in a
temporal bone surgery simulation show that the proposed method is able to
extract highly effective feedback at a high level of efficiency.",2017-06-30T06:36:14Z,"Xingjun Ma, Sudanthi Wijewickrema, Yun Zhou, Shuo Zhou, Stephen O'Leary, James Bailey"
1706.10240v2,"Bridging the Gap between Probabilistic and Deterministic Models: A
  Simulation Study on a Variational Bayes Predictive Coding Recurrent Neural
  Network Model","The current paper proposes a novel variational Bayes predictive coding RNN
model, which can learn to generate fluctuated temporal patterns from exemplars.
The model learns to maximize the lower bound of the weighted sum of the
regularization and reconstruction error terms. We examined how this weighting
can affect development of different types of information processing while
learning fluctuated temporal patterns. Simulation results show that strong
weighting of the reconstruction term causes the development of deterministic
chaos for imitating the randomness observed in target sequences, while strong
weighting of the regularization term causes the development of stochastic
dynamics imitating probabilistic processes observed in targets. Moreover,
results indicate that the most generalized learning emerges between these two
extremes. The paper concludes with implications in terms of the underlying
neuronal mechanisms for autism spectrum disorder and for free action.",2017-06-30T15:31:17Z,"Ahmadreza Ahmadi, Jun Tani"
1708.01611v1,Identification of Probabilities,"Within psychology, neuroscience and artificial intelligence, there has been
increasing interest in the proposal that the brain builds probabilistic models
of sensory and linguistic input: that is, to infer a probabilistic model from a
sample. The practical problems of such inference are substantial: the brain has
limited data and restricted computational resources. But there is a more
fundamental question: is the problem of inferring a probabilistic model from a
sample possible even in principle? We explore this question and find some
surprisingly positive and general results. First, for a broad class of
probability distributions characterised by computability restrictions, we
specify a learning algorithm that will almost surely identify a probability
distribution in the limit given a finite i.i.d. sample of sufficient but
unknown length. This is similarly shown to hold for sequences generated by a
broad class of Markov chains, subject to computability assumptions. The
technical tool is the strong law of large numbers. Second, for a large class of
dependent sequences, we specify an algorithm which identifies in the limit a
computable measure for which the sequence is typical, in the sense of
Martin-Lof (there may be more than one such measure). The technical tool is the
theory of Kolmogorov complexity. We analyse the associated predictions in both
cases. We also briefly consider special cases, including language learning, and
wider theoretical implications for psychology.",2017-08-04T16:36:12Z,"Paul M. B. Vitanyi, Nick Chater"
1708.02190v3,"Intrinsically Motivated Goal Exploration Processes with Automatic
  Curriculum Learning","Intrinsically motivated spontaneous exploration is a key enabler of
autonomous developmental learning in human children. It enables the discovery
of skill repertoires through autotelic learning, i.e. the self-generation,
self-selection, self-ordering and self-experimentation of learning goals. We
present an algorithmic approach called Intrinsically Motivated Goal Exploration
Processes (IMGEP) to enable similar properties of autonomous learning in
machines. The IMGEP architecture relies on several principles: 1)
self-generation of goals, generalized as parameterized fitness functions; 2)
selection of goals based on intrinsic rewards; 3) exploration with incremental
goal-parameterized policy search and exploitation with a batch learning
algorithm; 4) systematic reuse of information acquired when targeting a goal
for improving towards other goals. We present a particularly efficient form of
IMGEP, called AMB, that uses a population-based policy and an object-centered
spatio-temporal modularity. We provide several implementations of this
architecture and demonstrate their ability to automatically generate a learning
curriculum within several experimental setups. One of these experiments
includes a real humanoid robot exploring multiple spaces of goals with several
hundred continuous dimensions and with distractors. While no particular target
goal is provided to these autotelic agents, this curriculum allows the
discovery of diverse skills that act as stepping stones for learning more
complex skills, e.g. nested tool use.",2017-08-07T16:32:39Z,"Sbastien Forestier, Rmy Portelas, Yoan Mollard, Pierre-Yves Oudeyer"
1708.04321v3,"Distance and Similarity Measures Effect on the Performance of K-Nearest
  Neighbor Classifier -- A Review","The K-nearest neighbor (KNN) classifier is one of the simplest and most
common classifiers, yet its performance competes with the most complex
classifiers in the literature. The core of this classifier depends mainly on
measuring the distance or similarity between the tested examples and the
training examples. This raises a major question about which distance measures
to be used for the KNN classifier among a large number of distance and
similarity measures available? This review attempts to answer this question
through evaluating the performance (measured by accuracy, precision and recall)
of the KNN using a large number of distance measures, tested on a number of
real-world datasets, with and without adding different levels of noise. The
experimental results show that the performance of KNN classifier depends
significantly on the distance used, and the results showed large gaps between
the performances of different distances. We found that a recently proposed
non-convex distance performed the best when applied on most datasets comparing
to the other tested distances. In addition, the performance of the KNN with
this top performing distance degraded only about $20\%$ while the noise level
reaches $90\%$, this is true for most of the distances used as well. This means
that the KNN classifier using any of the top $10$ distances tolerate noise to a
certain degree. Moreover, the results show that some distances are less
affected by the added noise comparing to other distances.",2017-08-14T20:52:35Z,"V. B. Surya Prasath, Haneen Arafat Abu Alfeilat, Ahmad B. A. Hassanat, Omar Lasassmeh, Ahmad S. Tarawneh, Mahmoud Bashir Alhasanat, Hamzeh S. Eyal Salman"
1708.04782v1,StarCraft II: A New Challenge for Reinforcement Learning,"This paper introduces SC2LE (StarCraft II Learning Environment), a
reinforcement learning environment based on the StarCraft II game. This domain
poses a new grand challenge for reinforcement learning, representing a more
difficult class of problems than considered in most prior work. It is a
multi-agent problem with multiple players interacting; there is imperfect
information due to a partially observed map; it has a large action space
involving the selection and control of hundreds of units; it has a large state
space that must be observed solely from raw input feature planes; and it has
delayed credit assignment requiring long-term strategies over thousands of
steps. We describe the observation, action, and reward specification for the
StarCraft II domain and provide an open source Python-based interface for
communicating with the game engine. In addition to the main game maps, we
provide a suite of mini-games focusing on different elements of StarCraft II
gameplay. For the main game maps, we also provide an accompanying dataset of
game replay data from human expert players. We give initial baseline results
for neural networks trained from this data to predict game outcomes and player
actions. Finally, we present initial baseline results for canonical deep
reinforcement learning agents applied to the StarCraft II domain. On the
mini-games, these agents learn to achieve a level of play that is comparable to
a novice player. However, when trained on the main game, these agents are
unable to make significant progress. Thus, SC2LE offers a new and challenging
environment for exploring deep reinforcement learning algorithms and
architectures.",2017-08-16T06:20:52Z,"Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich Kttler, John Agapiou, Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen, Karen Simonyan, Tom Schaul, Hado van Hasselt, David Silver, Timothy Lillicrap, Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence, Anders Ekermo, Jacob Repp, Rodney Tsing"
1708.05563v1,Induction of Decision Trees based on Generalized Graph Queries,"Usually, decision tree induction algorithms are limited to work with non
relational data. Given a record, they do not take into account other objects
attributes even though they can provide valuable information for the learning
task. In this paper we present GGQ-ID3, a multi-relational decision tree
learning algorithm that uses Generalized Graph Queries (GGQ) as predicates in
the decision nodes. GGQs allow to express complex patterns (including cycles)
and they can be refined step-by-step. Also, they can evaluate structures (not
only single records) and perform Regular Pattern Matching. GGQ are built
dynamically (pattern mining) during the GGQ-ID3 tree construction process. We
will show how to use GGQ-ID3 to perform multi-relational machine learning
keeping complexity under control. Finally, some real examples of automatically
obtained classification trees and semantic patterns are shown.
  -----
  Normalmente, los algoritmos de inducci\'on de \'arboles de decisi\'on
trabajan con datos no relacionales. Dado un registro, no tienen en cuenta los
atributos de otros objetos a pesar de que \'estos pueden proporcionar
informaci\'on \'util para la tarea de aprendizaje. En este art\'iculo
presentamos GGQ-ID3, un algoritmo de aprendizaje de \'arboles de decisiones
multi-relacional que utiliza Generalized Graph Queries (GGQ) como predicados en
los nodos de decisi\'on. Los GGQs permiten expresar patrones complejos
(incluyendo ciclos) y pueden ser refinados paso a paso. Adem\'as, pueden
evaluar estructuras (no solo registros) y llevar a cabo Regular Pattern
Matching. En GGQ-ID3, los GGQ son construidos din\'amicamente (pattern mining)
durante el proceso de construcci\'on del \'arbol. Adem\'as, se muestran algunos
ejemplos reales de \'arboles de clasificaci\'on multi-relacionales y patrones
sem\'anticos obtenidos autom\'aticamente.",2017-08-18T11:19:01Z,"Pedro Almagro-Blanco, Fernando Sancho-Caparrini"
1708.06551v2,"Reinforcement Learning in POMDPs with Memoryless Options and
  Option-Observation Initiation Sets","Many real-world reinforcement learning problems have a hierarchical nature,
and often exhibit some degree of partial observability. While hierarchy and
partial observability are usually tackled separately (for instance by combining
recurrent neural networks and options), we show that addressing both problems
simultaneously is simpler and more efficient in many cases. More specifically,
we make the initiation set of options conditional on the previously-executed
option, and show that options with such Option-Observation Initiation Sets
(OOIs) are at least as expressive as Finite State Controllers (FSCs), a
state-of-the-art approach for learning in POMDPs. OOIs are easy to design based
on an intuitive description of the task, lead to explainable policies and keep
the top-level and option policies memoryless. Our experiments show that OOIs
allow agents to learn optimal policies in challenging POMDPs, while being much
more sample-efficient than a recurrent neural network over options.",2017-08-22T09:51:18Z,"Denis Steckelmacher, Diederik M. Roijers, Anna Harutyunyan, Peter Vrancx, Hlne Plisnier, Ann Now"
1708.06832v3,"Learning Anytime Predictions in Neural Networks via Adaptive Loss
  Balancing","This work considers the trade-off between accuracy and test-time
computational cost of deep neural networks (DNNs) via \emph{anytime}
predictions from auxiliary predictions. Specifically, we optimize auxiliary
losses jointly in an \emph{adaptive} weighted sum, where the weights are
inversely proportional to average of each loss. Intuitively, this balances the
losses to have the same scale. We demonstrate theoretical considerations that
motivate this approach from multiple viewpoints, including connecting it to
optimizing the geometric mean of the expectation of each loss, an objective
that ignores the scale of losses. Experimentally, the adaptive weights induce
more competitive anytime predictions on multiple recognition data-sets and
models than non-adaptive approaches including weighing all losses equally. In
particular, anytime neural networks (ANNs) can achieve the same accuracy faster
using adaptive weights on a small network than using static constant weights on
a large one. For problems with high performance saturation, we also show a
sequence of exponentially deepening ANNscan achieve near-optimal anytime
results at any budget, at the cost of a const fraction of extra computation.",2017-08-22T21:42:15Z,"Hanzhang Hu, Debadeepta Dey, Martial Hebert, J. Andrew Bagnell"
1708.06846v1,On Relaxing Determinism in Arithmetic Circuits,"The past decade has seen a significant interest in learning tractable
probabilistic representations. Arithmetic circuits (ACs) were among the first
proposed tractable representations, with some subsequent representations being
instances of ACs with weaker or stronger properties. In this paper, we provide
a formal basis under which variants on ACs can be compared, and where the
precise roles and semantics of their various properties can be made more
transparent. This allows us to place some recent developments on ACs in a
clearer perspective and to also derive new results for ACs. This includes an
exponential separation between ACs with and without determinism; completeness
and incompleteness results; and tractability results (or lack thereof) when
computing most probable explanations (MPEs).",2017-08-22T23:02:11Z,"Arthur Choi, Adnan Darwiche"
1708.08079v1,"Local Gaussian Processes for Efficient Fine-Grained Traffic Speed
  Prediction","Traffic speed is a key indicator for the efficiency of an urban
transportation system. Accurate modeling of the spatiotemporally varying
traffic speed thus plays a crucial role in urban planning and development. This
paper addresses the problem of efficient fine-grained traffic speed prediction
using big traffic data obtained from static sensors. Gaussian processes (GPs)
have been previously used to model various traffic phenomena, including flow
and speed. However, GPs do not scale with big traffic data due to their cubic
time complexity. In this work, we address their efficiency issues by proposing
local GPs to learn from and make predictions for correlated subsets of data.
The main idea is to quickly group speed variables in both spatial and temporal
dimensions into a finite number of clusters, so that future and unobserved
traffic speed queries can be heuristically mapped to one of such clusters. A
local GP corresponding to that cluster can then be trained on the fly to make
predictions in real-time. We call this method localization. We use non-negative
matrix factorization for localization and propose simple heuristics for cluster
mapping. We additionally leverage on the expressiveness of GP kernel functions
to model road network topology and incorporate side information. Extensive
experiments using real-world traffic data collected in the two U.S. cities of
Pittsburgh and Washington, D.C., show that our proposed local GPs significantly
improve both runtime performances and prediction accuracies compared to the
baseline global and local GPs.",2017-08-27T11:41:16Z,"Truc Viet Le, Richard J. Oentaryo, Siyuan Liu, Hoong Chuin Lau"
1710.00459v2,Deep Abstract Q-Networks,"We examine the problem of learning and planning on high-dimensional domains
with long horizons and sparse rewards. Recent approaches have shown great
successes in many Atari 2600 domains. However, domains with long horizons and
sparse rewards, such as Montezuma's Revenge and Venture, remain challenging for
existing methods. Methods using abstraction (Dietterich 2000; Sutton, Precup,
and Singh 1999) have shown to be useful in tackling long-horizon problems. We
combine recent techniques of deep reinforcement learning with existing
model-based approaches using an expert-provided state abstraction. We construct
toy domains that elucidate the problem of long horizons, sparse rewards and
high-dimensional inputs, and show that our algorithm significantly outperforms
previous methods on these domains. Our abstraction-based approach outperforms
Deep Q-Networks (Mnih et al. 2015) on Montezuma's Revenge and Venture, and
exhibits backtracking behavior that is absent from previous methods.",2017-10-02T02:17:09Z,"Melrose Roderick, Christopher Grimm, Stefanie Tellex"
1710.02224v3,Dilated Recurrent Neural Networks,"Learning with recurrent neural networks (RNNs) on long sequences is a
notoriously difficult task. There are three major challenges: 1) complex
dependencies, 2) vanishing and exploding gradients, and 3) efficient
parallelization. In this paper, we introduce a simple yet effective RNN
connection structure, the DilatedRNN, which simultaneously tackles all of these
challenges. The proposed architecture is characterized by multi-resolution
dilated recurrent skip connections and can be combined flexibly with diverse
RNN cells. Moreover, the DilatedRNN reduces the number of parameters needed and
enhances training efficiency significantly, while matching state-of-the-art
performance (even with standard RNN cells) in tasks involving very long-term
dependencies. To provide a theory-based quantification of the architecture's
advantages, we introduce a memory capacity measure, the mean recurrent length,
which is more suitable for RNNs with long skip connections than existing
measures. We rigorously prove the advantages of the DilatedRNN over other
recurrent neural architectures. The code for our method is publicly available
at https://github.com/code-terminator/DilatedRNN",2017-10-05T21:28:01Z,"Shiyu Chang, Yang Zhang, Wei Han, Mo Yu, Xiaoxiao Guo, Wei Tan, Xiaodong Cui, Michael Witbrock, Mark Hasegawa-Johnson, Thomas S. Huang"
1710.02298v1,Rainbow: Combining Improvements in Deep Reinforcement Learning,"The deep reinforcement learning community has made several independent
improvements to the DQN algorithm. However, it is unclear which of these
extensions are complementary and can be fruitfully combined. This paper
examines six extensions to the DQN algorithm and empirically studies their
combination. Our experiments show that the combination provides
state-of-the-art performance on the Atari 2600 benchmark, both in terms of data
efficiency and final performance. We also provide results from a detailed
ablation study that shows the contribution of each component to overall
performance.",2017-10-06T07:45:46Z,"Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, David Silver"
1710.03163v1,Random Projection and Its Applications,"Random Projection is a foundational research topic that connects a bunch of
machine learning algorithms under a similar mathematical basis. It is used to
reduce the dimensionality of the dataset by projecting the data points
efficiently to a smaller dimensions while preserving the original relative
distance between the data points. In this paper, we are intended to explain
random projection method, by explaining its mathematical background and
foundation, the applications that are currently adopting it, and an overview on
its current research perspective.",2017-10-09T15:57:45Z,Mahmoud Nabil
1710.03641v2,"Continuous Adaptation via Meta-Learning in Nonstationary and Competitive
  Environments","Ability to continuously learn and adapt from limited experience in
nonstationary environments is an important milestone on the path towards
general intelligence. In this paper, we cast the problem of continuous
adaptation into the learning-to-learn framework. We develop a simple
gradient-based meta-learning algorithm suitable for adaptation in dynamically
changing and adversarial scenarios. Additionally, we design a new multi-agent
competitive environment, RoboSumo, and define iterated adaptation games for
testing various aspects of continuous adaptation strategies. We demonstrate
that meta-learning enables significantly more efficient adaptation than
reactive baselines in the few-shot regime. Our experiments with a population of
agents that learn and compete suggest that meta-learners are the fittest.",2017-10-10T15:00:37Z,"Maruan Al-Shedivat, Trapit Bansal, Yuri Burda, Ilya Sutskever, Igor Mordatch, Pieter Abbeel"
1710.04380v1,Sign-Constrained Regularized Loss Minimization,"In practical analysis, domain knowledge about analysis target has often been
accumulated, although, typically, such knowledge has been discarded in the
statistical analysis stage, and the statistical tool has been applied as a
black box. In this paper, we introduce sign constraints that are a handy and
simple representation for non-experts in generic learning problems. We have
developed two new optimization algorithms for the sign-constrained regularized
loss minimization, called the sign-constrained Pegasos (SC-Pega) and the
sign-constrained SDCA (SC-SDCA), by simply inserting the sign correction step
into the original Pegasos and SDCA, respectively. We present theoretical
analyses that guarantee that insertion of the sign correction step does not
degrade the convergence rate for both algorithms. Two applications, where the
sign-constrained learning is effective, are presented. The one is exploitation
of prior information about correlation between explanatory variables and a
target variable. The other is introduction of the sign-constrained to
SVM-Pairwise method. Experimental results demonstrate significant improvement
of generalization performance by introducing sign constraints in both
applications.",2017-10-12T06:34:54Z,"Tsuyoshi Kato, Misato Kobayashi, Daisuke Sano"
1710.05219v1,Mental Sampling in Multimodal Representations,"Both resources in the natural environment and concepts in a semantic space
are distributed ""patchily"", with large gaps in between the patches. To describe
people's internal and external foraging behavior, various random walk models
have been proposed. In particular, internal foraging has been modeled as
sampling: in order to gather relevant information for making a decision, people
draw samples from a mental representation using random-walk algorithms such as
Markov chain Monte Carlo (MCMC). However, two common empirical observations
argue against simple sampling algorithms such as MCMC. First, the spatial
structure is often best described by a L\'evy flight distribution: the
probability of the distance between two successive locations follows a
power-law on the distances. Second, the temporal structure of the sampling that
humans and other animals produce have long-range, slowly decaying serial
correlations characterized as $1/f$-like fluctuations. We propose that mental
sampling is not done by simple MCMC, but is instead adapted to multimodal
representations and is implemented by Metropolis-coupled Markov chain Monte
Carlo (MC$^3$), one of the first algorithms developed for sampling from
multimodal distributions. MC$^3$ involves running multiple Markov chains in
parallel but with target distributions of different temperatures, and it swaps
the states of the chains whenever a better location is found. Heated chains
more readily traverse valleys in the probability landscape to propose moves to
far-away peaks, while the colder chains make the local steps that explore the
current peak or patch. We show that MC$^3$ generates distances between
successive samples that follow a L\'evy flight distribution and $1/f$-like
serial correlations, providing a single mechanistic account of these two
puzzling empirical phenomena.",2017-10-14T18:17:30Z,"Jian-Qiao Zhu, Adam N. Sanborn, Nick Chater"
1710.11089v3,Eigenoption Discovery through the Deep Successor Representation,"Options in reinforcement learning allow agents to hierarchically decompose a
task into subtasks, having the potential to speed up learning and planning.
However, autonomously learning effective sets of options is still a major
challenge in the field. In this paper we focus on the recently introduced idea
of using representation learning methods to guide the option discovery process.
Specifically, we look at eigenoptions, options obtained from representations
that encode diffusive information flow in the environment. We extend the
existing algorithms for eigenoption discovery to settings with stochastic
transitions and in which handcrafted features are not available. We propose an
algorithm that discovers eigenoptions while learning non-linear state
representations from raw pixels. It exploits recent successes in the deep
reinforcement learning literature and the equivalence between proto-value
functions and the successor representation. We use traditional tabular domains
to provide intuition about our approach and Atari 2600 games to demonstrate its
potential.",2017-10-30T17:36:19Z,"Marlos C. Machado, Clemens Rosenbaum, Xiaoxiao Guo, Miao Liu, Gerald Tesauro, Murray Campbell"
1710.11424v2,Regret Minimization for Partially Observable Deep Reinforcement Learning,"Deep reinforcement learning algorithms that estimate state and state-action
value functions have been shown to be effective in a variety of challenging
domains, including learning control strategies from raw image pixels. However,
algorithms that estimate state and state-action value functions typically
assume a fully observed state and must compensate for partial observations by
using finite length observation histories or recurrent networks. In this work,
we propose a new deep reinforcement learning algorithm based on counterfactual
regret minimization that iteratively updates an approximation to an
advantage-like function and is robust to partially observed state. We
demonstrate that this new algorithm can substantially outperform strong
baseline methods on several partially observed reinforcement learning tasks:
learning first-person 3D navigation in Doom and Minecraft, and acting in the
presence of partially observed objects in Doom and Pong.",2017-10-31T12:15:38Z,"Peter Jin, Kurt Keutzer, Sergey Levine"
1711.00455v3,A Unified View of Piecewise Linear Neural Network Verification,"The success of Deep Learning and its potential use in many safety-critical
applications has motivated research on formal verification of Neural Network
(NN) models. Despite the reputation of learned NN models to behave as black
boxes and the theoretical hardness of proving their properties, researchers
have been successful in verifying some classes of models by exploiting their
piecewise linear structure and taking insights from formal methods such as
Satisifiability Modulo Theory. These methods are however still far from scaling
to realistic neural networks. To facilitate progress on this crucial area, we
make two key contributions. First, we present a unified framework that
encompasses previous methods. This analysis results in the identification of
new methods that combine the strengths of multiple existing approaches,
accomplishing a speedup of two orders of magnitude compared to the previous
state of the art. Second, we propose a new data set of benchmarks which
includes a collection of previously released testcases. We use the benchmark to
provide the first experimental comparison of existing algorithms and identify
the factors impacting the hardness of verification problems.",2017-11-01T17:42:12Z,"Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, M. Pawan Kumar"
1711.01634v2,Strategies for Conceptual Change in Convolutional Neural Networks,"A remarkable feature of human beings is their capacity for creative
behaviour, referring to their ability to react to problems in ways that are
novel, surprising, and useful. Transformational creativity is a form of
creativity where the creative behaviour is induced by a transformation of the
actor's conceptual space, that is, the representational system with which the
actor interprets its environment. In this report, we focus on ways of adapting
systems of learned representations as they switch from performing one task to
performing another. We describe an experimental comparison of multiple
strategies for adaptation of learned features, and evaluate how effectively
each of these strategies realizes the adaptation, in terms of the amount of
training, and in terms of their ability to cope with restricted availability of
training data. We show, among other things, that across handwritten digits,
natural images, and classical music, adaptive strategies are systematically
more effective than a baseline method that starts learning from scratch.",2017-11-05T18:31:26Z,"Maarten Grachten, Carlos Eduardo Cancino Chacn"
1711.01754v1,Learning Solving Procedure for Artificial Neural Network,"It is expected that progress toward true artificial intelligence will be
achieved through the emergence of a system that integrates representation
learning and complex reasoning (LeCun et al. 2015). In response to this
prediction, research has been conducted on implementing the symbolic reasoning
of a von Neumann computer in an artificial neural network (Graves et al. 2016;
Graves et al. 2014; Reed et al. 2015). However, these studies have many
limitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we
present a new learning paradigm: a learning solving procedure (LSP) that learns
the procedure for solving complex problems. This is not accomplished merely by
learning input-output data, but by learning algorithms through a solving
procedure that obtains the output as a sequence of tasks for a given input
problem. The LSP neural network system not only learns simple problems of
addition and multiplication, but also the algorithms of complicated problems,
such as complex arithmetic expression, sorting, and Hanoi Tower. To realize
this, the LSP neural network structure consists of a deep neural network and
long short-term memory, which are recursively combined. Through
experimentation, we demonstrate the efficiency and scalability of LSP and its
validity as a mechanism of complex reasoning.",2017-11-06T07:28:10Z,"Ju-Hong Lee, Moon-Ju Kang, Bumghi Choi"
1711.01843v2,Online Tool Condition Monitoring Based on Parsimonious Ensemble+,"Accurate diagnosis of tool wear in metal turning process remains an open
challenge for both scientists and industrial practitioners because of
inhomogeneities in workpiece material, nonstationary machining settings to suit
production requirements, and nonlinear relations between measured variables and
tool wear. Common methodologies for tool condition monitoring still rely on
batch approaches which cannot cope with a fast sampling rate of metal cutting
process. Furthermore they require a retraining process to be completed from
scratch when dealing with a new set of machining parameters. This paper
presents an online tool condition monitoring approach based on Parsimonious
Ensemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly
flexible principle where both ensemble structure and base-classifier structure
can automatically grow and shrink on the fly based on the characteristics of
data streams. Moreover, the online feature selection scenario is integrated to
actively sample relevant input attributes. The paper presents advancement of a
newly developed ensemble learning algorithm, pENsemble+, where online active
learning scenario is incorporated to reduce operator labelling effort. The
ensemble merging scenario is proposed which allows reduction of ensemble
complexity while retaining its diversity. Experimental studies utilising
real-world manufacturing data streams and comparisons with well known
algorithms were carried out. Furthermore, the efficacy of pENsemble was
examined using benchmark concept drift data streams. It has been found that
pENsemble+ incurs low structural complexity and results in a significant
reduction of operator labelling effort.",2017-11-06T11:31:46Z,"Mahardhika Pratama, Eric Dimla, Edwin Lughofer, Witold Pedrycz, Tegoeh Tjahjowidowo"
1711.02827v2,Inverse Reward Design,"Autonomous agents optimize the reward function we give them. What they don't
know is how hard it is for us to design a reward function that actually
captures what we want. When designing the reward, we might think of some
specific training scenarios, and make sure that the reward will lead to the
right behavior in those scenarios. Inevitably, agents encounter new scenarios
(e.g., new types of terrain) where optimizing that same reward may lead to
undesired behavior. Our insight is that reward functions are merely
observations about what the designer actually wants, and that they should be
interpreted in the context in which they were designed. We introduce inverse
reward design (IRD) as the problem of inferring the true objective based on the
designed reward and the training MDP. We introduce approximate methods for
solving IRD problems, and use their solution to plan risk-averse behavior in
test MDPs. Empirical results suggest that this approach can help alleviate
negative side effects of misspecified reward functions and mitigate reward
hacking.",2017-11-08T04:44:32Z,"Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart Russell, Anca Dragan"
1711.05255v1,"Deep-ESN: A Multiple Projection-encoding Hierarchical Reservoir
  Computing Framework","As an efficient recurrent neural network (RNN) model, reservoir computing
(RC) models, such as Echo State Networks, have attracted widespread attention
in the last decade. However, while they have had great success with time series
data [1], [2], many time series have a multiscale structure, which a
single-hidden-layer RC model may have difficulty capturing. In this paper, we
propose a novel hierarchical reservoir computing framework we call Deep Echo
State Networks (Deep-ESNs). The most distinctive feature of a Deep-ESN is its
ability to deal with time series through hierarchical projections.
Specifically, when an input time series is projected into the high-dimensional
echo-state space of a reservoir, a subsequent encoding layer (e.g., a PCA,
autoencoder, or a random projection) can project the echo-state representations
into a lower-dimensional space. These low-dimensional representations can then
be processed by another ESN. By using projection layers and encoding layers
alternately in the hierarchical framework, a Deep-ESN can not only attenuate
the effects of the collinearity problem in ESNs, but also fully take advantage
of the temporal kernel property of ESNs to explore multiscale dynamics of time
series. To fuse the multiscale representations obtained by each reservoir, we
add connections from each encoding layer to the last output layer. Theoretical
analyses prove that stability of a Deep-ESN is guaranteed by the echo state
property (ESP), and the time complexity is equivalent to a conventional ESN.
Experimental results on some artificial and real world time series demonstrate
that Deep-ESNs can capture multiscale dynamics, and outperform both standard
ESNs and previous hierarchical ESN-based models.",2017-11-13T13:33:46Z,"Qianli Ma, Lifeng Shen, Garrison W. Cottrell"
1711.05627v1,"Exploiting Layerwise Convexity of Rectifier Networks with Sign
  Constrained Weights","By introducing sign constraints on the weights, this paper proposes sign
constrained rectifier networks (SCRNs), whose training can be solved
efficiently by the well known majorization-minimization (MM) algorithms. We
prove that the proposed two-hidden-layer SCRNs, which exhibit negative weights
in the second hidden layer and negative weights in the output layer, are
capable of separating any two (or more) disjoint pattern sets. Furthermore, the
proposed two-hidden-layer SCRNs can decompose the patterns of each class into
several clusters so that each cluster is convexly separable from all the
patterns from the other classes. This provides a means to learn the pattern
structures and analyse the discriminant factors between different classes of
patterns.",2017-11-14T10:20:44Z,"Senjian An, Farid Boussaid, Mohammed Bennamoun, Ferdous Sohel"
1711.06562v4,An Iterative Closest Points Approach to Neural Generative Models,"We present a simple way to learn a transformation that maps samples of one
distribution to the samples of another distribution. Our algorithm comprises an
iteration of 1) drawing samples from some simple distribution and transforming
them using a neural network, 2) determining pairwise correspondences between
the transformed samples and training data (or a minibatch), and 3) optimizing
the weights of the neural network being trained to minimize the distances
between the corresponding vectors. This can be considered as a variant of the
Iterative Closest Points (ICP) algorithm, common in geometric computer vision,
although ICP typically operates on sensor point clouds and linear transforms
instead of random sample sets and neural nonlinear transforms. We demonstrate
the algorithm on simple synthetic data and MNIST data. We furthermore
demonstrate that the algorithm is capable of handling distributions with both
continuous and discrete variables.",2017-11-16T08:07:47Z,"Joose Rajamki, Perttu Hmlinen"
1711.06677v2,Is prioritized sweeping the better episodic control?,"Episodic control has been proposed as a third approach to reinforcement
learning, besides model-free and model-based control, by analogy with the three
types of human memory. i.e. episodic, procedural and semantic memory. But the
theoretical properties of episodic control are not well investigated. Here I
show that in deterministic tree Markov decision processes, episodic control is
equivalent to a form of prioritized sweeping in terms of sample efficiency as
well as memory and computation demands. For general deterministic and
stochastic environments, prioritized sweeping performs better even when memory
and computation demands are restricted to be equal to those of episodic
control. These results suggest generalizations of prioritized sweeping to
partially observable environments, its combined use with function approximation
and the search for possible implementations of prioritized sweeping in brains.",2017-11-20T07:47:12Z,Johanni Brea
1711.07478v1,Implementing the Deep Q-Network,"The Deep Q-Network proposed by Mnih et al. [2015] has become a benchmark and
building point for much deep reinforcement learning research. However,
replicating results for complex systems is often challenging since original
scientific publications are not always able to describe in detail every
important parameter setting and software engineering solution. In this paper,
we present results from our work reproducing the results of the DQN paper. We
highlight key areas in the implementation that were not covered in great detail
in the original paper to make it easier for researchers to replicate these
results, including termination conditions and gradient descent algorithms.
Finally, we discuss methods for improving the computational performance and
provide our own implementation that is designed to work with a range of
domains, and not just the original Arcade Learning Environment [Bellemare et
al., 2013].",2017-11-20T16:40:33Z,"Melrose Roderick, James MacGlashan, Stefanie Tellex"
1711.07875v2,Constructive Preference Elicitation over Hybrid Combinatorial Spaces,"Preference elicitation is the task of suggesting a highly preferred
configuration to a decision maker. The preferences are typically learned by
querying the user for choice feedback over pairs or sets of objects. In its
constructive variant, new objects are synthesized ""from scratch"" by maximizing
an estimate of the user utility over a combinatorial (possibly infinite) space
of candidates. In the constructive setting, most existing elicitation
techniques fail because they rely on exhaustive enumeration of the candidates.
A previous solution explicitly designed for constructive tasks comes with no
formal performance guarantees, and can be very expensive in (or unapplicable
to) problems with non-Boolean attributes. We propose the Choice Perceptron, a
Perceptron-like algorithm for learning user preferences from set-wise choice
feedback over constructive domains and hybrid Boolean-numeric feature spaces.
We provide a theoretical analysis on the attained regret that holds for a large
class of query selection strategies, and devise a heuristic strategy that aims
at optimizing the regret in practice. Finally, we demonstrate its effectiveness
by empirical evaluation against existing competitors on constructive scenarios
of increasing complexity.",2017-11-21T16:20:24Z,"Paolo Dragone, Stefano Teso, Andrea Passerini"
1711.07979v3,Posterior Sampling for Large Scale Reinforcement Learning,"We propose a practical non-episodic PSRL algorithm that unlike recent
state-of-the-art PSRL algorithms uses a deterministic, model-independent
episode switching schedule. Our algorithm termed deterministic schedule PSRL
(DS-PSRL) is efficient in terms of time, sample, and space complexity. We prove
a Bayesian regret bound under mild assumptions. Our result is more generally
applicable to multiple parameters and continuous state action problems. We
compare our algorithm with state-of-the-art PSRL algorithms on standard
discrete and continuous problems from the literature. Finally, we show how the
assumptions of our algorithm satisfy a sensible parametrization for a large
class of problems in sequential recommendations.",2017-11-21T00:43:24Z,"Georgios Theocharous, Zheng Wen, Yasin Abbasi-Yadkori, Nikos Vlassis"
1711.08068v1,"Deterministic Policy Optimization by Combining Pathwise and Score
  Function Estimators for Discrete Action Spaces","Policy optimization methods have shown great promise in solving complex
reinforcement and imitation learning tasks. While model-free methods are
broadly applicable, they often require many samples to optimize complex
policies. Model-based methods greatly improve sample-efficiency but at the cost
of poor generalization, requiring a carefully handcrafted model of the system
dynamics for each task. Recently, hybrid methods have been successful in
trading off applicability for improved sample-complexity. However, these have
been limited to continuous action spaces. In this work, we present a new hybrid
method based on an approximation of the dynamics as an expectation over the
next state under the current policy. This relaxation allows us to derive a
novel hybrid policy gradient estimator, combining score function and pathwise
derivative estimators, that is applicable to discrete action spaces. We show
significant gains in sample complexity, ranging between $1.7$ and $25\times$,
when learning parameterized policies on Cart Pole, Acrobot, Mountain Car and
Hand Mass. Our method is applicable to both discrete and continuous action
spaces, when competing pathwise methods are limited to the latter.",2017-11-21T22:05:18Z,"Daniel Levy, Stefano Ermon"
1711.08228v1,"An influence-based fast preceding questionnaire model for elderly
  assessments","To improve the efficiency of elderly assessments, an influence-based fast
preceding questionnaire model (FPQM) is proposed. Compared with traditional
assessments, the FPQM optimizes questionnaires by reordering their attributes.
The values of low-ranking attributes can be predicted by the values of the
high-ranking attributes. Therefore, the number of attributes can be reduced
without redesigning the questionnaires. A new function for calculating the
influence of the attributes is proposed based on probability theory. Reordering
and reducing algorithms are given based on the attributes' influences. The
model is verified through a practical application. The practice in an
elderly-care company shows that the FPQM can reduce the number of attributes by
90.56% with a prediction accuracy of 98.39%. Compared with other methods, such
as the Expert Knowledge, Rough Set and C4.5 methods, the FPQM achieves the best
performance. In addition, the FPQM can also be applied to other questionnaires.",2017-11-22T11:10:39Z,"Tong Mo, Rong Zhang, Weiping Li, Jingbo Zhang, Zhonghai Wu, Wei Tan"
1711.08946v2,Action Branching Architectures for Deep Reinforcement Learning,"Discrete-action algorithms have been central to numerous recent successes of
deep reinforcement learning. However, applying these algorithms to
high-dimensional action tasks requires tackling the combinatorial increase of
the number of possible actions with the number of action dimensions. This
problem is further exacerbated for continuous-action tasks that require fine
control of actions via discretization. In this paper, we propose a novel neural
architecture featuring a shared decision module followed by several network
branches, one for each action dimension. This approach achieves a linear
increase of the number of network outputs with the number of degrees of freedom
by allowing a level of independence for each individual action dimension. To
illustrate the approach, we present a novel agent, called Branching Dueling
Q-Network (BDQ), as a branching variant of the Dueling Double Deep Q-Network
(Dueling DDQN). We evaluate the performance of our agent on a set of
challenging continuous control tasks. The empirical results show that the
proposed agent scales gracefully to environments with increasing action
dimensionality and indicate the significance of the shared decision module in
coordination of the distributed action branches. Furthermore, we show that the
proposed agent performs competitively against a state-of-the-art continuous
control algorithm, Deep Deterministic Policy Gradient (DDPG).",2017-11-24T12:45:30Z,"Arash Tavakoli, Fabio Pardo, Petar Kormushev"
1711.09602v1,Deep Reinforcement Learning for Sepsis Treatment,"Sepsis is a leading cause of mortality in intensive care units and costs
hospitals billions annually. Treating a septic patient is highly challenging,
because individual patients respond very differently to medical interventions
and there is no universally agreed-upon treatment for sepsis. In this work, we
propose an approach to deduce treatment policies for septic patients by using
continuous state-space models and deep reinforcement learning. Our model learns
clinically interpretable treatment policies, similar in important aspects to
the treatment policies of physicians. The learned policies could be used to aid
intensive care clinicians in medical decision making and improve the likelihood
of patient survival.",2017-11-27T09:49:57Z,"Aniruddh Raghu, Matthieu Komorowski, Imran Ahmed, Leo Celi, Peter Szolovits, Marzyeh Ghassemi"
1711.09883v2,AI Safety Gridworlds,"We present a suite of reinforcement learning environments illustrating
various safety properties of intelligent agents. These problems include safe
interruptibility, avoiding side effects, absent supervisor, reward gaming, safe
exploration, as well as robustness to self-modification, distributional shift,
and adversaries. To measure compliance with the intended safe behavior, we
equip each environment with a performance function that is hidden from the
agent. This allows us to categorize AI safety problems into robustness and
specification problems, depending on whether the performance function
corresponds to the observed reward function. We evaluate A2C and Rainbow, two
recent deep reinforcement learning agents, on our environments and show that
they are not able to solve them satisfactorily.",2017-11-27T18:57:13Z,"Jan Leike, Miljan Martic, Victoria Krakovna, Pedro A. Ortega, Tom Everitt, Andrew Lefrancq, Laurent Orseau, Shane Legg"
1712.00004v1,Learnings Options End-to-End for Continuous Action Tasks,"We present new results on learning temporally extended actions for
continuoustasks, using the options framework (Suttonet al.[1999b], Precup
[2000]). In orderto achieve this goal we work with the option-critic
architecture (Baconet al.[2017])using a deliberation cost and train it with
proximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy
gradient. Results on Mujoco domains arepromising, but lead to interesting
questions aboutwhena given option should beused, an issue directly connected to
the use of initiation sets.",2017-11-30T00:45:09Z,"Martin Klissarov, Pierre-Luc Bacon, Jean Harb, Doina Precup"
1712.00006v2,"Comparing Deep Reinforcement Learning and Evolutionary Methods in
  Continuous Control","Reinforcement Learning and the Evolutionary Strategy are two major approaches
in addressing complicated control problems. Both are strong contenders and have
their own devotee communities. Both groups have been very active in developing
new advances in their own domain and devising, in recent years, leading-edge
techniques to address complex continuous control tasks. Here, in the context of
Deep Reinforcement Learning, we formulate a parallelized version of the
Proximal Policy Optimization method and a Deep Deterministic Policy Gradient
method. Moreover, we conduct a thorough comparison between the state-of-the-art
techniques in both camps fro continuous control; evolutionary methods and Deep
Reinforcement Learning methods. The results show there is no consistent winner.",2017-11-30T03:40:06Z,"Shangtong Zhang, Osmar R. Zaiane"
1712.01235v1,On the Real-time Vehicle Placement Problem,"Motivated by ride-sharing platforms' efforts to reduce their riders' wait
times for a vehicle, this paper introduces a novel problem of placing vehicles
to fulfill real-time pickup requests in a spatially and temporally changing
environment. The real-time nature of this problem makes it fundamentally
different from other placement and scheduling problems, as it requires not only
real-time placement decisions but also handling real-time request dynamics,
which are influenced by human mobility patterns. We use a dataset of ten
million ride requests from four major U.S. cities to show that the requests
exhibit significant self-similarity. We then propose distributed online
learning algorithms for the real-time vehicle placement problem and bound their
expected performance under this observed self-similarity.",2017-12-04T18:21:38Z,"Abhinav Jauhri, Carlee Joe-Wong, John Paul Shen"
1712.01275v3,A Deeper Look at Experience Replay,"Recently experience replay is widely used in various deep reinforcement
learning (RL) algorithms, in this paper we rethink the utility of experience
replay. It introduces a new hyper-parameter, the memory buffer size, which
needs carefully tuning. However unfortunately the importance of this new
hyper-parameter has been underestimated in the community for a long time. In
this paper we did a systematic empirical study of experience replay under
various function representations. We showcase that a large replay buffer can
significantly hurt the performance. Moreover, we propose a simple O(1) method
to remedy the negative influence of a large replay buffer. We showcase its
utility in both simple grid world and challenging domains like Atari games.",2017-12-04T06:03:26Z,"Shangtong Zhang, Richard S. Sutton"
1712.01815v1,"Mastering Chess and Shogi by Self-Play with a General Reinforcement
  Learning Algorithm","The game of chess is the most widely-studied domain in the history of
artificial intelligence. The strongest programs are based on a combination of
sophisticated search techniques, domain-specific adaptations, and handcrafted
evaluation functions that have been refined by human experts over several
decades. In contrast, the AlphaGo Zero program recently achieved superhuman
performance in the game of Go, by tabula rasa reinforcement learning from games
of self-play. In this paper, we generalise this approach into a single
AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in
many challenging domains. Starting from random play, and given no domain
knowledge except the game rules, AlphaZero achieved within 24 hours a
superhuman level of play in the games of chess and shogi (Japanese chess) as
well as Go, and convincingly defeated a world-champion program in each case.",2017-12-05T18:45:38Z,"David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis"
1712.03333v4,Assumed Density Filtering Q-learning,"While off-policy temporal difference (TD) methods have widely been used in
reinforcement learning due to their efficiency and simple implementation, their
Bayesian counterparts have not been utilized as frequently. One reason is that
the non-linear max operation in the Bellman optimality equation makes it
difficult to define conjugate distributions over the value functions. In this
paper, we introduce a novel Bayesian approach to off-policy TD methods, called
as ADFQ, which updates beliefs on state-action values, Q, through an online
Bayesian inference method known as Assumed Density Filtering. We formulate an
efficient closed-form solution for the value update by approximately estimating
analytic parameters of the posterior of the Q-beliefs. Uncertainty measures in
the beliefs not only are used in exploration but also provide a natural
regularization for the value update considering all next available actions.
ADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs
decrease and improves common drawbacks of other Bayesian RL algorithms such as
computational complexity. We extend ADFQ with a neural network. Our empirical
results demonstrate that ADFQ outperforms comparable algorithms on various
Atari 2600 games, with drastic improvements in highly stochastic domains or
domains with a large action space.",2017-12-09T02:18:05Z,"Heejin Jeong, Clark Zhang, George J. Pappas, Daniel D. Lee"
1712.06015v1,StackInsights: Cognitive Learning for Hybrid Cloud Readiness,"Hybrid cloud is an integrated cloud computing environment utilizing a mix of
public cloud, private cloud, and on-premise traditional IT infrastructures.
Workload awareness, defined as a detailed full range understanding of each
individual workload, is essential in implementing the hybrid cloud. While it is
critical to perform an accurate analysis to determine which workloads are
appropriate for on-premise deployment versus which workloads can be migrated to
a cloud off-premise, the assessment is mainly performed by rule or policy based
approaches. In this paper, we introduce StackInsights, a novel cognitive system
to automatically analyze and predict the cloud readiness of workloads for an
enterprise. Our system harnesses the critical metrics across the entire stack:
1) infrastructure metrics, 2) data relevance metrics, and 3) application
taxonomy, to identify workloads that have characteristics of a) low sensitivity
with respect to business security, criticality and compliance, and b) low
response time requirements and access patterns. Since the capture of the data
relevance metrics involves an intrusive and in-depth scanning of the content of
storage objects, a machine learning model is applied to perform the business
relevance classification by learning from the meta level metrics harnessed
across stack. In contrast to traditional methods, StackInsights significantly
reduces the total time for hybrid cloud readiness assessment by orders of
magnitude.",2017-12-16T20:14:53Z,"Mu Qiao, Luis Bathen, Simon-Pierre Gnot, Sunhwan Lee, Ramani Routray"
1712.08163v1,"Reachable Set Computation and Safety Verification for Neural Networks
  with ReLU Activations","Neural networks have been widely used to solve complex real-world problems.
Due to the complicate, nonlinear, non-convex nature of neural networks, formal
safety guarantees for the output behaviors of neural networks will be crucial
for their applications in safety-critical systems.In this paper, the output
reachable set computation and safety verification problems for a class of
neural networks consisting of Rectified Linear Unit (ReLU) activation functions
are addressed. A layer-by-layer approach is developed to compute output
reachable set. The computation is formulated in the form of a set of
manipulations for a union of polyhedra, which can be efficiently applied with
the aid of polyhedron computation tools. Based on the output reachable set
computation results, the safety verification for a ReLU neural network can be
performed by checking the intersections of unsafe regions and output reachable
set described by a union of polyhedra. A numerical example of a randomly
generated ReLU neural network is provided to show the effectiveness of the
approach developed in this paper.",2017-12-21T08:57:06Z,"Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson"
1712.08164v1,"Multi-task learning of time series and its application to the travel
  demand","We address the problem of modeling and prediction of a set of temporal events
in the context of intelligent transportation systems. To leverage the
information shared by different events, we propose a multi-task learning
framework. We develop a support vector regression model for joint learning of
mutually dependent time series. It is the regularization-based multi-task
learning previously developed for the classification case and extended to time
series. We discuss the relatedness of observed time series and first deploy the
dynamic time warping distance measure to identify groups of similar series.
Then we take into account both time and scale warping and propose to align
multiple time series by inferring their common latent representation. We test
the proposed models on the problem of travel demand prediction in Nancy
(France) public transport system and analyze the benefits of multi-task
learning.",2017-12-21T11:04:14Z,Boris Chidlovskii
1803.00116v3,"Separators and Adjustment Sets in Causal Graphs: Complete Criteria and
  an Algorithmic Framework","Principled reasoning about the identifiability of causal effects from
non-experimental data is an important application of graphical causal models.
This paper focuses on effects that are identifiable by covariate adjustment, a
commonly used estimation approach. We present an algorithmic framework for
efficiently testing, constructing, and enumerating $m$-separators in ancestral
graphs (AGs), a class of graphical causal models that can represent uncertainty
about the presence of latent confounders. Furthermore, we prove a reduction
from causal effect identification by covariate adjustment to $m$-separation in
a subgraph for directed acyclic graphs (DAGs) and maximal ancestral graphs
(MAGs). Jointly, these results yield constructive criteria that characterize
all adjustment sets as well as all minimal and minimum adjustment sets for
identification of a desired causal effect with multivariate exposures and
outcomes in the presence of latent confounding. Our results extend several
existing solutions for special cases of these problems. Our efficient
algorithms allowed us to empirically quantify the identifiability gap between
covariate adjustment and the do-calculus in random DAGs and MAGs, covering a
wide range of scenarios. Implementations of our algorithms are provided in the
R package dagitty.",2018-02-28T22:28:08Z,"Benito van der Zander, Maciej Likiewicz, Johannes Textor"
1803.00781v3,"Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal
  Exploration","Intrinsically motivated goal exploration algorithms enable machines to
discover repertoires of policies that produce a diversity of effects in complex
environments. These exploration algorithms have been shown to allow real world
robots to acquire skills such as tool use in high-dimensional continuous state
and action spaces. However, they have so far assumed that self-generated goals
are sampled in a specifically engineered feature space, limiting their
autonomy. In this work, we propose to use deep representation learning
algorithms to learn an adequate goal space. This is a developmental 2-stage
approach: first, in a perceptual learning stage, deep learning algorithms use
passive raw sensor observations of world changes to learn a corresponding
latent space; then goal exploration happens in a second stage by sampling goals
in this latent space. We present experiments where a simulated robot arm
interacts with an object, and we show that exploration algorithms using such
learned representations can match the performance obtained using engineered
representations.",2018-03-02T09:45:53Z,"Alexandre Pr, Sbastien Forestier, Olivier Sigaud, Pierre-Yves Oudeyer"
1803.01364v2,"SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary
  Time Series Prediction","This paper presents a practical approach for detecting non-stationarity in
time series prediction. This method is called SAFE and works by monitoring the
evolution of the spectral contents of time series through a distance function.
This method is designed to work in combination with state-of-the-art machine
learning methods in real time by informing the online predictors to perform
necessary adaptation when a non-stationarity presents. We also propose an
algorithm to proportionally include some past data in the adaption process to
overcome the Catastrophic Forgetting problem. To validate our hypothesis and
test the effectiveness of our approach, we present comprehensive experiments in
different elements of the approach involving artificial and real-world
datasets. The experiments show that the proposed method is able to
significantly save computational resources in term of processor or GPU cycles
while maintaining high prediction performances.",2018-03-04T14:55:33Z,"Arief Koesdwiady, Fakhri Karray"
1803.01588v1,"N-body Networks: a Covariant Hierarchical Neural Network Architecture
  for Learning Atomic Potentials","We describe N-body networks, a neural network architecture for learning the
behavior and properties of complex many body physical systems. Our specific
application is to learn atomic potential energy surfaces for use in molecular
dynamics simulations. Our architecture is novel in that (a) it is based on a
hierarchical decomposition of the many body system into subsytems, (b) the
activations of the network correspond to the internal state of each subsystem,
(c) the ""neurons"" in the network are constructed explicitly so as to guarantee
that each of the activations is covariant to rotations, (d) the neurons operate
entirely in Fourier space, and the nonlinearities are realized by tensor
products followed by Clebsch-Gordan decompositions. As part of the description
of our network, we give a characterization of what way the weights of the
network may interact with the activations so as to ensure that the covariance
property is maintained.",2018-03-05T10:17:01Z,Risi Kondor
1803.02348v3,Smoothed Action Value Functions for Learning Gaussian Policies,"State-action value functions (i.e., Q-values) are ubiquitous in reinforcement
learning (RL), giving rise to popular algorithms such as SARSA and Q-learning.
We propose a new notion of action value defined by a Gaussian smoothed version
of the expected Q-value. We show that such smoothed Q-values still satisfy a
Bellman equation, making them learnable from experience sampled from an
environment. Moreover, the gradients of expected reward with respect to the
mean and covariance of a parameterized Gaussian policy can be recovered from
the gradient and Hessian of the smoothed Q-value function. Based on these
relationships, we develop new algorithms for training a Gaussian policy
directly from a learned smoothed Q-value approximator. The approach is
additionally amenable to proximal optimization by augmenting the objective with
a penalty on KL-divergence from a previous policy. We find that the ability to
learn both a mean and covariance during training leads to significantly
improved results on standard continuous control benchmarks.",2018-03-06T04:58:20Z,"Ofir Nachum, Mohammad Norouzi, George Tucker, Dale Schuurmans"
1803.02855v2,Satisficing in Time-Sensitive Bandit Learning,"Much of the recent literature on bandit learning focuses on algorithms that
aim to converge on an optimal action. One shortcoming is that this orientation
does not account for time sensitivity, which can play a crucial role when
learning an optimal action requires much more information than near-optimal
ones. Indeed, popular approaches such as upper-confidence-bound methods and
Thompson sampling can fare poorly in such situations. We consider instead
learning a satisficing action, which is near-optimal while requiring less
information, and propose satisficing Thompson sampling, an algorithm that
serves this purpose. We establish a general bound on expected discounted regret
and study the application of satisficing Thompson sampling to linear and
infinite-armed bandits, demonstrating arbitrarily large benefits over Thompson
sampling. We also discuss the relation between the notion of satisficing and
the theory of rate distortion, which offers guidance on the selection of
satisficing actions.",2018-03-07T19:41:44Z,"Daniel Russo, Benjamin Van Roy"
1803.03639v3,Precision and Recall for Time Series,"Classical anomaly detection is principally concerned with point-based
anomalies, those anomalies that occur at a single point in time. Yet, many
real-world anomalies are range-based, meaning they occur over a period of time.
Motivated by this observation, we present a new mathematical model to evaluate
the accuracy of time series classification algorithms. Our model expands the
well-known Precision and Recall metrics to measure ranges, while simultaneously
enabling customization support for domain-specific preferences.",2018-03-08T21:49:38Z,"Nesime Tatbul, Tae Jun Lee, Stan Zdonik, Mejbah Alam, Justin Gottschlich"
1803.05044v2,Learning to Explore with Meta-Policy Gradient,"The performance of off-policy learning, including deep Q-learning and deep
deterministic policy gradient (DDPG), critically depends on the choice of the
exploration policy. Existing exploration methods are mostly based on adding
noise to the on-going actor policy and can only explore \emph{local} regions
close to what the actor policy dictates. In this work, we develop a simple
meta-policy gradient algorithm that allows us to adaptively learn the
exploration policy in DDPG. Our algorithm allows us to train flexible
exploration behaviors that are independent of the actor policy, yielding a
\emph{global exploration} that significantly speeds up the learning process.
With an extensive study, we show that our method significantly improves the
sample-efficiency of DDPG on a variety of reinforcement learning tasks.",2018-03-13T21:04:17Z,"Tianbing Xu, Qiang Liu, Liang Zhao, Jian Peng"
1803.05262v2,Learning to Play General Video-Games via an Object Embedding Network,"Deep reinforcement learning (DRL) has proven to be an effective tool for
creating general video-game AI. However most current DRL video-game agents
learn end-to-end from the video-output of the game, which is superfluous for
many applications and creates a number of additional problems. More
importantly, directly working on pixel-based raw video data is substantially
distinct from what a human player does.In this paper, we present a novel method
which enables DRL agents to learn directly from object information. This is
obtained via use of an object embedding network (OEN) that compresses a set of
object feature vectors of different lengths into a single fixed-length unified
feature vector representing the current game-state and fulfills the DRL
simultaneously. We evaluate our OEN-based DRL agent by comparing to several
state-of-the-art approaches on a selection of games from the GVG-AI
Competition. Experimental results suggest that our object-based DRL agent
yields performance comparable to that of those approaches used in our
comparative study.",2018-03-14T13:26:44Z,"William Woof, Ke Chen"
1803.05768v3,PAC-Reasoning in Relational Domains,"We consider the problem of predicting plausible missing facts in relational
data, given a set of imperfect logical rules. In particular, our aim is to
provide bounds on the (expected) number of incorrect inferences that are made
in this way. Since for classical inference it is in general impossible to bound
this number in a non-trivial way, we consider two inference relations that
weaken, but remain close in spirit to classical inference.",2018-03-15T14:20:06Z,"Ondrej Kuzelka, Yuyi Wang, Jesse Davis, Steven Schockaert"
1803.08706v2,Alarm-Based Prescriptive Process Monitoring,"Predictive process monitoring is concerned with the analysis of events
produced during the execution of a process in order to predict the future state
of ongoing cases thereof. Existing techniques in this field are able to
predict, at each step of a case, the likelihood that the case will end up in an
undesired outcome. These techniques, however, do not take into account what
process workers may do with the generated predictions in order to decrease the
likelihood of undesired outcomes. This paper proposes a framework for
prescriptive process monitoring, which extends predictive process monitoring
approaches with the concepts of alarms, interventions, compensations, and
mitigation effects. The framework incorporates a parameterized cost model to
assess the cost-benefit tradeoffs of applying prescriptive process monitoring
in a given setting. The paper also outlines an approach to optimize the
generation of alarms given a dataset and a set of cost model parameters. The
proposed approach is empirically evaluated using a range of real-life event
logs.",2018-03-23T09:27:38Z,"Irene Teinemaa, Niek Tax, Massimiliano de Leoni, Marlon Dumas, Fabrizio Maria Maggi"
1805.02896v2,"Survey and cross-benchmark comparison of remaining time prediction
  methods in business process monitoring","Predictive business process monitoring methods exploit historical process
execution logs to generate predictions about running instances (called cases)
of a business process, such as the prediction of the outcome, next activity or
remaining cycle time of a given process case. These insights could be used to
support operational managers in taking remedial actions as business processes
unfold, e.g. shifting resources from one case onto another to ensure this
latter is completed on time. A number of methods to tackle the remaining cycle
time prediction problem have been proposed in the literature. However, due to
differences in their experimental setup, choice of datasets, evaluation
measures and baselines, the relative merits of each method remain unclear. This
article presents a systematic literature review and taxonomy of methods for
remaining time prediction in the context of business processes, as well as a
cross-benchmark comparison of 16 such methods based on 16 real-life datasets
originating from different industry domains.",2018-05-08T08:38:58Z,"Ilya Verenich, Marlon Dumas, Marcello La Rosa, Fabrizio Maggi, Irene Teinemaa"
1805.03364v1,A Symbolic Approach to Explaining Bayesian Network Classifiers,"We propose an approach for explaining Bayesian network classifiers, which is
based on compiling such classifiers into decision functions that have a
tractable and symbolic form. We introduce two types of explanations for why a
classifier may have classified an instance positively or negatively and suggest
algorithms for computing these explanations. The first type of explanation
identifies a minimal set of the currently active features that is responsible
for the current classification, while the second type of explanation identifies
a minimal set of features whose current state (active or not) is sufficient for
the classification. We consider in particular the compilation of Naive and
Latent-Tree Bayesian network classifiers into Ordered Decision Diagrams (ODDs),
providing a context for evaluating our proposal using case studies and
experiments based on classifiers from the literature.",2018-05-09T03:56:24Z,"Andy Shih, Arthur Choi, Adnan Darwiche"
1805.03643v1,Learning to Teach,"Teaching plays a very important role in our society, by spreading human
knowledge and educating our next generations. A good teacher will select
appropriate teaching materials, impact suitable methodologies, and set up
targeted examinations, according to the learning behaviors of the students. In
the field of artificial intelligence, however, one has not fully explored the
role of teaching, and pays most attention to machine \emph{learning}. In this
paper, we argue that equal attention, if not more, should be paid to teaching,
and furthermore, an optimization framework (instead of heuristics) should be
used to obtain good teaching strategies. We call this approach `learning to
teach'. In the approach, two intelligent agents interact with each other: a
student model (which corresponds to the learner in traditional machine learning
algorithms), and a teacher model (which determines the appropriate data, loss
function, and hypothesis space to facilitate the training of the student
model). The teacher model leverages the feedback from the student model to
optimize its own teaching strategies by means of reinforcement learning, so as
to achieve teacher-student co-evolution. To demonstrate the practical value of
our proposed approach, we take the training of deep neural networks (DNN) as an
example, and show that by using the learning to teach techniques, we are able
to use much less training data and fewer iterations to achieve almost the same
accuracy for different kinds of DNN models (e.g., multi-layer perceptron,
convolutional neural networks and recurrent neural networks) under various
machine learning tasks (e.g., image classification and text understanding).",2018-05-09T04:41:26Z,"Yang Fan, Fei Tian, Tao Qin, Xiang-Yang Li, Tie-Yan Liu"
1805.04220v1,Human-Machine Collaborative Optimization via Apprenticeship Scheduling,"Coordinating agents to complete a set of tasks with intercoupled temporal and
resource constraints is computationally challenging, yet human domain experts
can solve these difficult scheduling problems using paradigms learned through
years of apprenticeship. A process for manually codifying this domain knowledge
within a computational framework is necessary to scale beyond the
``single-expert, single-trainee"" apprenticeship model. However, human domain
experts often have difficulty describing their decision-making processes,
causing the codification of this knowledge to become laborious. We propose a
new approach for capturing domain-expert heuristics through a pairwise ranking
formulation. Our approach is model-free and does not require enumerating or
iterating through a large state space. We empirically demonstrate that this
approach accurately learns multifaceted heuristics on a synthetic data set
incorporating job-shop scheduling and vehicle routing problems, as well as on
two real-world data sets consisting of demonstrations of experts solving a
weapon-to-target assignment problem and a hospital resource allocation problem.
We also demonstrate that policies learned from human scheduling demonstration
via apprenticeship learning can substantially improve the efficiency of a
branch-and-bound search for an optimal schedule. We employ this human-machine
collaborative optimization technique on a variant of the weapon-to-target
assignment problem. We demonstrate that this technique generates solutions
substantially superior to those produced by human domain experts at a rate up
to 9.5 times faster than an optimization approach and can be applied to
optimally solve problems twice as complex as those solved by a human
demonstrator.",2018-05-11T01:53:05Z,"Matthew Gombolay, Reed Jensen, Jessica Stigile, Toni Golen, Neel Shah, Sung-Hyun Son, Julie Shah"
1805.04748v1,"Towards Autonomous Reinforcement Learning: Automatic Setting of
  Hyper-parameters using Bayesian Optimization","With the increase of machine learning usage by industries and scientific
communities in a variety of tasks such as text mining, image recognition and
self-driving cars, automatic setting of hyper-parameter in learning algorithms
is a key factor for achieving satisfactory performance regardless of user
expertise in the inner workings of the techniques and methodologies. In
particular, for a reinforcement learning algorithm, the efficiency of an agent
learning a control policy in an uncertain environment is heavily dependent on
the hyper-parameters used to balance exploration with exploitation. In this
work, an autonomous learning framework that integrates Bayesian optimization
with Gaussian process regression to optimize the hyper-parameters of a
reinforcement learning algorithm, is proposed. Also, a bandits-based approach
to achieve a balance between computational costs and decreasing uncertainty
about the Q-values, is presented. A gridworld example is used to highlight how
hyper-parameter configurations of a learning algorithm (SARSA) are iteratively
improved based on two performance functions.",2018-05-12T16:42:55Z,"Juan Cruz Barsce, Jorge A. Palombarini, Ernesto C. Martnez"
1805.05769v1,"Leveraging human knowledge in tabular reinforcement learning: A study of
  human subjects","Reinforcement Learning (RL) can be extremely effective in solving complex,
real-world problems. However, injecting human knowledge into an RL agent may
require extensive effort and expertise on the human designer's part. To date,
human factors are generally not considered in the development and evaluation of
possible RL approaches. In this article, we set out to investigate how
different methods for injecting human knowledge are applied, in practice, by
human designers of varying levels of knowledge and skill. We perform the first
empirical evaluation of several methods, including a newly proposed method
named SASS which is based on the notion of similarities in the agent's
state-action space. Through this human study, consisting of 51 human
participants, we shed new light on the human factors that play a key role in
RL. We find that the classical reward shaping technique seems to be the most
natural method for most designers, both expert and non-expert, to speed up RL.
However, we further find that our proposed method SASS can be effectively and
efficiently combined with reward shaping, and provides a beneficial alternative
to using only a single speedup method with minimal human designer effort
overhead.",2018-05-15T13:51:31Z,"Ariel Rosenfeld, Moshe Cohen, Matthew E. Taylor, Sarit Kraus"
1805.07107v2,"Extending Dynamic Bayesian Networks for Anomaly Detection in Complex
  Logs","Checking various log files from different processes can be a tedious task as
these logs contain lots of events, each with a (possibly large) number of
attributes. We developed a way to automatically model log files and detect
outlier traces in the data. For that we extend Dynamic Bayesian Networks to
model the normal behavior found in log files. We introduce a new algorithm that
is able to learn a model of a log file starting from the data itself. The model
is capable of scoring traces even when new values or new combinations of values
appear in the log file.",2018-05-18T09:23:12Z,"Stephen Pauwels, Toon Calders"
1805.08322v4,Teaching Multiple Concepts to a Forgetful Learner,"How can we help a forgetful learner learn multiple concepts within a limited
time frame? While there have been extensive studies in designing optimal
schedules for teaching a single concept given a learner's memory model,
existing approaches for teaching multiple concepts are typically based on
heuristic scheduling techniques without theoretical guarantees. In this paper,
we look at the problem from the perspective of discrete optimization and
introduce a novel algorithmic framework for teaching multiple concepts with
strong performance guarantees. Our framework is both generic, allowing the
design of teaching schedules for different memory models, and also interactive,
allowing the teacher to adapt the schedule to the underlying forgetting
mechanisms of the learner. Furthermore, for a well-known memory model, we are
able to identify a regime of model parameters where our framework is guaranteed
to achieve high performance. We perform extensive evaluations using simulations
along with real user studies in two concrete applications: (i) an educational
app for online vocabulary teaching; and (ii) an app for teaching novices how to
recognize animal species from images. Our results demonstrate the effectiveness
of our algorithm compared to popular heuristic approaches.",2018-05-21T23:34:11Z,"Anette Hunziker, Yuxin Chen, Oisin Mac Aodha, Manuel Gomez Rodriguez, Andreas Krause, Pietro Perona, Yisong Yue, Adish Singla"
1805.09938v1,"Automated Verification of Neural Networks: Advances, Challenges and
  Perspectives","Neural networks are one of the most investigated and widely used techniques
in Machine Learning. In spite of their success, they still find limited
application in safety- and security-related contexts, wherein assurance about
networks' performances must be provided. In the recent past, automated
reasoning techniques have been proposed by several researchers to close the gap
between neural networks and applications requiring formal guarantees about
their behavior. In this work, we propose a primer of such techniques and a
comprehensive categorization of existing approaches for the automated
verification of neural networks. A discussion about current limitations and
directions for future investigation is provided to foster research on this
topic at the crossroads of Machine Learning and Automated Reasoning.",2018-05-25T00:19:57Z,"Francesco Leofante, Nina Narodytska, Luca Pulina, Armando Tacchella"
1805.11199v2,Value Propagation Networks,"We present Value Propagation (VProp), a set of parameter-efficient
differentiable planning modules built on Value Iteration which can successfully
be trained using reinforcement learning to solve unseen tasks, has the
capability to generalize to larger map sizes, and can learn to navigate in
dynamic environments. We show that the modules enable learning to plan when the
environment also includes stochastic elements, providing a cost-efficient
learning system to build low-level size-invariant planners for a variety of
interactive navigation problems. We evaluate on static and dynamic
configurations of MazeBase grid-worlds, with randomly generated environments of
several different sizes, and on a StarCraft navigation scenario, with more
complex dynamics, and pixels as input.",2018-05-28T23:21:32Z,"Nantas Nardelli, Gabriel Synnaeve, Zeming Lin, Pushmeet Kohli, Philip H. S. Torr, Nicolas Usunier"
1808.01552v2,Smart City Development with Urban Transfer Learning,"Nowadays, the smart city development levels of different cities are still
unbalanced. For a large number of cities which just started development, the
governments will face a critical cold-start problem: 'how to develop a new
smart city service with limited data?'. To address this problem, transfer
learning can be leveraged to accelerate the smart city development, which we
term the urban transfer learning paradigm. This article investigates the common
process of urban transfer learning, aiming to provide city planners and
relevant practitioners with guidelines on how to apply this novel learning
paradigm. Our guidelines include common transfer strategies to take, general
steps to follow, and case studies in public safety, transportation management,
etc. We also summarize a few research opportunities and expect this article can
attract more researchers to study urban transfer learning.",2018-08-05T02:28:27Z,"Leye Wang, Bin Guo, Qiang Yang"
1808.01650v1,"Combining Graph-based Dependency Features with Convolutional Neural
  Network for Answer Triggering","Answer triggering is the task of selecting the best-suited answer for a given
question from a set of candidate answers if exists. In this paper, we present a
hybrid deep learning model for answer triggering, which combines several
dependency graph based alignment features, namely graph edit distance,
graph-based similarity and dependency graph coverage, with dense vector
embeddings from a Convolutional Neural Network (CNN). Our experiments on the
WikiQA dataset show that such a combination can more accurately trigger a
candidate answer compared to the previous state-of-the-art models. Comparative
study on WikiQA dataset shows 5.86% absolute F-score improvement at the
question level.",2018-08-05T16:44:25Z,"Deepak Gupta, Sarah Kohail, Pushpak Bhattacharyya"
1808.04794v1,"Improving Hearthstone AI by Combining MCTS and Supervised Learning
  Algorithms","We investigate the impact of supervised prediction models on the strength and
efficiency of artificial agents that use the Monte-Carlo Tree Search (MCTS)
algorithm to play a popular video game Hearthstone: Heroes of Warcraft. We
overview our custom implementation of the MCTS that is well-suited for games
with partially hidden information and random effects. We also describe
experiments which we designed to quantify the performance of our Hearthstone
agent's decision making. We show that even simple neural networks can be
trained and successfully used for the evaluation of game states. Moreover, we
demonstrate that by providing a guidance to the game state search heuristic, it
is possible to substantially improve the win rate, and at the same time reduce
the required computations.",2018-08-14T16:58:11Z,"Maciej wiechowski, Tomasz Tajmajer, Andrzej Janusz"
1808.05032v1,"Deep RTS: A Game Environment for Deep Reinforcement Learning in
  Real-Time Strategy Games","Reinforcement learning (RL) is an area of research that has blossomed
tremendously in recent years and has shown remarkable potential for artificial
intelligence based opponents in computer games. This success is primarily due
to the vast capabilities of convolutional neural networks, that can extract
useful features from noisy and complex data. Games are excellent tools to test
and push the boundaries of novel RL algorithms because they give valuable
insight into how well an algorithm can perform in isolated environments without
the real-life consequences. Real-time strategy games (RTS) is a genre that has
tremendous complexity and challenges the player in short and long-term
planning. There is much research that focuses on applied RL in RTS games, and
novel advances are therefore anticipated in the not too distant future.
However, there are to date few environments for testing RTS AIs. Environments
in the literature are often either overly simplistic, such as microRTS, or
complex and without the possibility for accelerated learning on consumer
hardware like StarCraft II. This paper introduces the Deep RTS game environment
for testing cutting-edge artificial intelligence algorithms for RTS games. Deep
RTS is a high-performance RTS game made specifically for artificial
intelligence research. It supports accelerated learning, meaning that it can
learn at a magnitude of 50 000 times faster compared to existing RTS games.
Deep RTS has a flexible configuration, enabling research in several different
RTS scenarios, including partially observable state-spaces and map complexity.
We show that Deep RTS lives up to our promises by comparing its performance
with microRTS, ELF, and StarCraft II on high-end consumer hardware. Using Deep
RTS, we show that a Deep Q-Network agent beats random-play agents over 70% of
the time. Deep RTS is publicly available at https://github.com/cair/DeepRTS.",2018-08-15T10:30:41Z,"Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo"
1808.09062v3,Cognitive Consistency Routing Algorithm of Capsule-network,"Artificial Neural Networks (ANNs) are computational models inspired by the
central nervous system (especially the brain) of animals and are used to
estimate or generate unknown approximation functions relied on large amounts of
inputs. Capsule Neural Network (Sabour S, et al.[2017]) is a novel structure of
Convolutional Neural Networks which simulates the visual processing system of
human brain. In this paper, we introduce psychological theories which called
Cognitive Consistency to optimize the routing algorithm of Capsnet to make it
more close to the work pattern of human brain. It has been shown in the
experiment that a progress had been made compared with the baseline.",2018-08-27T23:26:08Z,Huayu Li
1810.01112v1,"The Dreaming Variational Autoencoder for Reinforcement Learning
  Environments","Reinforcement learning has shown great potential in generalizing over raw
sensory data using only a single neural network for value optimization. There
are several challenges in the current state-of-the-art reinforcement learning
algorithms that prevent them from converging towards the global optima. It is
likely that the solution to these problems lies in short- and long-term
planning, exploration and memory management for reinforcement learning
algorithms. Games are often used to benchmark reinforcement learning algorithms
as they provide a flexible, reproducible, and easy to control environment.
Regardless, few games feature a state-space where results in exploration,
memory, and planning are easily perceived. This paper presents The Dreaming
Variational Autoencoder (DVAE), a neural network based generative modeling
architecture for exploration in environments with sparse feedback. We further
present Deep Maze, a novel and flexible maze engine that challenges DVAE in
partial and fully-observable state-spaces, long-horizon tasks, and
deterministic and stochastic problems. We show initial findings and encourage
further work in reinforcement learning driven by generative exploration.",2018-10-02T08:31:39Z,"Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo"
1810.01989v1,"Verification for Machine Learning, Autonomy, and Neural Networks Survey","This survey presents an overview of verification techniques for autonomous
systems, with a focus on safety-critical autonomous cyber-physical systems
(CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances
in artificial intelligence (AI) and machine learning (ML) through approaches
such as deep neural networks (DNNs), embedded in so-called learning enabled
components (LECs) that accomplish tasks from classification to control.
Recently, the formal methods and formal verification community has developed
methods to characterize behaviors in these LECs with eventual goals of formally
verifying specifications for LECs, and this article presents a survey of many
of these recent approaches.",2018-10-03T22:12:05Z,"Weiming Xiang, Patrick Musau, Ayana A. Wild, Diego Manzanas Lopez, Nathaniel Hamilton, Xiaodong Yang, Joel Rosenfeld, Taylor T. Johnson"
